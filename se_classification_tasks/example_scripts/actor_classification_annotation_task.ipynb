{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "actor_classification_annotation_task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u166XAqYc3r5"
      },
      "source": [
        "# Annotation task actor classification\n",
        "\n",
        "## Group members:\n",
        "- Mariann Burk\n",
        "- Maxine Hofstetter\n",
        "\n",
        "\n",
        "##  task\n",
        "\n",
        "* given\n",
        "    * train, development and test data\n",
        "    * use train and dev to train and tune your model\n",
        "    * use test data once at the end of tuning\n",
        "\n",
        "* specifiy a basic feedforward net with Pytorch\n",
        "    * 3 or more layers\n",
        "    * output layer a single node for binary classification (0 or 1)\n",
        "    * use BCELoss \n",
        "    * use ReLU in the hidden layers\n",
        "    * determine performance with sklearn metrics\n",
        "\n",
        "* tune your model\n",
        "    * try if layer normalisation improves the result\n",
        "    * try if dropout improves it \n",
        "\n",
        "* use the tuned model to produce a file as the basis for annotation\n",
        "    * the annotation is carried out on the ***devset*** not on the testset\n",
        "    \n",
        "* determine IAA with Cohen's Kappa\n",
        "* Merge your annotations into a single gold standard by discussing cases where you disagreed to with your partner\n",
        "\n",
        "* Create a zip file and upload to olat (exclude word embeddings)\n",
        "\n",
        "## howto\n",
        "* load fasttext word embeddings, needed for indexing (code given)\n",
        "* load the data (code given)\n",
        "* apply sklearn MLP to have a baseline (code given)\n",
        "* your task: apply your own MLP, try to tune it\n",
        "* your task: save the data for annotation\n",
        "* your task: annotate\n",
        "* your task: determine the real accuracy on the dev set by replacing the old dev_y with a true_dev_y created from your annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Maxine: I desgined the neural net based on these two articles:\n",
        "https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_feedforward_neuralnetwork/\n",
        "\n",
        "https://medium.com/biaslyai/pytorch-introduction-to-neural-network-feedforward-neural-network-model-e7231cff47cb"
      ],
      "metadata": {
        "id": "ocK9fcuEVM23"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itLxU3Rn1WCi",
        "outputId": "d1d82991-f44b-4eed-c2ee-f3378250bc4c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHRH7zwbc3r_"
      },
      "source": [
        "# load fasttext"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saEdMF4fc3sA"
      },
      "source": [
        "## Pfadnamen setzen\n",
        "\n",
        "# embedding=\"/home/klenner/Lehre/ml20/cc.de.300.vec\" # Manfred\n",
        "\n",
        "# Maxine: downloaded the embeddings from https://fasttext.cc/docs/en/crawl-vectors.html. > models > german > text. It took approx. 2 hours to upload\n",
        "embedding=\"/content/drive/MyDrive/ml_colabs/series_5/cc.de.300.vec\" \n",
        "\n",
        "# mariann: trying more generic path\n",
        "# embedding =\"/cc.de.300.vec.zip\"\n",
        "\n",
        "\n",
        "# wo die Daten liegen (train und test)\n",
        "# name=\"named/named_23_klenner/\" # Manfred\n",
        "name=\"/content/drive/MyDrive/ml_colabs/series_5/\" # Maxine\n",
        "\n",
        "# wohin die Resultate des Modells geschrieben werden (reine Textdata)\n",
        "# diese Datei sollte exportiert, annotiert und wieder importiert werden\n",
        "filename = 'devX_data_annotation.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32_IpaCc3sC"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_emb_from_file(filepath):\n",
        "\n",
        "    word_to_index = {}\n",
        "    embeddings = []\n",
        "    with open(filepath, \"r\") as fp:\n",
        "        for index, line in enumerate(fp):\n",
        "            line = line.split(\" \") # each line: word num1 num2 ...\n",
        "            word_to_index[line[0]] = index # word = line[0] \n",
        "            embedding_i = np.array([float(val) for val in line[1:]])\n",
        "            embeddings.append(embedding_i)\n",
        "    return word_to_index, embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiP7w-J9c3sD"
      },
      "source": [
        "widx,emb=load_emb_from_file(embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiz8C-TQc3sD"
      },
      "source": [
        "# load data\n",
        "\n",
        "* train, dev and test sets\n",
        "* dataX: nouns per line\n",
        "* datay: 0 (non-actors), 1 (actors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm5QAsy776av"
      },
      "source": [
        "# transform data to fasttext  embeddings\n",
        "def w2e(data):\n",
        "    out=[]\n",
        "    for w in data:\n",
        "        out.append(emb[widx[w]])\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjHrfiXJc3sD"
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle_in = open(name+\"devy_data.pickle\",\"rb\")\n",
        "devy = pickle.load(pickle_in)\n",
        "pickle_in = open(name+\"devX_data.pickle\",\"rb\")\n",
        "devX = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(name+\"trainX_data.pickle\",\"rb\")\n",
        "trainX = pickle.load(pickle_in)\n",
        "pickle_in = open(name+\"trainy_data.pickle\",\"rb\")\n",
        "trainy = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open(name+\"testy_data.pickle\",\"rb\") # Maxine: I added 'name+' for test data to make colab find the files\n",
        "testy = pickle.load(pickle_in)\n",
        "pickle_in = open(name+\"testX_data.pickle\",\"rb\")\n",
        "testX = pickle.load(pickle_in)\n",
        "\n",
        "# transform data to fasttext embeddings\n",
        "X_train=w2e(trainX)\n",
        "X_dev=w2e(devX)\n",
        "X_test=w2e(testX)\n",
        "\n",
        "y_dev=devy\n",
        "y_train=trainy\n",
        "y_test=testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0cttVs34BpL",
        "outputId": "643dcb0f-3689-4201-b5b4-892f58532f22"
      },
      "source": [
        "# Maxine: datasets are listst now\n",
        "len(X_train), len(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14953, 14953)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPk_qydDc3sD"
      },
      "source": [
        "# determine baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFOx76Yoc3sE"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oujsIlLYc3sE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ffbace-ab7d-4259-e1e2-ca64ec2f7733"
      },
      "source": [
        "# this is a sklearn baseline\n",
        "\n",
        "clf = MLPClassifier(random_state=1, hidden_layer_sizes=(300,100), max_iter=300).fit(X_train, y_train)\n",
        "\n",
        "y_pred_dev = clf.predict(X_dev)\n",
        "accuracy_score(y_dev, y_pred_dev), precision_recall_fscore_support(y_dev, y_pred_dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9180064308681672,\n",
              " (array([0.94663573, 0.85340314]),\n",
              "  array([0.93577982, 0.87634409]),\n",
              "  array([0.94117647, 0.86472149]),\n",
              "  array([436, 186])))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkgvSg9Rc3sF"
      },
      "source": [
        "# TODO implement a pytorch NN implementation for the task here\n",
        "\n",
        "    # requirements: \n",
        "    # 3 or more layers \n",
        "    # output layer a single node for binary classification (0 or 1)\n",
        "    # use BCELoss\n",
        "    # use ReLU in the hidden layers \n",
        "    # determine performance with sklearn metrics\n",
        "\n",
        "class FeedforwardNN(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(FeedforwardNN, self).__init__()\n",
        "   \n",
        "    self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
        "\n",
        "    self.relu_1 = torch.nn.ReLU()\n",
        "\n",
        "    self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    self.relu_2 = torch.nn.ReLU()\n",
        "\n",
        "    self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    self.relu_3 = torch.nn.ReLU()\n",
        "\n",
        "    self.fc4 = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    sigmoid = nn.Sigmoid()\n",
        "\n",
        "    out = self.fc1(x)\n",
        "        \n",
        "    out = sigmoid(out)\n",
        " \n",
        "    out = self.fc2(out)\n",
        "        \n",
        "    out = sigmoid(out)\n",
        "\n",
        "    out = self.fc3(out)\n",
        "        \n",
        "    out = sigmoid(out)\n",
        "\n",
        "    out = self.fc4(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYPx8Pbz7E24",
        "outputId": "711aa886-cbc5-48a8-9d28-b2ef913d889d"
      },
      "source": [
        "# instantiate the model\n",
        "\n",
        "#input_size = len(X_train)\n",
        "input_size = 300 # Maxine: i thought it should be the length of the input data but after getting an error, i tried with 300 and it works for some reason\n",
        "hidden_size = 20\n",
        "output_size = 1 # Maxine: see instructions: output layer a single node for binary classification (0 or 1)\n",
        "model = FeedforwardNN(input_size, hidden_size, output_size)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeedforwardNN(\n",
              "  (fc1): Linear(in_features=300, out_features=20, bias=True)\n",
              "  (relu_1): ReLU()\n",
              "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (relu_2): ReLU()\n",
              "  (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (relu_3): ReLU()\n",
              "  (fc4): Linear(in_features=20, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEwd4PHj9pxk"
      },
      "source": [
        "# hyperparameters\n",
        "\n",
        "#criterion = nn.BCEWithLogitsLoss() # Maxine: we are asked to use BCE Loss but i had to add Logits to squeeze values between 0 and 1\n",
        "criterion = nn.BCELoss() \n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8JLgtT_ZUe"
      },
      "source": [
        "# Maxine: I think we have to convert the data to tensors\n",
        "\n",
        "'''\n",
        "# approach with tensors > x and y are going to be separate datasets\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_dev = torch.FloatTensor(X_dev)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_dev = torch.FloatTensor(y_dev)\n",
        "y_test = torch.FloatTensor(y_test)\n",
        "\n",
        "'''\n",
        "# approach with DataLoader > x and y are going to form one set\n",
        "# prepare data: turn into tensors\n",
        "from torch.utils.data import DataLoader\n",
        "X_train_tensor = torch.FloatTensor(np.array(X_train))\n",
        "X_test_tensor = torch.FloatTensor(np.array(X_test))\n",
        "X_dev_tensor = torch.FloatTensor(np.array(X_dev))\n",
        "y_train_tensor = torch.Tensor(np.array(y_train))\n",
        "y_test_tensor = torch.Tensor(np.array(y_test))\n",
        "y_dev_tensor = torch.Tensor(np.array(y_dev))\n",
        "\n",
        "# prepare data: turn into tensor datasets\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
        "dev_dataset = torch.utils.data.TensorDataset(X_dev_tensor, y_dev_tensor)\n",
        "\n",
        "# turn into Dataloader\n",
        "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_dl = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "dev_dl = DataLoader(dev_dataset, batch_size=64, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Maxine: imports we need to get acc (like in series_3)\n",
        "from numpy import vstack\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "dyFLp_sgXlfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg6_re5IBGA6"
      },
      "source": [
        "# Maxine: TODO: add accuracy measure \n",
        "'''\n",
        "# approach without iterating over x, y in enumerate(dl)\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  y_pred = model(X_train)\n",
        "\n",
        "  # Maxine: I did this because it was of type Long before but it kept asking for float\n",
        "  y_pred = y_pred.to(device).float()\n",
        "  y_train= y_train.to(device).float()\n",
        "\n",
        "  loss = criterion(y_pred.squeeze(), y_train)\n",
        "\n",
        "  # accuracy >> fails because of tensor shape: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
        "  y_pred = y_pred.detach().numpy()\n",
        "  y_pred = y_pred.round()\n",
        "  actual = y_train.numpy()\n",
        "  actual  = actual.reshape((len(actual), 1))\n",
        "\n",
        "  y_pred, actual = vstack(y_pred), vstack(actual)\n",
        "  acc = accuracy_score(actual, y_pred) \n",
        "\n",
        "  print('Epoch {}: train loss: {} accuracy {}'.format(epoch, loss.item(), acc))\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "'''\n",
        "# mariann: added the iteration count for understanding purposes\n",
        "# train the model\n",
        "def train(epochs):\n",
        "    for i in range(epochs):\n",
        "        for batch, target in train_dl:\n",
        "          optimizer.zero_grad()\n",
        "          \n",
        "          y_pred=model(batch)\n",
        "          \n",
        "          loss=criterion(y_pred,target.unsqueeze(1))  #mariann: i had to remove the squeexe() from predict in order to equalize the sizes of target and predict\n",
        "        \n",
        "          loss.backward()\n",
        "          \n",
        "          optimizer.step()\n",
        "  \n",
        "        #print(loss.item())\n",
        "        for batch, target in dev_dl:\n",
        "            with torch.no_grad():\n",
        "                y_pred=model(batch)  \n",
        "                #y_pred=y_pred.detach().numpy()  # remove tensor specific stuff, move to numpy array\n",
        "           \n",
        "                loss_validation = criterion(y_pred, target.unsqueeze(1))\n",
        "            #print('Manfred')\n",
        "        #print(loss_validation)\n",
        "    return y_pred\n",
        "\n",
        "y_pred = train(50)\n",
        "\n",
        "# mariann: Calculate Accuracy         \n",
        "correct = 0\n",
        "total = 0\n",
        "# Iterate through test dataset\n",
        "for batch, target in test_dl:\n",
        "  y_predict=model(batch)\n",
        "\n",
        "# Get predictions from the maximum value\n",
        "  _, predicted = torch.max(y_predict.data, 1)\n",
        "# Total number of labels\n",
        "  total += target.size(0)\n",
        "\n",
        "# Total correct predictions\n",
        "  correct += (predicted == target).sum()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "#print('Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGj7PBBf6pSY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set threshold to convert prediction either to 1 or "
      ],
      "metadata": {
        "id": "czrxr0h4SD8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTKGC_t5c3sG"
      },
      "source": [
        "# write to file for annotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIERXLd8c3sH"
      },
      "source": [
        "# one noun per line incl. the predicted class, e.g. \"Tomate 1\"\n",
        "# nouns and labels are in the same file to ease annotation\n",
        "y_pred = y_pred.detach().numpy()\n",
        "\n",
        "file=open(name+filename,\"w\")\n",
        "for i,w in enumerate(devX):\n",
        "        file.write(w)\n",
        "        file.write(\" \")\n",
        "        file.write(str(y_pred))  # y_pred are the predictions of your tuned model\n",
        "        file.write(\"\\n\")\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbuqMi4XTpXQ",
        "outputId": "f98ab368-6bc8-48c1-861f-8eae96f0a430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='/content/drive/MyDrive/ml_colabs/series_5/devX_data_annotation.txt' mode='w' encoding='UTF-8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0eHihGxc3sH"
      },
      "source": [
        "# read annotated data \n",
        "\n",
        "* output data are lines like \"Tomate 1\" (1 is the predicted class)\n",
        "* 1 is actor, 0 is non-actor, so this is wrong\n",
        "* use \"x\" in front of a wrong prediction as annotation, e.g. \"xTomate 1\"\n",
        "* annotate only incorrect predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKZD6PtAc3sH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "f9f35090-c627-40f3-9e92-25f9db3c22d3"
      },
      "source": [
        "# reads your annotated data back into true_dev_y\n",
        "# filename is the name of the file of your annotated data\n",
        "# creates true_dev_y: your annotated data as a gold standard\n",
        "\n",
        "file=open(name+filename,\"r\")\n",
        "h,a,=0,0\n",
        "\n",
        "true_dev_y=[]\n",
        "for line in file:\n",
        "    w,l=line.split(\" \")\n",
        "    l=l.strip(\"\\n\")\n",
        "    a+=1\n",
        "    if w[0]=='x' and l=='1':   # prediction was wrong, actually the label is 0\n",
        "        my_dev_y.append(0)\n",
        "    elif w[0]=='x' and l=='0':\n",
        "        true_dev_y.append(1)\n",
        "    else:\n",
        "        true_dev_y.append(int(l))\n",
        "        h+=1   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-603edf289751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrue_dev_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrue_dev_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '[[0.32504502]'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ94oC1wc3sH"
      },
      "source": [
        "# how good is your best model really?\n",
        "\n",
        "* apply your best model to your new gold standard (the corrected dev file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmjc07btc3sI"
      },
      "source": [
        "# compare it first to the baseline\n",
        "\n",
        "clf = MLPClassifier(random_state=1, hidden_layer_sizes=(300,100), max_iter=300).fit(X_train, y_train)\n",
        "\n",
        "y_pred=clf.predict(X_dev)\n",
        "accuracy_score(true_dev_y, y_pred_dev),precision_recall_fscore_support(true_dev_y, y_pred_dev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6dPIDe8c3sI"
      },
      "source": [
        "# TODO: Calculate the inter-annotator agreement using cohens kappa between the 2 members of the group "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mCONhhOc3sJ"
      },
      "source": [
        "# TODO: Merge your annotations into a single gold standard by discussing cases where you disagreed to with your partner"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}