{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "I1ryVWjsp2C7"
   },
   "source": [
    "# Pytoch active learning loop: Portuguese\n",
    "\n",
    "maxhof905"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wh6mUpU9p2C7"
   },
   "source": [
    "\n",
    "sources :\n",
    "- https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
    "- https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/#step-2-make-dataset-iterable"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yCVhFC4p55R",
    "outputId": "c4b00e7c-747d-4e81-b64b-09ad00e32af2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkjctjBXp2C-",
    "outputId": "15d34a04-1cca-4c0b-abd9-40ca20a34740"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting skorch\n",
      "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
      "\u001B[?25l\r\u001B[K     |██▏                             | 10 kB 34.8 MB/s eta 0:00:01\r\u001B[K     |████▎                           | 20 kB 22.0 MB/s eta 0:00:01\r\u001B[K     |██████▍                         | 30 kB 11.7 MB/s eta 0:00:01\r\u001B[K     |████████▌                       | 40 kB 9.4 MB/s eta 0:00:01\r\u001B[K     |██████████▋                     | 51 kB 3.5 MB/s eta 0:00:01\r\u001B[K     |████████████▊                   | 61 kB 4.2 MB/s eta 0:00:01\r\u001B[K     |██████████████▉                 | 71 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████████               | 81 kB 4.2 MB/s eta 0:00:01\r\u001B[K     |███████████████████             | 92 kB 4.7 MB/s eta 0:00:01\r\u001B[K     |█████████████████████▏          | 102 kB 4.0 MB/s eta 0:00:01\r\u001B[K     |███████████████████████▎        | 112 kB 4.0 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▍      | 122 kB 4.0 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▌    | 133 kB 4.0 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▋  | 143 kB 4.0 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▊| 153 kB 4.0 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 155 kB 4.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.64.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.21.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n",
      "Installing collected packages: skorch\n",
      "Successfully installed skorch-0.11.0\n",
      "Collecting modal\n",
      "  Downloading modAL-0.4.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from modal) (1.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from modal) (1.3.5)\n",
      "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from modal) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from modal) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modal) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modal) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->modal) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modal) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modal) (1.1.0)\n",
      "Installing collected packages: modal\n",
      "Successfully installed modal-0.4.1\n"
     ]
    }
   ],
   "source": [
    "# installations for colab\n",
    "!pip install skorch\n",
    "!pip install modal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1-JVl-aXp2C_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EpochScoring\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcT5QKYzp2DA"
   },
   "source": [
    "## 2) helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "mmsVMbmWp2DA"
   },
   "outputs": [],
   "source": [
    "def get_class_dist(df_col):\n",
    "    \"\"\"\n",
    "    plot label distribution\n",
    "    \"\"\"\n",
    "    data = df_col.value_counts(normalize=True).rename('percentage').mul(100).reset_index().rename(columns = {\"index\":\"label\"})\n",
    "    plot = sns.barplot(x=\"label\", y=\"percentage\", data=data)\n",
    "    plot.set_xticklabels(plot.get_xticklabels(),\n",
    "                          rotation=90,\n",
    "                          horizontalalignment='right')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wgEsHgdwp2DB"
   },
   "outputs": [],
   "source": [
    "def get_balanced_set(df):\n",
    "    \"\"\"\n",
    "    create balanced data set (oversampling)\n",
    "    \"\"\"\n",
    "    max_size = df['se_label'].value_counts().max()\n",
    "    balanced_list = [df]\n",
    "    for class_index, group in df.groupby('se_label'):\n",
    "        balanced_list.append(group.sample(max_size-len(group), replace=True))\n",
    "    return pd.concat(balanced_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "u9u1sAApp2DB"
   },
   "outputs": [],
   "source": [
    "def get_flattened_list(nested_list):\n",
    "    return [item for sublist in nested_list for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1TjQU0TGp2DB"
   },
   "outputs": [],
   "source": [
    "def get_learners_preds(prediction_proba):\n",
    "    \"\"\"\n",
    "    return the learners predictions as a dict with labels as keys and the probabilities as values\n",
    "    :param prediction_proba: values obtained from learner.predict()\n",
    "    :return: dict with probability per label\n",
    "    \"\"\"\n",
    "    prediction_proba = np.round(prediction_proba, 2)\n",
    "    prediction_list = list()\n",
    "    for i in range(len(prediction_proba)):\n",
    "        predictions = {'expl': prediction_proba[i][0], 'fixed': prediction_proba[i][1],\n",
    "                      'iobj': prediction_proba[i][2], 'mark': prediction_proba[i][3], \n",
    "                       'nsubj': prediction_proba[i][4], 'obj': prediction_proba[i][5]}\n",
    "        prediction_list.append(predictions)\n",
    "    return prediction_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qoyt9cOp2DD"
   },
   "source": [
    "## 3) load and preprocess data\n",
    "- initial_train: labeled test set ('seed')\n",
    "- pool: pool of unlabeled data\n",
    "- test: small labeled test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "x2_jBdptp2DD"
   },
   "outputs": [],
   "source": [
    "train_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/pt_data/pt_bosque-ud-train.txt'\n",
    "test_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/pt_data/pt_bosque-ud-test.txt'\n",
    "dev_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/pt_data/pt_bosque-ud-dev.txt'\n",
    "pool_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/corpusdata_org/pt_text_se_corpus.txt'\n",
    "\n",
    "train = pd.read_csv(train_path, sep='\\t', names=['text', 'tokenized_text', 'se_label'])\n",
    "train.drop(columns=['text'], inplace = True)\n",
    "dev = pd.read_csv(dev_path, sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "dev.drop(columns=['text'], inplace = True)\n",
    "test = pd.read_csv(test_path, sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "test.drop(columns=['text'], inplace = True)\n",
    "\n",
    "se_corpus = pd.concat([train, dev, test]) # because the data was fileted for 'se' the data splits are not reliable anymore\n",
    "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'case')].index)\n",
    "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'nmod')].index)\n",
    "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'expl:pass')].index)\n",
    "\n",
    "pool = pd.read_csv(pool_path, sep='\\t', names=['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "ygIoN5Dtp2DD",
    "outputId": "704b6d13-df14-47c1-db85-8e9e67dead5a"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEXCAYAAACqIS9uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWpElEQVR4nO3de7QlZX3m8e8j4IAiAtK2RIVGJWjHKMIRRfBKNGS8wEQGo46yXGTIjJfB0WVkNImOiZmokxgHI9qK2ipxVBLCZQiIPYhBHeCAIJeGgAgqATnGC3jl9ps/qs7i0JzTvU/3qV19dn0/a/Xa+6296+xfrd372e9+q+qtVBWSpOF4QN8FSJLGy+CXpIEx+CVpYAx+SRoYg1+SBmbbvgsYxW677VarVq3quwxJWlYuvvjiH1TVig2XL4vgX7VqFdPT032XIUnLSpIb51vuUI8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNzLI4c3c++7/lU32XsGgXv+/VfZcgSfb4JWloOg3+JDsnOTnJ1UnWJzkwya5JzklybXu7S5c1SJLuq+se/weAs6rq8cCTgfXAccC6qtobWNe2JUlj0lnwJ3ko8CzgRICquqOqfgwcBqxtn7YWOLyrGiRJ99dlj38vYAb4RJJvJPlYkgcDK6vq5vY5twAr51s5yTFJppNMz8zMdFimJA1Ll8G/LbAfcEJVPQX4GRsM61RVATXfylW1pqqmqmpqxYr7XUdAkrSZugz+7wHfq6oL2vbJNF8E30+yO0B7e2uHNUiSNtBZ8FfVLcB3k+zTLjoEuAo4DTiqXXYUcGpXNUiS7q/rE7jeAJyU5IHA9cBraL5sPp/kaOBG4MiOa5AkzdFp8FfVpcDUPA8d0uXrSpIW5pm7kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQw23b5x5PcANwO3A3cVVVTSXYFPgesAm4AjqyqH3VZhyTpXuPo8T+3qvatqqm2fRywrqr2Bta1bUnSmPQx1HMYsLa9vxY4vIcaJGmwug7+Ar6Y5OIkx7TLVlbVze39W4CV862Y5Jgk00mmZ2ZmOi5Tkoaj0zF+4OCquinJw4Fzklw998GqqiQ134pVtQZYAzA1NTXvcyRJi9dpj7+qbmpvbwVOAQ4Avp9kd4D29tYua5Ak3VdnwZ/kwUkeMnsfeAFwBXAacFT7tKOAU7uqQZJ0f10O9awETkky+zp/W1VnJbkI+HySo4EbgSM7rEGStIHOgr+qrgeePM/yfwUO6ep1JUkb55m7kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwHQe/Em2SfKNJGe07b2SXJDkuiSfS/LArmuQJN1rHD3+Y4H1c9rvAd5fVY8DfgQcPYYaJEmtToM/yaOAFwIfa9sBngec3D5lLXB4lzVIku5r5OBPskOSfRb59/8a+EPgnrb9MODHVXVX2/4e8MgFXu+YJNNJpmdmZhb5spKkhYwU/EleDFwKnNW2901y2ibWeRFwa1VdvDmFVdWaqpqqqqkVK1Zszp+QJM1j2xGf907gAODLAFV1aZK9NrHOQcBLkvxbYHtgJ+ADwM5Jtm17/Y8CbtqMuiVJm2nUoZ47q+onGyyrja1QVf+tqh5VVauA3wP+b1W9EjgXOKJ92lHAqYuoV5K0hUYN/iuTvALYJsneSY4HvraZr/lW4E1JrqMZ8z9xM/+OJGkzjDrU8wbg7cCvgM8CZwN/OuqLVNWXuXeY6HqaYSNJUg9GCv6q+jlN8L+923IkSV0bKfiTnM79x/R/AkwDH6mqXy51YZKkbow6xn898FPgo+2/24DbgV9v25KkZWLUMf5nVNVT57RPT3JRVT01yZVdFCZJ6saoPf4dk+wx22jv79g271jyqiRJnRm1x/9m4Pwk3wIC7AW8NsmDaebbkSQtE6Me1XNmkr2Bx7eLrpmzQ/evO6lMktSJUXv8AHsD+9BMv/DkJFTVp7opS5LUlVEP53wH8BxgNXAm8DvA+YDBL0nLzKg7d48ADgFuqarXAE8GHtpZVZKkzowa/L+oqnuAu5LsBNwKPLq7siRJXRl1jH86yc40J2tdTHMy19c7q0qS1JlRj+p5bXv3w0nOAnaqqm92V5YkqSujXoFr3ez9qrqhqr45d5kkafnYaI8/yfbAg4DdkuxCc/IWNFfTmvdauZKkrdumhnr+AHgj8Gs0Y/uzwX8b8MEO65IkdWSjwV9VHwA+kOQNVXX8mGqSJHVo1J27xyd5BrBq7jqeuStJy8+oZ+5+GngscClwd7u48MxdSVp2Rj2OfwpYXVUbXoVLkrTMjHrm7hXAI7osRJI0HqP2+HcDrkpyIfCr2YVV9ZJOqpIkdWbU4H9nl0VIksZn1KN6zkuyJ7B3VX0pyYOAbbotTZLUhVGnbPiPwMnAR9pFjwT+oauiJEndGXXn7uuAg2jO2KWqrgUevrEVkmyf5MIklyW5Msl/b5fvleSCJNcl+VySB27JBkiSFmfU4P9VVd0x20iyLc1x/BtdB3heVT0Z2Bc4NMnTgfcA76+qxwE/Ao5efNmSpM01avCfl+RtwA5Jng98ATh9YytU46dtc7v2XwHPoxk2AlgLHL7oqiVJm23U4D8OmAEup5m47Uzgjza1UpJtklxKc8Wuc4BvAT+uqrvap3yPBWb5THJMkukk0zMzMyOWKUnalFEP59wB+HhVfRSaQG+X/XxjK1XV3cC+7dW7TgEeP2phVbUGWAMwNTXlGcOStERG7fGvown6WTsAXxr1Rarqx8C5wIHAzu0+AoBHATeN+nckSVtu1ODffs54Pe39B21shSQr2p4+SXYAng+sp/kCOKJ92lHAqYstWpK0+UYN/p8l2W+2kWR/4BebWGd34Nwk3wQuAs6pqjOAtwJvSnId8DDgxMWXLUnaXKOO8R8LfCHJv9BchesRwMs2tkJ7MfanzLP8euCARdYpSVoimwz+dkfuM2l2zO7TLr6mqu7ssjBJUjc2OdTTHpnz8qq6s6quaP8Z+pK0TI061PPVJB8EPgf8bHZhVV3SSVWSpM6MGvz7trfvmrNs9ixcSdIyMuq0zM/tuhBJ0niMOi3zyiQnJvnHtr06iZOrSdIyNOpx/J8EzgZ+rW3/M/DGLgqSJHVr1ODfrao+D9wD0E6ydndnVUmSOrOYM3cfRjsHfzuv/k86q0qS1JlRj+p5E3Aa8JgkXwVWcO98O5KkZWTU4L+KZlrlnwO301xv95+7KkqS1J1Rh3o+RTNlw58DxwO/Dny6q6IkSd0Ztcf/xKpaPad9bpKruihIktStUXv8l7Q7dAFI8jRgupuSJEldGrXHvz/wtSTfadt7ANckuZzmuupP6qQ6SdKSGzX4D+20CknS2Iw6V8+NXRciSRqPUcf4JUkTwuCXpIEx+CVpYAx+SRoYg1+SBsbgl6SBMfglaWA6C/4kj05ybpKrklyZ5Nh2+a5JzklybXu7S1c1SJLur8se/13Am9vJ3Z4OvC7JauA4YF1V7Q2sa9uSpDHpLPir6uaquqS9fzuwHngkcBiwtn3aWuDwrmqQJN3fWMb4k6wCngJcAKysqpvbh24BVi6wzjFJppNMz8zMjKNMSRqEzoM/yY7A3wFvrKrb5j5WVUV7Hd8NVdWaqpqqqqkVK1Z0XaYkDUanwZ9kO5rQP6mq/r5d/P0ku7eP7w7c2mUNkqT76vKongAnAuur6q/mPHQacFR7/yjg1K5qkCTd36jz8W+Og4BXAZcnubRd9jbgL4DPJzkauBE4ssMaJEkb6Cz4q+p8IAs8fEhXrytJ2jjP3JWkgTH4JWlgDH5JGhiDX5IGxuCXpIHp8nBObYHvvOs3+y5h0fb4k8v7LkHSCOzxS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjPPxqxcHHX9Q3yUs2lff8NW+S5CWhD1+SRoYg1+SBsbgl6SB6Sz4k3w8ya1JrpizbNck5yS5tr3dpavXlyTNr8se/yeBQzdYdhywrqr2Bta1bUnSGHUW/FX1FeCHGyw+DFjb3l8LHN7V60uS5jfuMf6VVXVze/8WYOVCT0xyTJLpJNMzMzPjqU6SBqC3nbtVVUBt5PE1VTVVVVMrVqwYY2WSNNnGHfzfT7I7QHt765hfX5IGb9zBfxpwVHv/KODUMb++JA1el4dzfhb4OrBPku8lORr4C+D5Sa4FfqttS5LGqLO5eqrq5Qs8dEhXrylJ2jTP3JWkgTH4JWlgDH5JGhjn45c6cN6znt13CYvy7K+c13cJGiN7/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sAY/JI0MAa/JA2MwS9JA2PwS9LAGPySNDAGvyQNjMEvSQNj8EvSwHixdUmL9sE3n953CYvy+r988cjPffd/OKLDSrrx9s+cvKjn99LjT3JokmuSXJfkuD5qkKShGnvwJ9kG+Bvgd4DVwMuTrB53HZI0VH30+A8Arquq66vqDuB/A4f1UIckDVKqarwvmBwBHFpVv9+2XwU8rapev8HzjgGOaZv7ANeMsczdgB+M8fXGbZK3b5K3Ddy+5W7c27dnVa3YcOFWu3O3qtYAa/p47STTVTXVx2uPwyRv3yRvG7h9y93Wsn19DPXcBDx6TvtR7TJJ0hj0EfwXAXsn2SvJA4HfA07roQ5JGqSxD/VU1V1JXg+cDWwDfLyqrhx3HZvQyxDTGE3y9k3ytoHbt9xtFds39p27kqR+OWWDJA2MwS9JA2PwS9LAGPxaVpLsNc+yp/ZRi7RcDWbnbpJdN/Z4Vf1wXLV0Icnjq+rqJPvN83ABP6yqG8dd11JLcgnw4qq6qW0/G/hgVf1mv5VtmUl//5LsVFW3LfA5LOC2qrp73HUthSSn02zDvKrqJWMsZyRDCv5v07w5mefhqqrHjLmkJZVkTVUdk+TcBZ7yMOCyqnrVOOtaam3v/kPAi4H9gP8BvKiqvttrYVto0t+/JGdU1Ys28jncEfhoVb1t/NVtmbbzAfC7wCOAz7TtlwPfr6r/2kthGzGY4Bck+WJVvaDvOrZUkgOBjwC/BF5YVTM9lzQWk/L+zaedtfeKqnpC37VsrvmmY9hapmjY0CCDP8nvAgfT9Dz+qar+oeeSlkyS7YHXMmf7gA9X1S97LWwLzfNzejVwM/Aj2Dp/Tm+OSX3/5prUz1+S9TQdkevb9l7AmVvjl9nggj/Jh4DHAZ9tF70M+FZVva6/qpZOks8Dt3Pvz81XADtX1b/vr6otN+fn9Lyq6rxx1dKlSX3/Zk3y5y/JoTRn5l5PM5S1J/AHVXV2r4XNY4jBfzXwhGo3PMkDgCu3xm/lzZHkqqpavally1E7HPClqnpu37V0ZZLfPxjE5+/fAI9vm1dX1a/6rGchQzyc8zpgjzntR7fLJsUlSZ4+20jyNGC6x3qWTHvUxz1JHtp3LR2a2PevNbGfvyQPAt4CvL6qLgP2SPKinsua11Y7H3+HHgKsT3IhzRjjAcB0ktNg+Y4VJ7mcZnu2A76W5Dtte0/g6j5rW2I/BS5Pcg7ws9mFVfVf+itpy036+zdnH83czx80n78LF1xxefkEcDFwYNu+CfgCcEZvFS1giMH/J30X0JGtsmfRgb9v/02aue/fLsAz2/tfAX48/nKW3P/su4AxeGxVvSzJywGq6udJ5jt8vHdDDP6Zqrpq7oIkz6mqL/dUz5KYPbknyR6beu5yVlVr+66hC3Pev2OB36f5cgvwaeCjwPH9Vbfl5u58T7ISmD3b+sKqurWfqpbcHUl2oD36LMljga1yjH+IO3evAD4FvA/YHngvMFVVB250xWVizpBBaLZvL+CaqvqNXgtbIkn2pjlpazXN9gGw3E/Am5Xkm8CBVfWztv1g4OtV9aR+K1saSY6k+ex9meb/6DOBt1TVyX3WtRSSvAB4O83/zS8CBwGvqaqFTsrrzRB7/E8D3gN8jWa88SSaN2gibDh1QTsFwGt7KqcLnwDeAbwfeC7wGibrIIUAc6cuuJv5zzZfrt4OPHW2l59kBfAlYNkHf1V9McnFwNNp3rNjq2qrvHD8JH1gRnUn8AtgB5oe47er6p5+S+pOVV1C82U3KXaoqnU0v1ZvrKp3Ai/suaal9AnggiTvTPJO4P8BJ/Zb0pJ6wAZDO//KhORQkk8Dd1XV/6mqM4AHJ1nXd13zGWKP/yLgVGAKWAF8OMlLJ+gEmTfNaT4A2B/4l57K6cKv2mO/r20v4XkTzTwvE6Gq/irJl2nObIVmqOAbPZa01M5Kcjb3PYHrzB7rWUrn03xpvwl4JM2hnW/ut6T5DXGM/wBgH2CvqnpXuzP01VX1Zz2XtiSSvGNO8y7gBuDvJuWU/3aStvXAzsCfAjsB762qC3otTCNL8lLuHV79p6o6pc96llKSg4FzgR8AT6mqW3ouaV5DDP4TgHuA51XVE5LsAnyxqiZuTve2Z7xjVd3Wdy1LJckUzTjxnjTHvEMzu+pE7PzU8pXkVcAf0+yDehLw2zS/2C7rtbB5DHGo52lVtV+SbwBU1Y+SbLeplZaLJH8L/CeanYIXATsl+UBVva/fypbMSTQ/oS+n+QLXMpDk/Ko6OMnt3HeyvdB8ce/UU2lL6aXAwe0+jM8mOQVYC+zbb1n3N8Tgv7Od82X2WNsVsPBFFJah1e0FL14J/CNwHM3ZhJMS/DNVdVrfRWhxqurg9vYhfdfSlao6fIP2he3Q8lZniMH/v4BTgIcneTdwBPBH/Za0pLZrf8EcTnNlqju30pMHN9c7knwMWMeck2OqahLP5tUykOQPq+q9SY5n/k7kVjedyOCCv6pOao+1PYTmZ+bhVbW+57KW0kdoduheBnwlyZ7AT3qtaGm9hmb2w+24d6inmMxpHLQ8vJXmRNBv0V4fYms3uJ27k66dFvYIYBWwDc0hndtU1R/3WddSSXJNVe3Tdx3SrCRXAb9FM7T6HDY44W5rvJ734Hr8A3AqzaRel9BcmhAmax/G15Ks3nC+JalHJ9AMPT6GZn/arNB89ra66UTs8U+YJFdU1RP7rqMr7eXtHgt8m2aMf/aoEA/nVK+SnFBV/7nvOkZh8E+YJGuA46vq8r5r6UK7z+J+Zme3lLRpBv+EaccbH4c9YkkLMPgnjD1iSZti8EvSwEzEdKiSpNEZ/JI0MAa/tIEkP93E46vaS3gu5m9+MskRW1aZtDQMfkkaGINfWkCSHZOsS3JJksuTHDbn4W2TnJRkfZKTkzyoXWf/JOcluTjJ2Ul276l8aUEGv7SwXwL/rqr2o7mw+1/m3qlO9wE+VFVPAG4DXtvOino8cERV7Q98HHh3D3VLG+VcPdLCAvx5kmfRzAT6SGBl+9h3q+qr7f3P0Ey9exbwROCc9vthG+DmsVYsjcDglxb2SmAFsH97XYMbgO3bxzY8AaZoviiurKoDx1eitHgO9UgLeyhwaxv6z6W5zu+sPZLMBvwrgPOBa4AVs8uTbJfkN8ZasTQCg19a2EnAVJLLgVcDV8957Brgde1sobsAJ1TVHTTXQnhPksuAS4FnjLlmaZOcskGSBsYevyQNjMEvSQNj8EvSwBj8kjQwBr8kDYzBL0kDY/BL0sD8fyL5gUTxznXvAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "get_class_dist(se_corpus.se_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1leMNrbXp2DF"
   },
   "outputs": [],
   "source": [
    "X = se_corpus.tokenized_text\n",
    "y = se_corpus.se_label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2022)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NxnZw-YSp2DF"
   },
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "pool_vectorized = vectorizer.transform(pool.text).toarray()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "F2cDu0ijp2DF"
   },
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jMfNtq6jp2DF"
   },
   "outputs": [],
   "source": [
    "class PoolDataset(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zZQT1J-Qp2DG"
   },
   "outputs": [],
   "source": [
    "train_set = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "test_set = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
    "\n",
    "pool_set = PoolDataset(torch.from_numpy(pool_vectorized).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuzJZKakp2DG"
   },
   "outputs": [],
   "source": [
    "train_features = torch.reshape(train_set.X_data,   (train_set.X_data.shape[0], 1,train_set.X_data.shape[1]))\n",
    "train_labels = train_set.y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tLkX2trp2DG"
   },
   "outputs": [],
   "source": [
    "test_features = torch.reshape(test_set.X_data,   (test_set.X_data.shape[0], 1,test_set.X_data.shape[1]))\n",
    "test_labels = test_set.y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_features.shape[2]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asa2TgM4rjwF",
    "outputId": "b3f9bd8d-2fe1-4530-d24c-a5cb9a713909"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7342"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SLD_dpYvp2DG"
   },
   "outputs": [],
   "source": [
    "X_pool = pool_set.X_data\n",
    "X_pool = torch.reshape(X_pool,   (X_pool.shape[0], 1, X_pool.shape[1]))\n",
    "X_pool = X_pool.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbudqpM-p2DG"
   },
   "source": [
    "## 2) Model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "label_encoder.classes_"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJH2qaBorvA5",
    "outputId": "9ced703e-9f0c-4788-e1fe-7b13c1220986"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['expl', 'fixed', 'iobj', 'mark', 'nsubj', 'obj'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RMogkBRUp2DH"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = 1\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(train_features.shape[2], hidden_dim, 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdR11kUnp2DH",
    "outputId": "ec8ea4c6-6911-4de8-81de-e8107d955cc1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using:  cuda\n"
     ]
    }
   ],
   "source": [
    "# skorch library creates sklearn classifier from torch neural net\n",
    "# infer initial parameters from es_pytorch_active_learning (which was run first with extensive GridSearch)\n",
    "\n",
    "# create the classifier\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('using: ', device)\n",
    "\n",
    "# Callbacks: print accuracy when model is fitted\n",
    "acc = EpochScoring(scoring='accuracy', on_train=True,\n",
    "                         name='accuracy', lower_is_better=False)\n",
    "\n",
    "f1 = EpochScoring(scoring='f1_weighted', on_train=True,\n",
    "                         name='f1-score', lower_is_better=False)\n",
    "\n",
    "callbacks = [acc, f1]\n",
    "\n",
    "classifier = NeuralNetClassifier(module=LSTMModel,\n",
    "                                 batch_size=64,\n",
    "                                 max_epochs= 10,\n",
    "                                 criterion=nn.CrossEntropyLoss,\n",
    "                                 optimizer=torch.optim.Adam,\n",
    "                                 lr=0.001,\n",
    "                                 train_split=None,\n",
    "                                 callbacks=callbacks,\n",
    "                                 verbose=1,\n",
    "                                 device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CL6ILTLLp2DI",
    "outputId": "b943bf00-1a64-499e-a912-805d87d4c286"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4410\u001B[0m      \u001B[32m0.4070\u001B[0m        \u001B[35m1.7037\u001B[0m  0.0756\n",
      "      2      \u001B[36m0.6170\u001B[0m      \u001B[32m0.4719\u001B[0m        \u001B[35m1.5089\u001B[0m  0.0606\n",
      "      3      0.6160      0.4696        \u001B[35m1.2841\u001B[0m  0.0637\n",
      "      4      0.6160      0.4696        \u001B[35m1.0947\u001B[0m  0.0706\n",
      "      5      0.6160      0.4696        \u001B[35m0.9596\u001B[0m  0.0626\n",
      "      6      \u001B[36m0.6430\u001B[0m      \u001B[32m0.5258\u001B[0m        \u001B[35m0.8239\u001B[0m  0.0606\n",
      "      7      \u001B[36m0.7530\u001B[0m      \u001B[32m0.7026\u001B[0m        \u001B[35m0.6775\u001B[0m  0.0591\n",
      "      8      \u001B[36m0.8570\u001B[0m      \u001B[32m0.8374\u001B[0m        \u001B[35m0.5317\u001B[0m  0.0585\n",
      "      9      \u001B[36m0.9190\u001B[0m      \u001B[32m0.9081\u001B[0m        \u001B[35m0.4043\u001B[0m  0.0600\n",
      "     10      \u001B[36m0.9480\u001B[0m      \u001B[32m0.9410\u001B[0m        \u001B[35m0.3048\u001B[0m  0.0606\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=LSTMModel(\n",
       "    (lstm): LSTM(7342, 64, batch_first=True)\n",
       "    (fc): Linear(in_features=64, out_features=6, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "classifier.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuwMlAfup2DI"
   },
   "source": [
    "***model is overfitting***: \n",
    "Run hyperparameter for best parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6qb9lylp2DI",
    "outputId": "35fb4bb1-277a-403c-e631-c1b5f75f9411"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5175\u001B[0m      \u001B[32m0.4404\u001B[0m        \u001B[35m1.6780\u001B[0m  0.0804\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.3630\u001B[0m  0.0802\n",
      "      3      0.6162      0.4699        \u001B[35m1.1085\u001B[0m  0.0799\n",
      "      4      \u001B[36m0.6175\u001B[0m      \u001B[32m0.4728\u001B[0m        \u001B[35m0.9461\u001B[0m  0.0801\n",
      "      5      \u001B[36m0.6713\u001B[0m      \u001B[32m0.5723\u001B[0m        \u001B[35m0.7750\u001B[0m  0.0813\n",
      "      6      \u001B[36m0.8137\u001B[0m      \u001B[32m0.7685\u001B[0m        \u001B[35m0.5885\u001B[0m  0.0797\n",
      "      7      \u001B[36m0.9038\u001B[0m      \u001B[32m0.8803\u001B[0m        \u001B[35m0.4217\u001B[0m  0.0927\n",
      "      8      \u001B[36m0.9500\u001B[0m      \u001B[32m0.9444\u001B[0m        \u001B[35m0.2963\u001B[0m  0.0806\n",
      "      9      \u001B[36m0.9762\u001B[0m      \u001B[32m0.9751\u001B[0m        \u001B[35m0.2098\u001B[0m  0.0785\n",
      "     10      \u001B[36m0.9900\u001B[0m      \u001B[32m0.9897\u001B[0m        \u001B[35m0.1522\u001B[0m  0.0799\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.3725\u001B[0m      \u001B[32m0.3917\u001B[0m        \u001B[35m1.7347\u001B[0m  0.0773\n",
      "      2      \u001B[36m0.6225\u001B[0m      \u001B[32m0.4857\u001B[0m        \u001B[35m1.3882\u001B[0m  0.0804\n",
      "      3      0.6162      0.4699        \u001B[35m1.1065\u001B[0m  0.0792\n",
      "      4      0.6188      0.4756        \u001B[35m0.9477\u001B[0m  0.0795\n",
      "      5      \u001B[36m0.6675\u001B[0m      \u001B[32m0.5709\u001B[0m        \u001B[35m0.7899\u001B[0m  0.0816\n",
      "      6      \u001B[36m0.7925\u001B[0m      \u001B[32m0.7484\u001B[0m        \u001B[35m0.6178\u001B[0m  0.0851\n",
      "      7      \u001B[36m0.8912\u001B[0m      \u001B[32m0.8736\u001B[0m        \u001B[35m0.4544\u001B[0m  0.0791\n",
      "      8      \u001B[36m0.9463\u001B[0m      \u001B[32m0.9405\u001B[0m        \u001B[35m0.3248\u001B[0m  0.0798\n",
      "      9      \u001B[36m0.9688\u001B[0m      \u001B[32m0.9673\u001B[0m        \u001B[35m0.2334\u001B[0m  0.0775\n",
      "     10      \u001B[36m0.9800\u001B[0m      \u001B[32m0.9792\u001B[0m        \u001B[35m0.1716\u001B[0m  0.0786\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.2725\u001B[0m      \u001B[32m0.3118\u001B[0m        \u001B[35m1.7552\u001B[0m  0.0891\n",
      "      2      \u001B[36m0.6250\u001B[0m      \u001B[32m0.5006\u001B[0m        \u001B[35m1.4438\u001B[0m  0.0836\n",
      "      3      0.6150      0.4684        \u001B[35m1.1385\u001B[0m  0.0819\n",
      "      4      0.6162      0.4712        \u001B[35m0.9632\u001B[0m  0.0801\n",
      "      5      \u001B[36m0.6675\u001B[0m      \u001B[32m0.5731\u001B[0m        \u001B[35m0.7885\u001B[0m  0.0754\n",
      "      6      \u001B[36m0.8187\u001B[0m      \u001B[32m0.7806\u001B[0m        \u001B[35m0.5963\u001B[0m  0.0778\n",
      "      7      \u001B[36m0.9137\u001B[0m      \u001B[32m0.8951\u001B[0m        \u001B[35m0.4213\u001B[0m  0.0801\n",
      "      8      \u001B[36m0.9575\u001B[0m      \u001B[32m0.9528\u001B[0m        \u001B[35m0.2912\u001B[0m  0.0816\n",
      "      9      \u001B[36m0.9712\u001B[0m      \u001B[32m0.9695\u001B[0m        \u001B[35m0.2047\u001B[0m  0.0770\n",
      "     10      \u001B[36m0.9838\u001B[0m      \u001B[32m0.9831\u001B[0m        \u001B[35m0.1487\u001B[0m  0.0759\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5000\u001B[0m      \u001B[32m0.4405\u001B[0m        \u001B[35m1.6979\u001B[0m  0.0757\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.3810\u001B[0m  0.0800\n",
      "      3      0.6162      0.4699        \u001B[35m1.1086\u001B[0m  0.0821\n",
      "      4      0.6162      0.4699        \u001B[35m0.9418\u001B[0m  0.0781\n",
      "      5      \u001B[36m0.6737\u001B[0m      \u001B[32m0.5799\u001B[0m        \u001B[35m0.7635\u001B[0m  0.0775\n",
      "      6      \u001B[36m0.8150\u001B[0m      \u001B[32m0.7823\u001B[0m        \u001B[35m0.5697\u001B[0m  0.0800\n",
      "      7      \u001B[36m0.9187\u001B[0m      \u001B[32m0.9090\u001B[0m        \u001B[35m0.3989\u001B[0m  0.0771\n",
      "      8      \u001B[36m0.9637\u001B[0m      \u001B[32m0.9603\u001B[0m        \u001B[35m0.2747\u001B[0m  0.0848\n",
      "      9      \u001B[36m0.9775\u001B[0m      \u001B[32m0.9752\u001B[0m        \u001B[35m0.1932\u001B[0m  0.0747\n",
      "     10      \u001B[36m0.9862\u001B[0m      \u001B[32m0.9859\u001B[0m        \u001B[35m0.1408\u001B[0m  0.0780\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4338\u001B[0m      \u001B[32m0.4264\u001B[0m        \u001B[35m1.6982\u001B[0m  0.0763\n",
      "      2      \u001B[36m0.6175\u001B[0m      \u001B[32m0.4728\u001B[0m        \u001B[35m1.3803\u001B[0m  0.0790\n",
      "      3      0.6162      0.4699        \u001B[35m1.1174\u001B[0m  0.0810\n",
      "      4      0.6162      0.4699        \u001B[35m0.9515\u001B[0m  0.0862\n",
      "      5      \u001B[36m0.6800\u001B[0m      \u001B[32m0.5946\u001B[0m        \u001B[35m0.7728\u001B[0m  0.0787\n",
      "      6      \u001B[36m0.8213\u001B[0m      \u001B[32m0.7865\u001B[0m        \u001B[35m0.5757\u001B[0m  0.0787\n",
      "      7      \u001B[36m0.9237\u001B[0m      \u001B[32m0.9112\u001B[0m        \u001B[35m0.4008\u001B[0m  0.0783\n",
      "      8      \u001B[36m0.9613\u001B[0m      \u001B[32m0.9573\u001B[0m        \u001B[35m0.2744\u001B[0m  0.0749\n",
      "      9      \u001B[36m0.9750\u001B[0m      \u001B[32m0.9731\u001B[0m        \u001B[35m0.1922\u001B[0m  0.0773\n",
      "     10      \u001B[36m0.9838\u001B[0m      \u001B[32m0.9831\u001B[0m        \u001B[35m0.1399\u001B[0m  0.0811\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5437\u001B[0m      \u001B[32m0.4500\u001B[0m        \u001B[35m1.6553\u001B[0m  0.0986\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.2447\u001B[0m  0.1011\n",
      "      3      0.6162      0.4699        \u001B[35m0.9973\u001B[0m  0.0990\n",
      "      4      \u001B[36m0.6625\u001B[0m      \u001B[32m0.5605\u001B[0m        \u001B[35m0.7885\u001B[0m  0.0993\n",
      "      5      \u001B[36m0.8313\u001B[0m      \u001B[32m0.8004\u001B[0m        \u001B[35m0.5445\u001B[0m  0.0996\n",
      "      6      \u001B[36m0.9400\u001B[0m      \u001B[32m0.9323\u001B[0m        \u001B[35m0.3345\u001B[0m  0.1003\n",
      "      7      \u001B[36m0.9738\u001B[0m      \u001B[32m0.9717\u001B[0m        \u001B[35m0.2029\u001B[0m  0.0973\n",
      "      8      \u001B[36m0.9875\u001B[0m      \u001B[32m0.9870\u001B[0m        \u001B[35m0.1302\u001B[0m  0.0999\n",
      "      9      \u001B[36m0.9950\u001B[0m      \u001B[32m0.9948\u001B[0m        \u001B[35m0.0895\u001B[0m  0.0987\n",
      "     10      0.9950      0.9948        \u001B[35m0.0652\u001B[0m  0.0994\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4813\u001B[0m      \u001B[32m0.4258\u001B[0m        \u001B[35m1.6661\u001B[0m  0.0980\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.2376\u001B[0m  0.1027\n",
      "      3      0.6162      0.4699        \u001B[35m1.0010\u001B[0m  0.1017\n",
      "      4      \u001B[36m0.6625\u001B[0m      \u001B[32m0.5615\u001B[0m        \u001B[35m0.7987\u001B[0m  0.1007\n",
      "      5      \u001B[36m0.8125\u001B[0m      \u001B[32m0.7762\u001B[0m        \u001B[35m0.5653\u001B[0m  0.0984\n",
      "      6      \u001B[36m0.9187\u001B[0m      \u001B[32m0.9055\u001B[0m        \u001B[35m0.3587\u001B[0m  0.0981\n",
      "      7      \u001B[36m0.9650\u001B[0m      \u001B[32m0.9616\u001B[0m        \u001B[35m0.2236\u001B[0m  0.0978\n",
      "      8      \u001B[36m0.9838\u001B[0m      \u001B[32m0.9828\u001B[0m        \u001B[35m0.1458\u001B[0m  0.1003\n",
      "      9      \u001B[36m0.9900\u001B[0m      \u001B[32m0.9898\u001B[0m        \u001B[35m0.1004\u001B[0m  0.0977\n",
      "     10      \u001B[36m0.9938\u001B[0m      \u001B[32m0.9935\u001B[0m        \u001B[35m0.0727\u001B[0m  0.0979\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4338\u001B[0m      \u001B[32m0.4010\u001B[0m        \u001B[35m1.6707\u001B[0m  0.0971\n",
      "      2      \u001B[36m0.6150\u001B[0m      \u001B[32m0.4684\u001B[0m        \u001B[35m1.2344\u001B[0m  0.0999\n",
      "      3      0.6150      0.4684        \u001B[35m1.0014\u001B[0m  0.0997\n",
      "      4      \u001B[36m0.6613\u001B[0m      \u001B[32m0.5594\u001B[0m        \u001B[35m0.7956\u001B[0m  0.0990\n",
      "      5      \u001B[36m0.8163\u001B[0m      \u001B[32m0.7809\u001B[0m        \u001B[35m0.5589\u001B[0m  0.0969\n",
      "      6      \u001B[36m0.9300\u001B[0m      \u001B[32m0.9181\u001B[0m        \u001B[35m0.3556\u001B[0m  0.1054\n",
      "      7      \u001B[36m0.9600\u001B[0m      \u001B[32m0.9562\u001B[0m        \u001B[35m0.2228\u001B[0m  0.1035\n",
      "      8      \u001B[36m0.9788\u001B[0m      \u001B[32m0.9774\u001B[0m        \u001B[35m0.1459\u001B[0m  0.1027\n",
      "      9      \u001B[36m0.9862\u001B[0m      \u001B[32m0.9857\u001B[0m        \u001B[35m0.1010\u001B[0m  0.1054\n",
      "     10      \u001B[36m0.9900\u001B[0m      \u001B[32m0.9898\u001B[0m        \u001B[35m0.0736\u001B[0m  0.1000\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4363\u001B[0m      \u001B[32m0.4069\u001B[0m        \u001B[35m1.6792\u001B[0m  0.1022\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.2474\u001B[0m  0.0988\n",
      "      3      0.6162      0.4699        \u001B[35m0.9982\u001B[0m  0.0993\n",
      "      4      \u001B[36m0.6687\u001B[0m      \u001B[32m0.5715\u001B[0m        \u001B[35m0.7852\u001B[0m  0.1014\n",
      "      5      \u001B[36m0.8313\u001B[0m      \u001B[32m0.7973\u001B[0m        \u001B[35m0.5433\u001B[0m  0.1018\n",
      "      6      \u001B[36m0.9313\u001B[0m      \u001B[32m0.9215\u001B[0m        \u001B[35m0.3377\u001B[0m  0.1017\n",
      "      7      \u001B[36m0.9750\u001B[0m      \u001B[32m0.9726\u001B[0m        \u001B[35m0.2086\u001B[0m  0.1032\n",
      "      8      \u001B[36m0.9825\u001B[0m      \u001B[32m0.9812\u001B[0m        \u001B[35m0.1358\u001B[0m  0.0999\n",
      "      9      \u001B[36m0.9900\u001B[0m      \u001B[32m0.9894\u001B[0m        \u001B[35m0.0938\u001B[0m  0.1009\n",
      "     10      \u001B[36m0.9925\u001B[0m      \u001B[32m0.9922\u001B[0m        \u001B[35m0.0682\u001B[0m  0.1017\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5650\u001B[0m      \u001B[32m0.4593\u001B[0m        \u001B[35m1.6178\u001B[0m  0.0976\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.2078\u001B[0m  0.0984\n",
      "      3      0.6162      0.4699        \u001B[35m0.9821\u001B[0m  0.0989\n",
      "      4      \u001B[36m0.6775\u001B[0m      \u001B[32m0.5803\u001B[0m        \u001B[35m0.7709\u001B[0m  0.1034\n",
      "      5      \u001B[36m0.8337\u001B[0m      \u001B[32m0.7972\u001B[0m        \u001B[35m0.5301\u001B[0m  0.1016\n",
      "      6      \u001B[36m0.9425\u001B[0m      \u001B[32m0.9356\u001B[0m        \u001B[35m0.3257\u001B[0m  0.0978\n",
      "      7      \u001B[36m0.9700\u001B[0m      \u001B[32m0.9677\u001B[0m        \u001B[35m0.1986\u001B[0m  0.0998\n",
      "      8      \u001B[36m0.9838\u001B[0m      \u001B[32m0.9832\u001B[0m        \u001B[35m0.1287\u001B[0m  0.0981\n",
      "      9      \u001B[36m0.9900\u001B[0m      \u001B[32m0.9898\u001B[0m        \u001B[35m0.0890\u001B[0m  0.0987\n",
      "     10      \u001B[36m0.9950\u001B[0m      \u001B[32m0.9948\u001B[0m        \u001B[35m0.0648\u001B[0m  0.1024\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5938\u001B[0m      \u001B[32m0.4613\u001B[0m        \u001B[35m1.2643\u001B[0m  0.0746\n",
      "      2      \u001B[36m0.8187\u001B[0m      \u001B[32m0.7881\u001B[0m        \u001B[35m0.5154\u001B[0m  0.0767\n",
      "      3      \u001B[36m0.9938\u001B[0m      \u001B[32m0.9933\u001B[0m        \u001B[35m0.0450\u001B[0m  0.0785\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0074\u001B[0m  0.0803\n",
      "      5      1.0000      1.0000        \u001B[35m0.0034\u001B[0m  0.0760\n",
      "      6      1.0000      1.0000        \u001B[35m0.0022\u001B[0m  0.0755\n",
      "      7      1.0000      1.0000        \u001B[35m0.0016\u001B[0m  0.0773\n",
      "      8      1.0000      1.0000        \u001B[35m0.0012\u001B[0m  0.0727\n",
      "      9      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0743\n",
      "     10      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0777\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5913\u001B[0m      \u001B[32m0.4616\u001B[0m        \u001B[35m1.2799\u001B[0m  0.0782\n",
      "      2      \u001B[36m0.7762\u001B[0m      \u001B[32m0.7342\u001B[0m        \u001B[35m0.5659\u001B[0m  0.0771\n",
      "      3      \u001B[36m0.9938\u001B[0m      \u001B[32m0.9937\u001B[0m        \u001B[35m0.0575\u001B[0m  0.0755\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0082\u001B[0m  0.0779\n",
      "      5      1.0000      1.0000        \u001B[35m0.0036\u001B[0m  0.0762\n",
      "      6      1.0000      1.0000        \u001B[35m0.0023\u001B[0m  0.0812\n",
      "      7      1.0000      1.0000        \u001B[35m0.0017\u001B[0m  0.0772\n",
      "      8      1.0000      1.0000        \u001B[35m0.0013\u001B[0m  0.0786\n",
      "      9      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0800\n",
      "     10      1.0000      1.0000        \u001B[35m0.0009\u001B[0m  0.0766\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5763\u001B[0m      \u001B[32m0.4598\u001B[0m        \u001B[35m1.2772\u001B[0m  0.0785\n",
      "      2      \u001B[36m0.8013\u001B[0m      \u001B[32m0.7613\u001B[0m        \u001B[35m0.5256\u001B[0m  0.0838\n",
      "      3      \u001B[36m0.9912\u001B[0m      \u001B[32m0.9911\u001B[0m        \u001B[35m0.0532\u001B[0m  0.0775\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0076\u001B[0m  0.0774\n",
      "      5      1.0000      1.0000        \u001B[35m0.0034\u001B[0m  0.0799\n",
      "      6      1.0000      1.0000        \u001B[35m0.0022\u001B[0m  0.0791\n",
      "      7      1.0000      1.0000        \u001B[35m0.0016\u001B[0m  0.0843\n",
      "      8      1.0000      1.0000        \u001B[35m0.0012\u001B[0m  0.0787\n",
      "      9      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0772\n",
      "     10      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0796\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.6112\u001B[0m      \u001B[32m0.4704\u001B[0m        \u001B[35m1.2577\u001B[0m  0.0755\n",
      "      2      \u001B[36m0.8187\u001B[0m      \u001B[32m0.7886\u001B[0m        \u001B[35m0.4930\u001B[0m  0.0794\n",
      "      3      \u001B[36m0.9938\u001B[0m      \u001B[32m0.9935\u001B[0m        \u001B[35m0.0448\u001B[0m  0.0766\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0077\u001B[0m  0.0805\n",
      "      5      1.0000      1.0000        \u001B[35m0.0034\u001B[0m  0.0787\n",
      "      6      1.0000      1.0000        \u001B[35m0.0022\u001B[0m  0.0765\n",
      "      7      1.0000      1.0000        \u001B[35m0.0016\u001B[0m  0.0776\n",
      "      8      1.0000      1.0000        \u001B[35m0.0012\u001B[0m  0.0844\n",
      "      9      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0801\n",
      "     10      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0801\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.6000\u001B[0m      \u001B[32m0.4735\u001B[0m        \u001B[35m1.2555\u001B[0m  0.0772\n",
      "      2      \u001B[36m0.8200\u001B[0m      \u001B[32m0.7881\u001B[0m        \u001B[35m0.5117\u001B[0m  0.0809\n",
      "      3      \u001B[36m0.9925\u001B[0m      \u001B[32m0.9923\u001B[0m        \u001B[35m0.0570\u001B[0m  0.0786\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0085\u001B[0m  0.0782\n",
      "      5      1.0000      1.0000        \u001B[35m0.0035\u001B[0m  0.0821\n",
      "      6      1.0000      1.0000        \u001B[35m0.0022\u001B[0m  0.0805\n",
      "      7      1.0000      1.0000        \u001B[35m0.0015\u001B[0m  0.0880\n",
      "      8      1.0000      1.0000        \u001B[35m0.0012\u001B[0m  0.0776\n",
      "      9      1.0000      1.0000        \u001B[35m0.0009\u001B[0m  0.0771\n",
      "     10      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0772\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5737\u001B[0m      \u001B[32m0.4575\u001B[0m        \u001B[35m1.2653\u001B[0m  0.1002\n",
      "      2      \u001B[36m0.8375\u001B[0m      \u001B[32m0.8147\u001B[0m        \u001B[35m0.4327\u001B[0m  0.1025\n",
      "      3      \u001B[36m0.9962\u001B[0m      \u001B[32m0.9961\u001B[0m        \u001B[35m0.0226\u001B[0m  0.0999\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0034\u001B[0m  0.1005\n",
      "      5      1.0000      1.0000        \u001B[35m0.0016\u001B[0m  0.1017\n",
      "      6      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0985\n",
      "      7      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0988\n",
      "      8      1.0000      1.0000        \u001B[35m0.0006\u001B[0m  0.0985\n",
      "      9      1.0000      1.0000        \u001B[35m0.0005\u001B[0m  0.1071\n",
      "     10      1.0000      1.0000        \u001B[35m0.0004\u001B[0m  0.0993\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5887\u001B[0m      \u001B[32m0.4593\u001B[0m        \u001B[35m1.2460\u001B[0m  0.0977\n",
      "      2      \u001B[36m0.8462\u001B[0m      \u001B[32m0.8276\u001B[0m        \u001B[35m0.3777\u001B[0m  0.0982\n",
      "      3      \u001B[36m0.9962\u001B[0m      \u001B[32m0.9962\u001B[0m        \u001B[35m0.0198\u001B[0m  0.0999\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0033\u001B[0m  0.1011\n",
      "      5      1.0000      1.0000        \u001B[35m0.0016\u001B[0m  0.0991\n",
      "      6      1.0000      1.0000        \u001B[35m0.0011\u001B[0m  0.1011\n",
      "      7      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.1027\n",
      "      8      1.0000      1.0000        \u001B[35m0.0006\u001B[0m  0.0991\n",
      "      9      1.0000      1.0000        \u001B[35m0.0005\u001B[0m  0.0999\n",
      "     10      1.0000      1.0000        \u001B[35m0.0004\u001B[0m  0.0973\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5875\u001B[0m      \u001B[32m0.4618\u001B[0m        \u001B[35m1.2715\u001B[0m  0.0972\n",
      "      2      \u001B[36m0.8762\u001B[0m      \u001B[32m0.8616\u001B[0m        \u001B[35m0.3711\u001B[0m  0.1058\n",
      "      3      \u001B[36m0.9975\u001B[0m      \u001B[32m0.9975\u001B[0m        \u001B[35m0.0212\u001B[0m  0.1021\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0028\u001B[0m  0.1068\n",
      "      5      1.0000      1.0000        \u001B[35m0.0014\u001B[0m  0.0990\n",
      "      6      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0991\n",
      "      7      1.0000      1.0000        \u001B[35m0.0007\u001B[0m  0.1015\n",
      "      8      1.0000      1.0000        \u001B[35m0.0006\u001B[0m  0.1017\n",
      "      9      1.0000      1.0000        \u001B[35m0.0005\u001B[0m  0.0993\n",
      "     10      1.0000      1.0000        \u001B[35m0.0004\u001B[0m  0.0979\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.6000\u001B[0m      \u001B[32m0.4708\u001B[0m        \u001B[35m1.2459\u001B[0m  0.1002\n",
      "      2      \u001B[36m0.8925\u001B[0m      \u001B[32m0.8792\u001B[0m        \u001B[35m0.3608\u001B[0m  0.1037\n",
      "      3      \u001B[36m0.9975\u001B[0m      \u001B[32m0.9975\u001B[0m        \u001B[35m0.0223\u001B[0m  0.0997\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0030\u001B[0m  0.1005\n",
      "      5      1.0000      1.0000        \u001B[35m0.0014\u001B[0m  0.0996\n",
      "      6      1.0000      1.0000        \u001B[35m0.0009\u001B[0m  0.1019\n",
      "      7      1.0000      1.0000        \u001B[35m0.0007\u001B[0m  0.1024\n",
      "      8      1.0000      1.0000        \u001B[35m0.0005\u001B[0m  0.0997\n",
      "      9      1.0000      1.0000        \u001B[35m0.0004\u001B[0m  0.0994\n",
      "     10      1.0000      1.0000        \u001B[35m0.0004\u001B[0m  0.0998\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5950\u001B[0m      \u001B[32m0.4623\u001B[0m        \u001B[35m1.2556\u001B[0m  0.1030\n",
      "      2      \u001B[36m0.8938\u001B[0m      \u001B[32m0.8801\u001B[0m        \u001B[35m0.3467\u001B[0m  0.1030\n",
      "      3      \u001B[36m0.9988\u001B[0m      \u001B[32m0.9987\u001B[0m        \u001B[35m0.0216\u001B[0m  0.1031\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0033\u001B[0m  0.1007\n",
      "      5      1.0000      1.0000        \u001B[35m0.0016\u001B[0m  0.1034\n",
      "      6      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.1072\n",
      "      7      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.1053\n",
      "      8      1.0000      1.0000        \u001B[35m0.0006\u001B[0m  0.1043\n",
      "      9      1.0000      1.0000        \u001B[35m0.0005\u001B[0m  0.1037\n",
      "     10      1.0000      1.0000        \u001B[35m0.0004\u001B[0m  0.1080\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4250\u001B[0m      \u001B[32m0.4078\u001B[0m        \u001B[35m1.6833\u001B[0m  0.0508\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4703\u001B[0m        \u001B[35m1.5150\u001B[0m  0.0491\n",
      "      3      0.6162      0.4699        \u001B[35m1.3278\u001B[0m  0.0505\n",
      "      4      0.6162      0.4699        \u001B[35m1.1489\u001B[0m  0.0483\n",
      "      5      0.6162      0.4699        \u001B[35m1.0152\u001B[0m  0.0478\n",
      "      6      \u001B[36m0.6188\u001B[0m      \u001B[32m0.4756\u001B[0m        \u001B[35m0.9035\u001B[0m  0.0478\n",
      "      7      \u001B[36m0.6663\u001B[0m      \u001B[32m0.5698\u001B[0m        \u001B[35m0.7873\u001B[0m  0.0495\n",
      "      8      \u001B[36m0.7775\u001B[0m      \u001B[32m0.7303\u001B[0m        \u001B[35m0.6646\u001B[0m  0.0497\n",
      "      9      \u001B[36m0.8525\u001B[0m      \u001B[32m0.8154\u001B[0m        \u001B[35m0.5430\u001B[0m  0.0483\n",
      "     10      \u001B[36m0.9038\u001B[0m      \u001B[32m0.8765\u001B[0m        \u001B[35m0.4331\u001B[0m  0.0474\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.2313\u001B[0m      \u001B[32m0.2834\u001B[0m        \u001B[35m1.7766\u001B[0m  0.0467\n",
      "      2      \u001B[36m0.6150\u001B[0m      \u001B[32m0.5122\u001B[0m        \u001B[35m1.6023\u001B[0m  0.0520\n",
      "      3      \u001B[36m0.6212\u001B[0m      0.4829        \u001B[35m1.4018\u001B[0m  0.0477\n",
      "      4      0.6175      0.4728        \u001B[35m1.1999\u001B[0m  0.0491\n",
      "      5      0.6175      0.4728        \u001B[35m1.0503\u001B[0m  0.0481\n",
      "      6      0.6200      0.4784        \u001B[35m0.9351\u001B[0m  0.0541\n",
      "      7      \u001B[36m0.6475\u001B[0m      \u001B[32m0.5352\u001B[0m        \u001B[35m0.8189\u001B[0m  0.0487\n",
      "      8      \u001B[36m0.7300\u001B[0m      \u001B[32m0.6700\u001B[0m        \u001B[35m0.6972\u001B[0m  0.0485\n",
      "      9      \u001B[36m0.8175\u001B[0m      \u001B[32m0.7826\u001B[0m        \u001B[35m0.5751\u001B[0m  0.0480\n",
      "     10      \u001B[36m0.8912\u001B[0m      \u001B[32m0.8778\u001B[0m        \u001B[35m0.4617\u001B[0m  0.0481\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.0900\u001B[0m      \u001B[32m0.1255\u001B[0m        \u001B[35m1.7953\u001B[0m  0.0467\n",
      "      2      \u001B[36m0.5450\u001B[0m      \u001B[32m0.5002\u001B[0m        \u001B[35m1.6272\u001B[0m  0.0491\n",
      "      3      \u001B[36m0.6225\u001B[0m      0.4873        \u001B[35m1.4210\u001B[0m  0.0500\n",
      "      4      0.6150      0.4684        \u001B[35m1.2060\u001B[0m  0.0481\n",
      "      5      0.6150      0.4684        \u001B[35m1.0458\u001B[0m  0.0487\n",
      "      6      0.6225      0.4849        \u001B[35m0.9205\u001B[0m  0.0473\n",
      "      7      \u001B[36m0.6713\u001B[0m      \u001B[32m0.5759\u001B[0m        \u001B[35m0.7928\u001B[0m  0.0470\n",
      "      8      \u001B[36m0.7863\u001B[0m      \u001B[32m0.7408\u001B[0m        \u001B[35m0.6616\u001B[0m  0.0456\n",
      "      9      \u001B[36m0.8550\u001B[0m      \u001B[32m0.8271\u001B[0m        \u001B[35m0.5352\u001B[0m  0.0479\n",
      "     10      \u001B[36m0.9237\u001B[0m      \u001B[32m0.9088\u001B[0m        \u001B[35m0.4238\u001B[0m  0.0509\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4363\u001B[0m      \u001B[32m0.4074\u001B[0m        \u001B[35m1.7240\u001B[0m  0.0469\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.5573\u001B[0m  0.0512\n",
      "      3      0.6162      0.4699        \u001B[35m1.3689\u001B[0m  0.0527\n",
      "      4      0.6162      0.4699        \u001B[35m1.1829\u001B[0m  0.0505\n",
      "      5      0.6162      0.4699        \u001B[35m1.0430\u001B[0m  0.0502\n",
      "      6      \u001B[36m0.6175\u001B[0m      \u001B[32m0.4728\u001B[0m        \u001B[35m0.9281\u001B[0m  0.0486\n",
      "      7      \u001B[36m0.6562\u001B[0m      \u001B[32m0.5474\u001B[0m        \u001B[35m0.8066\u001B[0m  0.0524\n",
      "      8      \u001B[36m0.7450\u001B[0m      \u001B[32m0.6851\u001B[0m        \u001B[35m0.6761\u001B[0m  0.0525\n",
      "      9      \u001B[36m0.8488\u001B[0m      \u001B[32m0.8171\u001B[0m        \u001B[35m0.5461\u001B[0m  0.0501\n",
      "     10      \u001B[36m0.9062\u001B[0m      \u001B[32m0.8922\u001B[0m        \u001B[35m0.4294\u001B[0m  0.0507\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.6050\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.6858\u001B[0m  0.0500\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.5246\u001B[0m  0.0498\n",
      "      3      0.6162      0.4699        \u001B[35m1.3393\u001B[0m  0.0478\n",
      "      4      0.6162      0.4699        \u001B[35m1.1587\u001B[0m  0.0480\n",
      "      5      0.6162      0.4699        \u001B[35m1.0232\u001B[0m  0.0482\n",
      "      6      \u001B[36m0.6175\u001B[0m      \u001B[32m0.4728\u001B[0m        \u001B[35m0.9062\u001B[0m  0.0487\n",
      "      7      \u001B[36m0.6538\u001B[0m      \u001B[32m0.5465\u001B[0m        \u001B[35m0.7807\u001B[0m  0.0512\n",
      "      8      \u001B[36m0.7688\u001B[0m      \u001B[32m0.7226\u001B[0m        \u001B[35m0.6490\u001B[0m  0.0474\n",
      "      9      \u001B[36m0.8662\u001B[0m      \u001B[32m0.8464\u001B[0m        \u001B[35m0.5207\u001B[0m  0.0552\n",
      "     10      \u001B[36m0.9313\u001B[0m      \u001B[32m0.9208\u001B[0m        \u001B[35m0.4078\u001B[0m  0.0476\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4738\u001B[0m      \u001B[32m0.4211\u001B[0m        \u001B[35m1.7171\u001B[0m  0.0596\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.4480\u001B[0m  0.0612\n",
      "      3      0.6162      0.4699        \u001B[35m1.1834\u001B[0m  0.0604\n",
      "      4      0.6162      0.4699        \u001B[35m1.0163\u001B[0m  0.0619\n",
      "      5      \u001B[36m0.6200\u001B[0m      \u001B[32m0.4784\u001B[0m        \u001B[35m0.8827\u001B[0m  0.0604\n",
      "      6      \u001B[36m0.6913\u001B[0m      \u001B[32m0.6111\u001B[0m        \u001B[35m0.7355\u001B[0m  0.0634\n",
      "      7      \u001B[36m0.8187\u001B[0m      \u001B[32m0.7786\u001B[0m        \u001B[35m0.5786\u001B[0m  0.0703\n",
      "      8      \u001B[36m0.9062\u001B[0m      \u001B[32m0.8875\u001B[0m        \u001B[35m0.4314\u001B[0m  0.0705\n",
      "      9      \u001B[36m0.9475\u001B[0m      \u001B[32m0.9405\u001B[0m        \u001B[35m0.3126\u001B[0m  0.0595\n",
      "     10      \u001B[36m0.9675\u001B[0m      \u001B[32m0.9638\u001B[0m        \u001B[35m0.2266\u001B[0m  0.0617\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4875\u001B[0m      \u001B[32m0.4271\u001B[0m        \u001B[35m1.6835\u001B[0m  0.0619\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.4345\u001B[0m  0.0615\n",
      "      3      0.6162      0.4699        \u001B[35m1.1876\u001B[0m  0.0619\n",
      "      4      0.6162      0.4699        \u001B[35m1.0198\u001B[0m  0.0638\n",
      "      5      \u001B[36m0.6200\u001B[0m      \u001B[32m0.4784\u001B[0m        \u001B[35m0.8853\u001B[0m  0.0612\n",
      "      6      \u001B[36m0.6950\u001B[0m      \u001B[32m0.6150\u001B[0m        \u001B[35m0.7368\u001B[0m  0.0590\n",
      "      7      \u001B[36m0.8113\u001B[0m      \u001B[32m0.7701\u001B[0m        \u001B[35m0.5799\u001B[0m  0.0604\n",
      "      8      \u001B[36m0.8862\u001B[0m      \u001B[32m0.8697\u001B[0m        \u001B[35m0.4332\u001B[0m  0.0638\n",
      "      9      \u001B[36m0.9450\u001B[0m      \u001B[32m0.9397\u001B[0m        \u001B[35m0.3156\u001B[0m  0.0612\n",
      "     10      \u001B[36m0.9700\u001B[0m      \u001B[32m0.9678\u001B[0m        \u001B[35m0.2308\u001B[0m  0.0645\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5000\u001B[0m      \u001B[32m0.4306\u001B[0m        \u001B[35m1.7142\u001B[0m  0.0576\n",
      "      2      \u001B[36m0.6150\u001B[0m      \u001B[32m0.4684\u001B[0m        \u001B[35m1.4531\u001B[0m  0.0602\n",
      "      3      0.6150      0.4684        \u001B[35m1.1914\u001B[0m  0.0598\n",
      "      4      0.6150      0.4684        \u001B[35m1.0185\u001B[0m  0.0590\n",
      "      5      \u001B[36m0.6238\u001B[0m      \u001B[32m0.4879\u001B[0m        \u001B[35m0.8710\u001B[0m  0.0616\n",
      "      6      \u001B[36m0.7400\u001B[0m      \u001B[32m0.6834\u001B[0m        \u001B[35m0.7091\u001B[0m  0.0603\n",
      "      7      \u001B[36m0.8588\u001B[0m      \u001B[32m0.8348\u001B[0m        \u001B[35m0.5446\u001B[0m  0.0598\n",
      "      8      \u001B[36m0.9237\u001B[0m      \u001B[32m0.9117\u001B[0m        \u001B[35m0.3996\u001B[0m  0.0605\n",
      "      9      \u001B[36m0.9550\u001B[0m      \u001B[32m0.9499\u001B[0m        \u001B[35m0.2890\u001B[0m  0.0590\n",
      "     10      \u001B[36m0.9725\u001B[0m      \u001B[32m0.9705\u001B[0m        \u001B[35m0.2112\u001B[0m  0.0595\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5363\u001B[0m      \u001B[32m0.4588\u001B[0m        \u001B[35m1.6754\u001B[0m  0.0577\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.4441\u001B[0m  0.0623\n",
      "      3      0.6162      0.4699        \u001B[35m1.1959\u001B[0m  0.0598\n",
      "      4      0.6162      0.4699        \u001B[35m1.0136\u001B[0m  0.0605\n",
      "      5      \u001B[36m0.6288\u001B[0m      \u001B[32m0.4974\u001B[0m        \u001B[35m0.8594\u001B[0m  0.0598\n",
      "      6      \u001B[36m0.7412\u001B[0m      \u001B[32m0.6830\u001B[0m        \u001B[35m0.6906\u001B[0m  0.0595\n",
      "      7      \u001B[36m0.8612\u001B[0m      \u001B[32m0.8388\u001B[0m        \u001B[35m0.5221\u001B[0m  0.0592\n",
      "      8      \u001B[36m0.9225\u001B[0m      \u001B[32m0.9104\u001B[0m        \u001B[35m0.3785\u001B[0m  0.0613\n",
      "      9      \u001B[36m0.9600\u001B[0m      \u001B[32m0.9551\u001B[0m        \u001B[35m0.2723\u001B[0m  0.0603\n",
      "     10      \u001B[36m0.9762\u001B[0m      \u001B[32m0.9739\u001B[0m        \u001B[35m0.1987\u001B[0m  0.0597\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.3800\u001B[0m      \u001B[32m0.3885\u001B[0m        \u001B[35m1.7310\u001B[0m  0.0577\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4699\u001B[0m        \u001B[35m1.4653\u001B[0m  0.0640\n",
      "      3      0.6162      0.4699        \u001B[35m1.1944\u001B[0m  0.0674\n",
      "      4      0.6162      0.4699        \u001B[35m1.0145\u001B[0m  0.0619\n",
      "      5      \u001B[36m0.6225\u001B[0m      \u001B[32m0.4839\u001B[0m        \u001B[35m0.8676\u001B[0m  0.0614\n",
      "      6      \u001B[36m0.7262\u001B[0m      \u001B[32m0.6594\u001B[0m        \u001B[35m0.7104\u001B[0m  0.0601\n",
      "      7      \u001B[36m0.8425\u001B[0m      \u001B[32m0.8088\u001B[0m        \u001B[35m0.5507\u001B[0m  0.0603\n",
      "      8      \u001B[36m0.9250\u001B[0m      \u001B[32m0.9128\u001B[0m        \u001B[35m0.4059\u001B[0m  0.0629\n",
      "      9      \u001B[36m0.9500\u001B[0m      \u001B[32m0.9439\u001B[0m        \u001B[35m0.2928\u001B[0m  0.0606\n",
      "     10      \u001B[36m0.9675\u001B[0m      \u001B[32m0.9638\u001B[0m        \u001B[35m0.2132\u001B[0m  0.0606\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5437\u001B[0m      \u001B[32m0.4474\u001B[0m        \u001B[35m1.4077\u001B[0m  0.0460\n",
      "      2      \u001B[36m0.6875\u001B[0m      \u001B[32m0.6047\u001B[0m        \u001B[35m0.8130\u001B[0m  0.0507\n",
      "      3      \u001B[36m0.9563\u001B[0m      \u001B[32m0.9493\u001B[0m        \u001B[35m0.2230\u001B[0m  0.0477\n",
      "      4      \u001B[36m0.9962\u001B[0m      \u001B[32m0.9962\u001B[0m        \u001B[35m0.0329\u001B[0m  0.0456\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0094\u001B[0m  0.0485\n",
      "      6      1.0000      1.0000        \u001B[35m0.0044\u001B[0m  0.0483\n",
      "      7      1.0000      1.0000        \u001B[35m0.0028\u001B[0m  0.0531\n",
      "      8      1.0000      1.0000        \u001B[35m0.0020\u001B[0m  0.0566\n",
      "      9      1.0000      1.0000        \u001B[35m0.0016\u001B[0m  0.0542\n",
      "     10      1.0000      1.0000        \u001B[35m0.0013\u001B[0m  0.0523\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5675\u001B[0m      \u001B[32m0.4592\u001B[0m        \u001B[35m1.3643\u001B[0m  0.0484\n",
      "      2      \u001B[36m0.7075\u001B[0m      \u001B[32m0.6366\u001B[0m        \u001B[35m0.7806\u001B[0m  0.0514\n",
      "      3      \u001B[36m0.9563\u001B[0m      \u001B[32m0.9517\u001B[0m        \u001B[35m0.2348\u001B[0m  0.0497\n",
      "      4      \u001B[36m0.9962\u001B[0m      \u001B[32m0.9962\u001B[0m        \u001B[35m0.0396\u001B[0m  0.0505\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0116\u001B[0m  0.0475\n",
      "      6      1.0000      1.0000        \u001B[35m0.0055\u001B[0m  0.0475\n",
      "      7      1.0000      1.0000        \u001B[35m0.0034\u001B[0m  0.0478\n",
      "      8      1.0000      1.0000        \u001B[35m0.0024\u001B[0m  0.0509\n",
      "      9      1.0000      1.0000        \u001B[35m0.0019\u001B[0m  0.0485\n",
      "     10      1.0000      1.0000        \u001B[35m0.0015\u001B[0m  0.0503\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5850\u001B[0m      \u001B[32m0.4576\u001B[0m        \u001B[35m1.3611\u001B[0m  0.0453\n",
      "      2      \u001B[36m0.7250\u001B[0m      \u001B[32m0.6603\u001B[0m        \u001B[35m0.7758\u001B[0m  0.0479\n",
      "      3      \u001B[36m0.9525\u001B[0m      \u001B[32m0.9469\u001B[0m        \u001B[35m0.2263\u001B[0m  0.0476\n",
      "      4      \u001B[36m0.9950\u001B[0m      \u001B[32m0.9948\u001B[0m        \u001B[35m0.0395\u001B[0m  0.0493\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0110\u001B[0m  0.0537\n",
      "      6      1.0000      1.0000        \u001B[35m0.0050\u001B[0m  0.0482\n",
      "      7      1.0000      1.0000        \u001B[35m0.0031\u001B[0m  0.0494\n",
      "      8      1.0000      1.0000        \u001B[35m0.0023\u001B[0m  0.0496\n",
      "      9      1.0000      1.0000        \u001B[35m0.0018\u001B[0m  0.0473\n",
      "     10      1.0000      1.0000        \u001B[35m0.0015\u001B[0m  0.0490\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5663\u001B[0m      \u001B[32m0.4585\u001B[0m        \u001B[35m1.3958\u001B[0m  0.0479\n",
      "      2      \u001B[36m0.7238\u001B[0m      \u001B[32m0.6594\u001B[0m        \u001B[35m0.7732\u001B[0m  0.0470\n",
      "      3      \u001B[36m0.9750\u001B[0m      \u001B[32m0.9705\u001B[0m        \u001B[35m0.2284\u001B[0m  0.0489\n",
      "      4      \u001B[36m0.9975\u001B[0m      \u001B[32m0.9974\u001B[0m        \u001B[35m0.0399\u001B[0m  0.0476\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0113\u001B[0m  0.0491\n",
      "      6      1.0000      1.0000        \u001B[35m0.0051\u001B[0m  0.0475\n",
      "      7      1.0000      1.0000        \u001B[35m0.0031\u001B[0m  0.0474\n",
      "      8      1.0000      1.0000        \u001B[35m0.0022\u001B[0m  0.0539\n",
      "      9      1.0000      1.0000        \u001B[35m0.0017\u001B[0m  0.0477\n",
      "     10      1.0000      1.0000        \u001B[35m0.0014\u001B[0m  0.0485\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5737\u001B[0m      \u001B[32m0.4676\u001B[0m        \u001B[35m1.3772\u001B[0m  0.0456\n",
      "      2      \u001B[36m0.7225\u001B[0m      \u001B[32m0.6582\u001B[0m        \u001B[35m0.7628\u001B[0m  0.0564\n",
      "      3      \u001B[36m0.9475\u001B[0m      \u001B[32m0.9381\u001B[0m        \u001B[35m0.2337\u001B[0m  0.0477\n",
      "      4      \u001B[36m0.9938\u001B[0m      \u001B[32m0.9935\u001B[0m        \u001B[35m0.0415\u001B[0m  0.0504\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0113\u001B[0m  0.0477\n",
      "      6      1.0000      1.0000        \u001B[35m0.0050\u001B[0m  0.0476\n",
      "      7      1.0000      1.0000        \u001B[35m0.0031\u001B[0m  0.0485\n",
      "      8      1.0000      1.0000        \u001B[35m0.0022\u001B[0m  0.0496\n",
      "      9      1.0000      1.0000        \u001B[35m0.0017\u001B[0m  0.0477\n",
      "     10      1.0000      1.0000        \u001B[35m0.0014\u001B[0m  0.0478\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.6025\u001B[0m      \u001B[32m0.4674\u001B[0m        \u001B[35m1.3191\u001B[0m  0.0579\n",
      "      2      \u001B[36m0.8113\u001B[0m      \u001B[32m0.7689\u001B[0m        \u001B[35m0.5981\u001B[0m  0.0617\n",
      "      3      \u001B[36m0.9888\u001B[0m      \u001B[32m0.9883\u001B[0m        \u001B[35m0.0860\u001B[0m  0.0597\n",
      "      4      \u001B[36m0.9988\u001B[0m      \u001B[32m0.9987\u001B[0m        \u001B[35m0.0129\u001B[0m  0.0599\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0043\u001B[0m  0.0603\n",
      "      6      1.0000      1.0000        \u001B[35m0.0020\u001B[0m  0.0631\n",
      "      7      1.0000      1.0000        \u001B[35m0.0013\u001B[0m  0.0611\n",
      "      8      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0644\n",
      "      9      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0613\n",
      "     10      1.0000      1.0000        \u001B[35m0.0006\u001B[0m  0.0607\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5663\u001B[0m      \u001B[32m0.4565\u001B[0m        \u001B[35m1.3426\u001B[0m  0.0584\n",
      "      2      \u001B[36m0.8113\u001B[0m      \u001B[32m0.7756\u001B[0m        \u001B[35m0.5981\u001B[0m  0.0621\n",
      "      3      \u001B[36m0.9862\u001B[0m      \u001B[32m0.9856\u001B[0m        \u001B[35m0.0898\u001B[0m  0.0614\n",
      "      4      \u001B[36m0.9975\u001B[0m      \u001B[32m0.9975\u001B[0m        \u001B[35m0.0139\u001B[0m  0.0597\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0047\u001B[0m  0.0611\n",
      "      6      1.0000      1.0000        \u001B[35m0.0022\u001B[0m  0.0603\n",
      "      7      1.0000      1.0000        \u001B[35m0.0014\u001B[0m  0.0600\n",
      "      8      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0607\n",
      "      9      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0603\n",
      "     10      1.0000      1.0000        \u001B[35m0.0007\u001B[0m  0.0615\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5550\u001B[0m      \u001B[32m0.4485\u001B[0m        \u001B[35m1.3558\u001B[0m  0.0583\n",
      "      2      \u001B[36m0.8200\u001B[0m      \u001B[32m0.7857\u001B[0m        \u001B[35m0.6016\u001B[0m  0.0664\n",
      "      3      \u001B[36m0.9862\u001B[0m      \u001B[32m0.9850\u001B[0m        \u001B[35m0.0914\u001B[0m  0.0601\n",
      "      4      \u001B[36m0.9975\u001B[0m      \u001B[32m0.9975\u001B[0m        \u001B[35m0.0141\u001B[0m  0.0608\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0041\u001B[0m  0.0602\n",
      "      6      1.0000      1.0000        \u001B[35m0.0019\u001B[0m  0.0612\n",
      "      7      1.0000      1.0000        \u001B[35m0.0013\u001B[0m  0.0602\n",
      "      8      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0596\n",
      "      9      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0598\n",
      "     10      1.0000      1.0000        \u001B[35m0.0006\u001B[0m  0.0595\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5925\u001B[0m      \u001B[32m0.4637\u001B[0m        \u001B[35m1.3190\u001B[0m  0.0587\n",
      "      2      \u001B[36m0.8125\u001B[0m      \u001B[32m0.7722\u001B[0m        \u001B[35m0.6037\u001B[0m  0.0607\n",
      "      3      \u001B[36m0.9888\u001B[0m      \u001B[32m0.9878\u001B[0m        \u001B[35m0.1037\u001B[0m  0.0604\n",
      "      4      \u001B[36m0.9975\u001B[0m      \u001B[32m0.9975\u001B[0m        \u001B[35m0.0147\u001B[0m  0.0618\n",
      "      5      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0048\u001B[0m  0.0623\n",
      "      6      1.0000      1.0000        \u001B[35m0.0019\u001B[0m  0.0649\n",
      "      7      1.0000      1.0000        \u001B[35m0.0012\u001B[0m  0.0604\n",
      "      8      1.0000      1.0000        \u001B[35m0.0009\u001B[0m  0.0606\n",
      "      9      1.0000      1.0000        \u001B[35m0.0007\u001B[0m  0.0604\n",
      "     10      1.0000      1.0000        \u001B[35m0.0006\u001B[0m  0.0621\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5637\u001B[0m      \u001B[32m0.4527\u001B[0m        \u001B[35m1.3459\u001B[0m  0.0601\n",
      "      2      \u001B[36m0.8475\u001B[0m      \u001B[32m0.8190\u001B[0m        \u001B[35m0.5798\u001B[0m  0.0620\n",
      "      3      \u001B[36m0.9825\u001B[0m      \u001B[32m0.9815\u001B[0m        \u001B[35m0.0898\u001B[0m  0.0605\n",
      "      4      \u001B[36m1.0000\u001B[0m      \u001B[32m1.0000\u001B[0m        \u001B[35m0.0133\u001B[0m  0.0586\n",
      "      5      1.0000      1.0000        \u001B[35m0.0044\u001B[0m  0.0604\n",
      "      6      1.0000      1.0000        \u001B[35m0.0021\u001B[0m  0.0613\n",
      "      7      1.0000      1.0000        \u001B[35m0.0014\u001B[0m  0.0605\n",
      "      8      1.0000      1.0000        \u001B[35m0.0010\u001B[0m  0.0624\n",
      "      9      1.0000      1.0000        \u001B[35m0.0008\u001B[0m  0.0609\n",
      "     10      1.0000      1.0000        \u001B[35m0.0007\u001B[0m  0.0603\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=LSTMModel(\n",
       "    (lstm): LSTM(7342, 64, batch_first=True)\n",
       "    (fc): Linear(in_features=64, out_features=6, bias=True)\n",
       "  ),\n",
       "),\n",
       "             param_grid={'batch_size': [32, 64], 'lr': [0.001, 0.01],\n",
       "                         'max_epochs': [10], 'module__hidden_dim': [64, 128]},\n",
       "             refit=False, scoring='accuracy')"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# infer suited parameters from es_pytorch_active_learning and run smaller hyperparameter search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_epochs': [10],\n",
    "    'batch_size':[32, 64],\n",
    "    'lr': [0.001, 0.01],\n",
    "    'module__hidden_dim': [64, 128],\n",
    "}\n",
    "gs = GridSearchCV(classifier, params, refit=False, cv=5, scoring='accuracy')\n",
    "\n",
    "gs.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G977iYEep2DI",
    "outputId": "b404364a-e239-4771-ecc8-91eeb1500f6e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "gs.best_score_  0.634 \n",
      "gs.best_params_ {'batch_size': 32, 'lr': 0.001, 'max_epochs': 10, 'module__hidden_dim': 128}\n"
     ]
    }
   ],
   "source": [
    "print('\\ngs.best_score_ ', gs.best_score_, '\\ngs.best_params_', gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kokQy6x3p2DJ",
    "outputId": "33247700-cc95-43b1-9b02-f4229a0dbf1a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4570\u001B[0m      \u001B[32m0.4290\u001B[0m        \u001B[35m1.6500\u001B[0m  0.1943\n",
      "      2      \u001B[36m0.6160\u001B[0m      \u001B[32m0.4696\u001B[0m        \u001B[35m1.1836\u001B[0m  0.0883\n",
      "      3      \u001B[36m0.6180\u001B[0m      \u001B[32m0.4742\u001B[0m        \u001B[35m0.9477\u001B[0m  0.0886\n",
      "      4      \u001B[36m0.7440\u001B[0m      \u001B[32m0.6872\u001B[0m        \u001B[35m0.6797\u001B[0m  0.0863\n",
      "      5      \u001B[36m0.9030\u001B[0m      \u001B[32m0.8869\u001B[0m        \u001B[35m0.4022\u001B[0m  0.0868\n",
      "      6      \u001B[36m0.9610\u001B[0m      \u001B[32m0.9566\u001B[0m        \u001B[35m0.2261\u001B[0m  0.0874\n",
      "      7      \u001B[36m0.9800\u001B[0m      \u001B[32m0.9791\u001B[0m        \u001B[35m0.1360\u001B[0m  0.0868\n",
      "      8      \u001B[36m0.9910\u001B[0m      \u001B[32m0.9908\u001B[0m        \u001B[35m0.0891\u001B[0m  0.0882\n",
      "      9      \u001B[36m0.9930\u001B[0m      \u001B[32m0.9928\u001B[0m        \u001B[35m0.0625\u001B[0m  0.0878\n",
      "     10      \u001B[36m0.9960\u001B[0m      \u001B[32m0.9960\u001B[0m        \u001B[35m0.0461\u001B[0m  0.0865\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=LSTMModel(\n",
       "    (lstm): LSTM(7342, 128, batch_first=True)\n",
       "    (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# refit with optimal parameters\n",
    "\n",
    "classifier = NeuralNetClassifier(module=LSTMModel,\n",
    "                                 module__hidden_dim = 128,\n",
    "                                 batch_size=32,\n",
    "                                 max_epochs= 10,\n",
    "                                 criterion=nn.CrossEntropyLoss,\n",
    "                                 optimizer=torch.optim.Adam,\n",
    "                                 lr=0.001,\n",
    "                                 train_split=None,\n",
    "                                 callbacks=callbacks,\n",
    "                                 #callbacks__train_loss=None,\n",
    "                                 verbose=1,\n",
    "                                 device=device)\n",
    "\n",
    "classifier.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vlbYtszp2DJ",
    "outputId": "35becd21-d6ed-44b7-dac9-9faebe90f36c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        expl       0.67      0.95      0.79       155\n",
      "       fixed       0.00      0.00      0.00         2\n",
      "        iobj       0.00      0.00      0.00         2\n",
      "        mark       0.71      0.16      0.26        31\n",
      "       nsubj       0.23      0.12      0.15        43\n",
      "         obj       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.63       251\n",
      "   macro avg       0.27      0.21      0.20       251\n",
      "weighted avg       0.54      0.63      0.54       251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "targets = label_encoder.classes_\n",
    "\n",
    "y_pred_test = classifier.predict(test_features)\n",
    "print(classification_report(test_labels, y_pred_test, target_names=targets, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLgsxuAwp2DJ"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzMdeiEpp2DK"
   },
   "source": [
    "## 3) Active Learner"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_features = train_features.detach().cpu().numpy()\n",
    "train_labels = train_labels.detach().cpu().numpy()"
   ],
   "metadata": {
    "id": "TxlojtZOxKiO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLc1PJUgp2DK",
    "outputId": "a002f1ad-488d-4310-dbbb-74a9ee75b992"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5500\u001B[0m      \u001B[32m0.4698\u001B[0m        \u001B[35m1.5926\u001B[0m  0.0871\n",
      "      2      \u001B[36m0.6160\u001B[0m      0.4696        \u001B[35m1.1458\u001B[0m  0.0910\n",
      "      3      \u001B[36m0.6180\u001B[0m      \u001B[32m0.4742\u001B[0m        \u001B[35m0.9364\u001B[0m  0.0900\n",
      "      4      \u001B[36m0.7310\u001B[0m      \u001B[32m0.6702\u001B[0m        \u001B[35m0.6838\u001B[0m  0.0913\n",
      "      5      \u001B[36m0.8990\u001B[0m      \u001B[32m0.8831\u001B[0m        \u001B[35m0.4106\u001B[0m  0.0907\n",
      "      6      \u001B[36m0.9600\u001B[0m      \u001B[32m0.9557\u001B[0m        \u001B[35m0.2297\u001B[0m  0.0903\n",
      "      7      \u001B[36m0.9820\u001B[0m      \u001B[32m0.9810\u001B[0m        \u001B[35m0.1372\u001B[0m  0.0891\n",
      "      8      \u001B[36m0.9890\u001B[0m      \u001B[32m0.9885\u001B[0m        \u001B[35m0.0894\u001B[0m  0.0888\n",
      "      9      \u001B[36m0.9940\u001B[0m      \u001B[32m0.9939\u001B[0m        \u001B[35m0.0626\u001B[0m  0.0912\n",
      "     10      \u001B[36m0.9950\u001B[0m      \u001B[32m0.9949\u001B[0m        \u001B[35m0.0461\u001B[0m  0.0852\n"
     ]
    }
   ],
   "source": [
    "# no training arguments because classifier is already fitted\n",
    "learner = ActiveLearner(estimator=classifier,\n",
    "                        query_strategy=uncertainty_sampling,\n",
    "                        X_training=train_features,\n",
    "                        y_training=train_labels,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "lgqDsiAPwW1H"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wCn2vA3ep2DK"
   },
   "outputs": [],
   "source": [
    "n_instances = 3\n",
    "# n_instances = 20\n",
    "accuracies = [learner.score(test_features, test_labels)] # append first accuracy without learning\n",
    "pool_sent_list= list() # store annotated sentences and the labels\n",
    "pool_label_list= list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWTyhVKFp2DK"
   },
   "source": [
    "### Loop\n",
    "- stops after 20 iterations\n",
    "- prompt sentence\n",
    "\n",
    "Problem: if annotation is 'None' (e.g in the case a sentence is discarded) the loop breaks. We have to discard certain sentences because when creating the underlying corpus\n",
    "phrases that do not contain 'se' like 'aunque a tu mac no le pase nada' were not discarded because there is no suited programmatical way to differentiate btw. 'pase' and 'siéntese'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "o8LjOxFZp2DL"
   },
   "outputs": [],
   "source": [
    "number_of_loops = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8eJhW4Ap2DL",
    "outputId": "511734bf-1e34-447d-a84e-38782199e60f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "loop: 1\n",
      "sentence: 1\n",
      "The learners predictions are:\n",
      "[('expl', 0.23), ('mark', 0.2), ('nsubj', 0.18), ('fixed', 0.15), ('obj', 0.14), ('iobj', 0.09)]\n",
      "\n",
      "E começar a agir como se estivesse já lá !\n",
      "expl\n",
      "\n",
      "loop: 1\n",
      "sentence: 2\n",
      "The learners predictions are:\n",
      "[('expl', 0.23), ('obj', 0.22), ('mark', 0.21), ('fixed', 0.14), ('nsubj', 0.11), ('iobj', 0.09)]\n",
      "\n",
      "Então é como se você lá estivesse . \"\n",
      "expl\n",
      "\n",
      "loop: 1\n",
      "sentence: 3\n",
      "The learners predictions are:\n",
      "[('fixed', 0.23), ('mark', 0.18), ('expl', 0.16), ('nsubj', 0.16), ('obj', 0.15), ('iobj', 0.1)]\n",
      "\n",
      "Ou pior , vender como se fosse uma guitarra de luthier fabricada a mão .\n",
      "fixed\n",
      "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.5932\u001B[0m      \u001B[32m0.4642\u001B[0m        \u001B[35m1.5841\u001B[0m  0.0886\n",
      "      2      \u001B[36m0.6162\u001B[0m      \u001B[32m0.4698\u001B[0m        \u001B[35m1.1581\u001B[0m  0.0894\n",
      "      3      \u001B[36m0.6171\u001B[0m      \u001B[32m0.4721\u001B[0m        \u001B[35m0.9452\u001B[0m  0.0857\n",
      "      4      \u001B[36m0.7278\u001B[0m      \u001B[32m0.6658\u001B[0m        \u001B[35m0.6939\u001B[0m  0.0880\n",
      "      5      \u001B[36m0.9063\u001B[0m      \u001B[32m0.8916\u001B[0m        \u001B[35m0.4180\u001B[0m  0.0876\n",
      "      6      \u001B[36m0.9551\u001B[0m      \u001B[32m0.9501\u001B[0m        \u001B[35m0.2345\u001B[0m  0.0877\n",
      "      7      \u001B[36m0.9791\u001B[0m      \u001B[32m0.9777\u001B[0m        \u001B[35m0.1406\u001B[0m  0.0888\n",
      "      8      \u001B[36m0.9900\u001B[0m      \u001B[32m0.9898\u001B[0m        \u001B[35m0.0921\u001B[0m  0.0887\n",
      "      9      \u001B[36m0.9930\u001B[0m      \u001B[32m0.9929\u001B[0m        \u001B[35m0.0647\u001B[0m  0.0874\n",
      "     10      \u001B[36m0.9950\u001B[0m      \u001B[32m0.9950\u001B[0m        \u001B[35m0.0479\u001B[0m  0.0920\n",
      "\n",
      "loop: 2\n",
      "sentence: 1\n",
      "The learners predictions are:\n",
      "[('expl', 0.22), ('mark', 0.21), ('nsubj', 0.21), ('obj', 0.21), ('fixed', 0.1), ('iobj', 0.04)]\n",
      "\n",
      "Senti um suspiro agora mesmo e te o sentindo um negocio em a orelha como se ele estivesse olhando eu escrever .\n",
      "expl\n",
      "\n",
      "loop: 2\n",
      "sentence: 2\n",
      "The learners predictions are:\n",
      "[('expl', 0.23), ('nsubj', 0.22), ('obj', 0.18), ('mark', 0.16), ('fixed', 0.13), ('iobj', 0.09)]\n",
      "\n",
      "Depois que o fenômeno de o neopentecostalismo e seus escândalos fizeram a entrega de dinheiro para igrejas tornar se uma atitude questionável e suspeita , pela primeira vez em a história eclodiu entre os próprios cristãos a ideia de que poderiam não entregar o dízimo .\n",
      "expl\n",
      "\n",
      "loop: 2\n",
      "sentence: 3\n",
      "The learners predictions are:\n",
      "[('expl', 0.23), ('mark', 0.22), ('obj', 0.21), ('nsubj', 0.18), ('fixed', 0.08), ('iobj', 0.08)]\n",
      "\n",
      "Uma de as formas de descobrir se você tem mau hálito é lamber o interior de seu pulso , esperar cinco segundos e então dar uma baforada .\n",
      "expl\n",
      "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4751\u001B[0m      \u001B[32m0.4263\u001B[0m        \u001B[35m1.6415\u001B[0m  0.0886\n",
      "      2      \u001B[36m0.6173\u001B[0m      \u001B[32m0.4712\u001B[0m        \u001B[35m1.1697\u001B[0m  0.0881\n",
      "      3      0.6173      0.4712        \u001B[35m0.9534\u001B[0m  0.0871\n",
      "      4      \u001B[36m0.7217\u001B[0m      \u001B[32m0.6567\u001B[0m        \u001B[35m0.7062\u001B[0m  0.0868\n",
      "      5      \u001B[36m0.8837\u001B[0m      \u001B[32m0.8635\u001B[0m        \u001B[35m0.4321\u001B[0m  0.0880\n",
      "      6      \u001B[36m0.9513\u001B[0m      \u001B[32m0.9462\u001B[0m        \u001B[35m0.2445\u001B[0m  0.0908\n",
      "      7      \u001B[36m0.9801\u001B[0m      \u001B[32m0.9791\u001B[0m        \u001B[35m0.1466\u001B[0m  0.0875\n",
      "      8      \u001B[36m0.9881\u001B[0m      \u001B[32m0.9878\u001B[0m        \u001B[35m0.0956\u001B[0m  0.0901\n",
      "      9      \u001B[36m0.9911\u001B[0m      \u001B[32m0.9908\u001B[0m        \u001B[35m0.0670\u001B[0m  0.0885\n",
      "     10      \u001B[36m0.9950\u001B[0m      \u001B[32m0.9950\u001B[0m        \u001B[35m0.0496\u001B[0m  0.0896\n",
      "\n",
      "loop: 3\n",
      "sentence: 1\n",
      "The learners predictions are:\n",
      "[('expl', 0.22), ('mark', 0.22), ('nsubj', 0.2), ('obj', 0.18), ('fixed', 0.1), ('iobj', 0.07)]\n",
      "\n",
      "EVANGELHO MT 20 , 1-16ª Em aquele tempo , disse Jesus a os seus discípulos a seguinte parábola : « O reino de os Céus pode comparar se a um proprietário , que saiu muito cedo a contratar trabalhadores para a sua vinha .\n",
      "mark\n",
      "\n",
      "loop: 3\n",
      "sentence: 2\n",
      "The learners predictions are:\n",
      "[('expl', 0.22), ('fixed', 0.21), ('nsubj', 0.17), ('obj', 0.17), ('mark', 0.12), ('iobj', 0.11)]\n",
      "\n",
      "Mas , se alguém me perguntasse o que deverá ser doce , talvez não saiba responder .\n",
      "fixed\n",
      "\n",
      "loop: 3\n",
      "sentence: 3\n",
      "The learners predictions are:\n",
      "[('mark', 0.24), ('expl', 0.23), ('fixed', 0.2), ('nsubj', 0.17), ('iobj', 0.1), ('obj', 0.06)]\n",
      "\n",
      "Cada um se protege em uma trincheira cheia de munições : mágoas , ressentimentos , tudo isso lançado contra o outro .\n",
      "mark\n",
      "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    accuracy    f1-score    train_loss     dur\n",
      "-------  ----------  ----------  ------------  ------\n",
      "      1      \u001B[36m0.4747\u001B[0m      \u001B[32m0.4353\u001B[0m        \u001B[35m1.6573\u001B[0m  0.0887\n",
      "      2      \u001B[36m0.6155\u001B[0m      \u001B[32m0.4690\u001B[0m        \u001B[35m1.1754\u001B[0m  0.0906\n",
      "      3      0.6155      0.4690        \u001B[35m0.9508\u001B[0m  0.0867\n",
      "      4      \u001B[36m0.7215\u001B[0m      \u001B[32m0.6562\u001B[0m        \u001B[35m0.6932\u001B[0m  0.0883\n",
      "      5      \u001B[36m0.8930\u001B[0m      \u001B[32m0.8769\u001B[0m        \u001B[35m0.4184\u001B[0m  0.0875\n",
      "      6      \u001B[36m0.9574\u001B[0m      \u001B[32m0.9533\u001B[0m        \u001B[35m0.2382\u001B[0m  0.0889\n",
      "      7      \u001B[36m0.9782\u001B[0m      \u001B[32m0.9764\u001B[0m        \u001B[35m0.1449\u001B[0m  0.0879\n",
      "      8      \u001B[36m0.9901\u001B[0m      \u001B[32m0.9899\u001B[0m        \u001B[35m0.0955\u001B[0m  0.0898\n",
      "      9      \u001B[36m0.9931\u001B[0m      \u001B[32m0.9929\u001B[0m        \u001B[35m0.0672\u001B[0m  0.0874\n",
      "     10      \u001B[36m0.9950\u001B[0m      \u001B[32m0.9950\u001B[0m        \u001B[35m0.0496\u001B[0m  0.0872\n"
     ]
    }
   ],
   "source": [
    "for i in range(number_of_loops):# annotate 10 times 20 instances\n",
    "\n",
    "    # query new instances\n",
    "    query_idx, query_inst = learner.query(X_pool, n_instances=n_instances)\n",
    "    predicted_proba = get_learners_preds(learner.predict_proba(X_pool[query_idx]))\n",
    "    sentences = pool.text.iloc[query_idx]\n",
    "\n",
    "    # annotate the queried instances\n",
    "    annotation = list()\n",
    "    counter = 0\n",
    "    for sent, proba in zip(sentences, predicted_proba):\n",
    "        counter += 1\n",
    "        sorted_proba = sorted(proba.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        prompt = '\\n'+'loop: '+str(i+1)+'\\n'+'sentence: '+str(counter)+'\\n'+'The learners predictions are:'+'\\n'+str(sorted_proba)+'\\n\\n'+sent+'\\n'\n",
    "        label = str(input(prompt))\n",
    "        annotation.append(label)\n",
    "\n",
    "    # keep track of annotations\n",
    "    sent_list = sentences.to_list()\n",
    "    pool_sent_list.append(sent_list)\n",
    "    pool_label_list.append(annotation)\n",
    "\n",
    "    # filter out sentences that were assigned 'None'; the learner should not see them\n",
    "    if 'None' in annotation:\n",
    "        print('Note: you either discarded samples or did not annotate all samples')\n",
    "        discarded_idxs=[idx for idx, sample in enumerate(annotation) if sample == 'None'] # TODO\n",
    "        discarded_idxs = sorted(discarded_idxs, reverse=True)\n",
    "        for index in discarded_idxs:\n",
    "            query_inst = np.delete(query_inst, index, axis=0)\n",
    "        annotation = list(filter('None'.__ne__, annotation))\n",
    "\n",
    "\n",
    "    # teach the learner\n",
    "    y_pool = label_encoder.transform(annotation)\n",
    "    learner.teach(query_inst, y_pool)\n",
    "    accuracies.append(learner.score(X=test_features, y=test_labels))\n",
    "\n",
    "    # delete queried instances from pool\n",
    "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "fUUAjbblp2DL",
    "outputId": "1a0bd35b-7134-42ec-f514-a8e54bae702a"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# plot learning curve\n",
    "with plt.style.context('bmh'):\n",
    "    csfont = {'fontname':'Times New Roman'}\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(range(number_of_loops+1), accuracies)\n",
    "    plt.scatter(range(number_of_loops+1), accuracies)\n",
    "    plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20, **csfont)\n",
    "    plt.xticks(np.arange(0, 11, 1), fontsize=20, **csfont)\n",
    "    plt.xlabel('loop number',fontsize=24, **csfont)\n",
    "    plt.ylabel('accuracy',fontsize=24, **csfont)\n",
    "    plt.savefig('al_plots/pt_pytorch.png')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8nKkOG8p2DM",
    "outputId": "c1be8aea-ca9c-4fe9-95e4-51ce5584a03e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6294820717131474"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "max(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lG4heVnXp2DM",
    "outputId": "7ecfe2de-41b4-4d2f-94c8-92b78bd3a00d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(9, 2)\n",
      "                                                text se_label\n",
      "0         E começar a agir como se estivesse já lá !     expl\n",
      "1              Então é como se você lá estivesse . \"     expl\n",
      "2  Ou pior , vender como se fosse uma guitarra de...    fixed\n",
      "3  Senti um suspiro agora mesmo e te o sentindo u...     expl\n",
      "4  Depois que o fenômeno de o neopentecostalismo ...     expl\n"
     ]
    }
   ],
   "source": [
    "# create df from annotations\n",
    "sent_flattened = get_flattened_list(pool_sent_list)\n",
    "label_flattened = get_flattened_list(pool_label_list)\n",
    "\n",
    "labeled_pool = pd.DataFrame(list(zip(sent_flattened, label_flattened)),\n",
    "               columns =['text', 'se_label'])\n",
    "print(labeled_pool.shape)\n",
    "print(labeled_pool.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RN_SSf6_p2DM"
   },
   "outputs": [],
   "source": [
    "# save labeled pool\n",
    "labeled_pool.to_csv('labeled_data/pt_pytorch_annotations.txt', header=None, index=False,  sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "pt_pytorch_active_learning.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}