{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxhof905/se_corpus/blob/main/task/scripts/es_pytorch_active_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivIzeaGXnivx"
      },
      "source": [
        "# Pytoch active learning loop: Spanish\n",
        "\n",
        "maxhof905"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg8Akxmonivz"
      },
      "source": [
        "\n",
        "sources :\n",
        "- https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
        "- https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/#step-2-make-dataset-iterable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJzzVVH6oIZw",
        "outputId": "b5332e32-88ad-449c-aa50-2a11c111b4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6DcSBGOniv2"
      },
      "source": [
        "## 1) Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRvyIvtCniv1",
        "outputId": "117033c0-5ea0-4a31-e4fd-eb7efcf38cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20 kB 31.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 155 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.1.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.11.0\n",
            "Collecting modal\n",
            "  Downloading modAL-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from modal) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from modal) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from modal) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from modal) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modal) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->modal) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modal) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modal) (1.1.0)\n",
            "Installing collected packages: modal\n",
            "Successfully installed modal-0.4.1\n"
          ]
        }
      ],
      "source": [
        "# installations for colab\n",
        "!pip install skorch\n",
        "!pip install modal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AHsU2Vjzniv3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.callbacks import EpochScoring\n",
        "\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gonCBBoWniv4"
      },
      "source": [
        "## 2) helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aw7aGCpaniv4"
      },
      "outputs": [],
      "source": [
        "def get_class_dist(df_col):\n",
        "    \"\"\"\n",
        "    plot label distribution\n",
        "    \"\"\"\n",
        "    data = df_col.value_counts(normalize=True).rename('percentage').mul(100).reset_index().rename(columns = {\"index\":\"label\"})\n",
        "    plot = sns.barplot(x=\"label\", y=\"percentage\", data=data)\n",
        "    plot.set_xticklabels(plot.get_xticklabels(),\n",
        "                          rotation=90,\n",
        "                          horizontalalignment='right')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ltJ1YT-Fniv4"
      },
      "outputs": [],
      "source": [
        "def get_balanced_set(df):\n",
        "    \"\"\"\n",
        "    create balanced data set (oversampling)\n",
        "    \"\"\"\n",
        "    max_size = df['se_label'].value_counts().max()\n",
        "    balanced_list = [df]\n",
        "    for class_index, group in df.groupby('se_label'):\n",
        "        balanced_list.append(group.sample(max_size-len(group), replace=True))\n",
        "    return pd.concat(balanced_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bzn5yiaZniv5"
      },
      "outputs": [],
      "source": [
        "def get_flattened_list(nested_list):\n",
        "    return [item for sublist in nested_list for item in sublist]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9gap6Dvcniv6"
      },
      "outputs": [],
      "source": [
        "def get_learners_preds(prediction_proba):\n",
        "    \"\"\"\n",
        "    return the learners predictions as a dict with labels as keys and the probabilities as values\n",
        "    :param prediction_proba: values obtained from learner.predict()\n",
        "    :return: dict with probability per label\n",
        "    \"\"\"\n",
        "    prediction_proba = np.round(prediction_proba, 2)\n",
        "    prediction_list = list()\n",
        "    for i in range(len(prediction_proba)):\n",
        "        predictions = {'expl:impers': prediction_proba[i][0], 'expl:pass': prediction_proba[i][1],\n",
        "                      'expl:pv': prediction_proba[i][2], 'iobj': prediction_proba[i][3], 'obj': prediction_proba[i][4]}\n",
        "        prediction_list.append(predictions)\n",
        "    return prediction_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-mX19N0niv6"
      },
      "source": [
        "## 3) load and preprocess data\n",
        "- pool: pool of unlabeled data (Corpus del Español)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "txOUAwV_niv7"
      },
      "outputs": [],
      "source": [
        "train_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/es_data/es_ancora-ud-train.txt'\n",
        "test_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/es_data/es_ancora-ud-test.txt'\n",
        "dev_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/es_data/es_ancora-ud-dev.txt'\n",
        "pool_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/corpusdata_org/sp_text_se_corpus.txt'\n",
        "\n",
        "train = pd.read_csv(train_path, sep='\\t', names=['text', 'tokenized_text', 'se_label'])\n",
        "train.drop(columns=['text'], inplace = True)\n",
        "dev = pd.read_csv(dev_path, sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
        "dev.drop(columns=['text'], inplace = True)\n",
        "test = pd.read_csv(test_path, sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
        "test.drop(columns=['text'], inplace = True)\n",
        "\n",
        "se_corpus = pd.concat([train, dev, test]) # because the data was fileted for 'se' the data splits are not reliable anymore\n",
        "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'flat')].index)\n",
        "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'fixed')].index)\n",
        "\n",
        "pool = pd.read_csv(pool_path, sep='\\t', names=['text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "oyzByo70niv7",
        "outputId": "681a8c90-44ae-4619-f878-2ea4bb300fcd",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "get_class_dist(se_corpus.se_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Rft_KTMiniv8"
      },
      "outputs": [],
      "source": [
        "X = se_corpus.tokenized_text\n",
        "y = se_corpus.se_label\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2022)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NZRtuFORniv8"
      },
      "outputs": [],
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "pool_vectorized = vectorizer.transform(pool.text).toarray()\n",
        "\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y4vaU63Tniv9"
      },
      "outputs": [],
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cC62uG8univ-"
      },
      "outputs": [],
      "source": [
        "class PoolDataset(Dataset):\n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_data)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BXjTsKlrniv-"
      },
      "outputs": [],
      "source": [
        "train_set = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "test_set = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "pool_set = PoolDataset(torch.from_numpy(pool_vectorized).float())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DfxJGpGLniv-"
      },
      "outputs": [],
      "source": [
        "train_features = torch.reshape(train_set.X_data,   (train_set.X_data.shape[0], 1,train_set.X_data.shape[1]))\n",
        "train_labels = train_set.y_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QgnzijGtniv-"
      },
      "outputs": [],
      "source": [
        "test_features = torch.reshape(test_set.X_data,   (test_set.X_data.shape[0], 1,test_set.X_data.shape[1]))\n",
        "test_labels = test_set.y_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EYhFpKeRniv-"
      },
      "outputs": [],
      "source": [
        "X_pool = pool_set.X_data\n",
        "X_pool = torch.reshape(X_pool,   (X_pool.shape[0], 1, X_pool.shape[1]))\n",
        "X_pool = X_pool.detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7_silEoniv-"
      },
      "source": [
        "## 4) Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i8KBL3y0niwA"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, hidden_dim=32):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = 1\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(train_features.shape[2], hidden_dim, 1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51cFpiqniwA",
        "outputId": "e867615a-411a-4b97-f76a-116b1db31961",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using:  cuda\n"
          ]
        }
      ],
      "source": [
        "# skorch library creates sklearn classifier from torch neural net\n",
        "\n",
        "batch_size = 32\n",
        "n_iters = 1000\n",
        "epochs = int(n_iters/(len(train_set)/ batch_size))\n",
        "\n",
        "# create the classifier\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print('using: ', device)\n",
        "\n",
        "# Callbacks: print accuracy when model is fitted\n",
        "acc = EpochScoring(scoring='accuracy', on_train=True,\n",
        "                         name='accuracy', lower_is_better=False)\n",
        "\n",
        "f1 = EpochScoring(scoring='f1_weighted', on_train=True,\n",
        "                         name='f1-score', lower_is_better=False)\n",
        "\n",
        "callbacks = [acc, f1]\n",
        "\n",
        "classifier = NeuralNetClassifier(module=LSTMModel,\n",
        "                                 batch_size=batch_size,\n",
        "                                 max_epochs= epochs,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.Adam,\n",
        "                                 lr=0.1,\n",
        "                                 train_split=None,\n",
        "                                 callbacks=callbacks,\n",
        "                                 verbose=1,\n",
        "                                 device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "envQCUQkniwA",
        "outputId": "e01e2a58-759e-4bd3-8026-dcf7e3b4c6dd",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4932\u001b[0m      \u001b[32m0.4376\u001b[0m        \u001b[35m1.2042\u001b[0m  0.3537\n",
            "      2      \u001b[36m0.8214\u001b[0m      \u001b[32m0.8088\u001b[0m        \u001b[35m0.5367\u001b[0m  0.4214\n",
            "      3      \u001b[36m0.9191\u001b[0m      \u001b[32m0.9164\u001b[0m        \u001b[35m0.2302\u001b[0m  0.4092\n",
            "      4      \u001b[36m0.9738\u001b[0m      \u001b[32m0.9734\u001b[0m        \u001b[35m0.0823\u001b[0m  0.4189\n",
            "      5      \u001b[36m0.9932\u001b[0m      \u001b[32m0.9932\u001b[0m        \u001b[35m0.0247\u001b[0m  0.4196\n",
            "      6      \u001b[36m0.9988\u001b[0m      \u001b[32m0.9988\u001b[0m        \u001b[35m0.0087\u001b[0m  0.4179\n",
            "      7      0.9988      \u001b[32m0.9988\u001b[0m        \u001b[35m0.0058\u001b[0m  0.4183\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0026\u001b[0m  0.4176\n",
            "      9      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  0.4164\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=LSTMModel(\n",
              "    (lstm): LSTM(17200, 32, batch_first=True)\n",
              "    (fc): Linear(in_features=32, out_features=5, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.fit(train_features, train_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aBQF2oHniwA"
      },
      "source": [
        "***model is overfitting***: \n",
        "Run hyperparameter for best parameter setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94jfld7QniwA",
        "outputId": "ba4a15bc-653c-4575-9dfe-b183a0d67c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4882\u001b[0m      \u001b[32m0.3426\u001b[0m        \u001b[35m1.2769\u001b[0m  0.7774\n",
            "      2      \u001b[36m0.6711\u001b[0m      \u001b[32m0.6016\u001b[0m        \u001b[35m0.9798\u001b[0m  0.7406\n",
            "      3      \u001b[36m0.8506\u001b[0m      \u001b[32m0.8276\u001b[0m        \u001b[35m0.4766\u001b[0m  0.7404\n",
            "      4      \u001b[36m0.9742\u001b[0m      \u001b[32m0.9736\u001b[0m        \u001b[35m0.1563\u001b[0m  0.7362\n",
            "      5      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0603\u001b[0m  0.7307\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0301\u001b[0m  0.7313\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0176\u001b[0m  0.7352\n",
            "      8      0.9996      0.9996        \u001b[35m0.0114\u001b[0m  0.7341\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0079\u001b[0m  0.7322\n",
            "     10      1.0000      1.0000        \u001b[35m0.0058\u001b[0m  0.7239\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4768\u001b[0m      \u001b[32m0.3309\u001b[0m        \u001b[35m1.2821\u001b[0m  0.7051\n",
            "      2      \u001b[36m0.6439\u001b[0m      \u001b[32m0.5730\u001b[0m        \u001b[35m0.9867\u001b[0m  0.7241\n",
            "      3      \u001b[36m0.8411\u001b[0m      \u001b[32m0.8142\u001b[0m        \u001b[35m0.5081\u001b[0m  0.7118\n",
            "      4      \u001b[36m0.9698\u001b[0m      \u001b[32m0.9691\u001b[0m        \u001b[35m0.1728\u001b[0m  0.7113\n",
            "      5      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0644\u001b[0m  0.7052\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0324\u001b[0m  0.7264\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0193\u001b[0m  0.7178\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0127\u001b[0m  0.7259\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0089\u001b[0m  0.7141\n",
            "     10      1.0000      1.0000        \u001b[35m0.0065\u001b[0m  0.7130\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4695\u001b[0m      \u001b[32m0.3630\u001b[0m        \u001b[35m1.2887\u001b[0m  0.7275\n",
            "      2      \u001b[36m0.6674\u001b[0m      \u001b[32m0.5983\u001b[0m        \u001b[35m0.9766\u001b[0m  0.7291\n",
            "      3      \u001b[36m0.8488\u001b[0m      \u001b[32m0.8222\u001b[0m        \u001b[35m0.4973\u001b[0m  0.7263\n",
            "      4      \u001b[36m0.9658\u001b[0m      \u001b[32m0.9646\u001b[0m        \u001b[35m0.1782\u001b[0m  0.7194\n",
            "      5      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0683\u001b[0m  0.7315\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0333\u001b[0m  0.7379\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0194\u001b[0m  0.7172\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0126\u001b[0m  0.7115\n",
            "      9      1.0000      1.0000        \u001b[35m0.0087\u001b[0m  0.7102\n",
            "     10      1.0000      1.0000        \u001b[35m0.0064\u001b[0m  0.7101\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4917\u001b[0m      \u001b[32m0.3276\u001b[0m        \u001b[35m1.2605\u001b[0m  0.7281\n",
            "      2      \u001b[36m0.6624\u001b[0m      \u001b[32m0.5928\u001b[0m        \u001b[35m0.9721\u001b[0m  0.7180\n",
            "      3      \u001b[36m0.8544\u001b[0m      \u001b[32m0.8296\u001b[0m        \u001b[35m0.4687\u001b[0m  0.7101\n",
            "      4      \u001b[36m0.9772\u001b[0m      \u001b[32m0.9766\u001b[0m        \u001b[35m0.1551\u001b[0m  0.7106\n",
            "      5      \u001b[36m0.9949\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0603\u001b[0m  0.7118\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0309\u001b[0m  0.7117\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0185\u001b[0m  0.7153\n",
            "      8      0.9996      0.9996        \u001b[35m0.0122\u001b[0m  0.7115\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0086\u001b[0m  0.7098\n",
            "     10      1.0000      1.0000        \u001b[35m0.0063\u001b[0m  0.7094\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4899\u001b[0m      \u001b[32m0.3431\u001b[0m        \u001b[35m1.2722\u001b[0m  0.7210\n",
            "      2      \u001b[36m0.6661\u001b[0m      \u001b[32m0.5966\u001b[0m        \u001b[35m0.9692\u001b[0m  0.7236\n",
            "      3      \u001b[36m0.8573\u001b[0m      \u001b[32m0.8354\u001b[0m        \u001b[35m0.4625\u001b[0m  0.7255\n",
            "      4      \u001b[36m0.9779\u001b[0m      \u001b[32m0.9774\u001b[0m        \u001b[35m0.1494\u001b[0m  0.7243\n",
            "      5      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0575\u001b[0m  0.7182\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0295\u001b[0m  0.6913\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0177\u001b[0m  0.6670\n",
            "      8      0.9993      0.9993        \u001b[35m0.0117\u001b[0m  0.6443\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0082\u001b[0m  0.6204\n",
            "     10      1.0000      1.0000        \u001b[35m0.0060\u001b[0m  0.6125\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4827\u001b[0m      \u001b[32m0.3794\u001b[0m        \u001b[35m1.2657\u001b[0m  0.9784\n",
            "      2      \u001b[36m0.7112\u001b[0m      \u001b[32m0.6452\u001b[0m        \u001b[35m0.8622\u001b[0m  0.9906\n",
            "      3      \u001b[36m0.9198\u001b[0m      \u001b[32m0.9138\u001b[0m        \u001b[35m0.2873\u001b[0m  0.9906\n",
            "      4      \u001b[36m0.9897\u001b[0m      \u001b[32m0.9896\u001b[0m        \u001b[35m0.0718\u001b[0m  1.0096\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0285\u001b[0m  1.0650\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0148\u001b[0m  1.0693\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0089\u001b[0m  1.0827\n",
            "      8      0.9996      0.9996        \u001b[35m0.0059\u001b[0m  1.0831\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0042\u001b[0m  1.0832\n",
            "     10      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.0815\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4930\u001b[0m      \u001b[32m0.3599\u001b[0m        \u001b[35m1.2593\u001b[0m  1.0774\n",
            "      2      \u001b[36m0.7082\u001b[0m      \u001b[32m0.6453\u001b[0m        \u001b[35m0.8374\u001b[0m  1.0807\n",
            "      3      \u001b[36m0.9268\u001b[0m      \u001b[32m0.9220\u001b[0m        \u001b[35m0.2662\u001b[0m  1.0768\n",
            "      4      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9907\u001b[0m        \u001b[35m0.0679\u001b[0m  1.0621\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0278\u001b[0m  1.0447\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0150\u001b[0m  0.9877\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0093\u001b[0m  0.9857\n",
            "      8      0.9996      0.9996        \u001b[35m0.0062\u001b[0m  0.9883\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0044\u001b[0m  0.9885\n",
            "     10      1.0000      1.0000        \u001b[35m0.0032\u001b[0m  0.9901\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4794\u001b[0m      \u001b[32m0.3766\u001b[0m        \u001b[35m1.2569\u001b[0m  1.0812\n",
            "      2      \u001b[36m0.7160\u001b[0m      \u001b[32m0.6519\u001b[0m        \u001b[35m0.8462\u001b[0m  1.0806\n",
            "      3      \u001b[36m0.9297\u001b[0m      \u001b[32m0.9254\u001b[0m        \u001b[35m0.2794\u001b[0m  1.0818\n",
            "      4      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9911\u001b[0m        \u001b[35m0.0720\u001b[0m  1.0801\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0278\u001b[0m  1.0816\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0145\u001b[0m  1.0810\n",
            "      7      1.0000      1.0000        \u001b[35m0.0088\u001b[0m  1.0844\n",
            "      8      1.0000      1.0000        \u001b[35m0.0058\u001b[0m  1.0819\n",
            "      9      1.0000      1.0000        \u001b[35m0.0041\u001b[0m  1.0808\n",
            "     10      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.0808\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4914\u001b[0m      \u001b[32m0.3480\u001b[0m        \u001b[35m1.2554\u001b[0m  1.0613\n",
            "      2      \u001b[36m0.7157\u001b[0m      \u001b[32m0.6488\u001b[0m        \u001b[35m0.8590\u001b[0m  1.0619\n",
            "      3      \u001b[36m0.9165\u001b[0m      \u001b[32m0.9105\u001b[0m        \u001b[35m0.2988\u001b[0m  1.0396\n",
            "      4      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9907\u001b[0m        \u001b[35m0.0743\u001b[0m  0.9927\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0291\u001b[0m  0.9874\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0155\u001b[0m  0.9872\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0095\u001b[0m  1.0579\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0063\u001b[0m  1.0641\n",
            "      9      1.0000      1.0000        \u001b[35m0.0045\u001b[0m  1.0842\n",
            "     10      1.0000      1.0000        \u001b[35m0.0033\u001b[0m  1.0835\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4792\u001b[0m      \u001b[32m0.3667\u001b[0m        \u001b[35m1.2539\u001b[0m  1.0869\n",
            "      2      \u001b[36m0.6966\u001b[0m      \u001b[32m0.6338\u001b[0m        \u001b[35m0.8553\u001b[0m  1.0813\n",
            "      3      \u001b[36m0.9279\u001b[0m      \u001b[32m0.9236\u001b[0m        \u001b[35m0.2653\u001b[0m  1.0357\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      4      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0636\u001b[0m  0.9792\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0253\u001b[0m  0.9864\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0135\u001b[0m  1.0663\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0083\u001b[0m  1.0645\n",
            "      8      1.0000      1.0000        \u001b[35m0.0055\u001b[0m  1.0180\n",
            "      9      1.0000      1.0000        \u001b[35m0.0039\u001b[0m  1.0099\n",
            "     10      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.0610\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4798\u001b[0m      \u001b[32m0.3956\u001b[0m        \u001b[35m1.2503\u001b[0m  1.7993\n",
            "      2      \u001b[36m0.7583\u001b[0m      \u001b[32m0.7127\u001b[0m        \u001b[35m0.6972\u001b[0m  1.7973\n",
            "      3      \u001b[36m0.9673\u001b[0m      \u001b[32m0.9666\u001b[0m        \u001b[35m0.1419\u001b[0m  1.7882\n",
            "      4      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0329\u001b[0m  1.8006\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0138\u001b[0m  1.7497\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0074\u001b[0m  1.7530\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0046\u001b[0m  1.8006\n",
            "      8      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.7778\n",
            "      9      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  1.7482\n",
            "     10      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.7987\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4919\u001b[0m      \u001b[32m0.3997\u001b[0m        \u001b[35m1.2408\u001b[0m  1.7985\n",
            "      2      \u001b[36m0.7586\u001b[0m      \u001b[32m0.7147\u001b[0m        \u001b[35m0.6961\u001b[0m  1.7566\n",
            "      3      \u001b[36m0.9658\u001b[0m      \u001b[32m0.9651\u001b[0m        \u001b[35m0.1463\u001b[0m  1.7922\n",
            "      4      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0336\u001b[0m  1.8022\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0147\u001b[0m  1.8026\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0080\u001b[0m  1.7574\n",
            "      7      0.9996      0.9996        \u001b[35m0.0050\u001b[0m  1.7887\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0034\u001b[0m  1.8425\n",
            "      9      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.8098\n",
            "     10      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.8045\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5000\u001b[0m      \u001b[32m0.3773\u001b[0m        \u001b[35m1.2386\u001b[0m  1.7867\n",
            "      2      \u001b[36m0.7675\u001b[0m      \u001b[32m0.7237\u001b[0m        \u001b[35m0.6854\u001b[0m  1.7618\n",
            "      3      \u001b[36m0.9632\u001b[0m      \u001b[32m0.9624\u001b[0m        \u001b[35m0.1433\u001b[0m  1.7743\n",
            "      4      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0312\u001b[0m  1.7206\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0129\u001b[0m  1.7272\n",
            "      6      1.0000      1.0000        \u001b[35m0.0069\u001b[0m  1.7133\n",
            "      7      1.0000      1.0000        \u001b[35m0.0043\u001b[0m  1.7174\n",
            "      8      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.7256\n",
            "      9      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.7253\n",
            "     10      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.7329\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4939\u001b[0m      \u001b[32m0.3824\u001b[0m        \u001b[35m1.2416\u001b[0m  1.7986\n",
            "      2      \u001b[36m0.7587\u001b[0m      \u001b[32m0.7118\u001b[0m        \u001b[35m0.7007\u001b[0m  1.7415\n",
            "      3      \u001b[36m0.9662\u001b[0m      \u001b[32m0.9655\u001b[0m        \u001b[35m0.1498\u001b[0m  1.7217\n",
            "      4      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0331\u001b[0m  1.7755\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0142\u001b[0m  1.8012\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0079\u001b[0m  1.7681\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0049\u001b[0m  1.7277\n",
            "      8      1.0000      1.0000        \u001b[35m0.0033\u001b[0m  1.7276\n",
            "      9      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.7276\n",
            "     10      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.7778\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4866\u001b[0m      \u001b[32m0.3834\u001b[0m        \u001b[35m1.2416\u001b[0m  1.7960\n",
            "      2      \u001b[36m0.7683\u001b[0m      \u001b[32m0.7233\u001b[0m        \u001b[35m0.6806\u001b[0m  1.7545\n",
            "      3      \u001b[36m0.9680\u001b[0m      \u001b[32m0.9672\u001b[0m        \u001b[35m0.1363\u001b[0m  1.7251\n",
            "      4      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0305\u001b[0m  1.7734\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0132\u001b[0m  1.7871\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0072\u001b[0m  1.7569\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0045\u001b[0m  1.7121\n",
            "      8      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.7124\n",
            "      9      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.7556\n",
            "     10      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.7883\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4879\u001b[0m      \u001b[32m0.4089\u001b[0m        \u001b[35m1.2347\u001b[0m  3.3125\n",
            "      2      \u001b[36m0.8013\u001b[0m      \u001b[32m0.7771\u001b[0m        \u001b[35m0.5537\u001b[0m  3.2659\n",
            "      3      \u001b[36m0.9834\u001b[0m      \u001b[32m0.9833\u001b[0m        \u001b[35m0.0779\u001b[0m  3.2710\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0164\u001b[0m  3.2693\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0071\u001b[0m  3.2727\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0040\u001b[0m  3.3203\n",
            "      7      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  3.2680\n",
            "      8      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  3.2668\n",
            "      9      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  3.2820\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  3.3050\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5018\u001b[0m      \u001b[32m0.4058\u001b[0m        \u001b[35m1.2265\u001b[0m  3.2667\n",
            "      2      \u001b[36m0.8043\u001b[0m      \u001b[32m0.7809\u001b[0m        \u001b[35m0.5556\u001b[0m  3.3305\n",
            "      3      \u001b[36m0.9845\u001b[0m      \u001b[32m0.9844\u001b[0m        \u001b[35m0.0779\u001b[0m  3.3358\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0170\u001b[0m  3.3437\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0078\u001b[0m  3.3418\n",
            "      6      0.9996      0.9996        \u001b[35m0.0044\u001b[0m  3.3400\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0028\u001b[0m  3.2887\n",
            "      8      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  3.3389\n",
            "      9      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  3.3290\n",
            "     10      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  3.2558\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5037\u001b[0m      \u001b[32m0.4016\u001b[0m        \u001b[35m1.2245\u001b[0m  3.3099\n",
            "      2      \u001b[36m0.8190\u001b[0m      \u001b[32m0.7971\u001b[0m        \u001b[35m0.5307\u001b[0m  3.2701\n",
            "      3      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9830\u001b[0m        \u001b[35m0.0783\u001b[0m  3.2698\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0149\u001b[0m  3.2707\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0066\u001b[0m  3.2710\n",
            "      6      1.0000      1.0000        \u001b[35m0.0037\u001b[0m  3.2678\n",
            "      7      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  3.2686\n",
            "      8      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  3.2709\n",
            "      9      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  3.2685\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  3.2675\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5020\u001b[0m      \u001b[32m0.4087\u001b[0m        \u001b[35m1.2286\u001b[0m  3.2690\n",
            "      2      \u001b[36m0.8076\u001b[0m      \u001b[32m0.7816\u001b[0m        \u001b[35m0.5618\u001b[0m  3.2693\n",
            "      3      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9830\u001b[0m        \u001b[35m0.0826\u001b[0m  3.2699\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0170\u001b[0m  3.2681\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0077\u001b[0m  3.2682\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0043\u001b[0m  3.3268\n",
            "      7      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  3.2695\n",
            "      8      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  3.2710\n",
            "      9      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  3.2729\n",
            "     10      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  3.2717\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4980\u001b[0m      \u001b[32m0.4036\u001b[0m        \u001b[35m1.2298\u001b[0m  3.3202\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      2      \u001b[36m0.8146\u001b[0m      \u001b[32m0.7937\u001b[0m        \u001b[35m0.5388\u001b[0m  3.2687\n",
            "      3      \u001b[36m0.9853\u001b[0m      \u001b[32m0.9852\u001b[0m        \u001b[35m0.0722\u001b[0m  3.2691\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0151\u001b[0m  3.2681\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0069\u001b[0m  3.2699\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0038\u001b[0m  3.2666\n",
            "      7      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  3.3185\n",
            "      8      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  3.2709\n",
            "      9      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  3.3143\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  3.2662\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4625\u001b[0m      \u001b[32m0.3441\u001b[0m        \u001b[35m1.2965\u001b[0m  0.6471\n",
            "      2      \u001b[36m0.6637\u001b[0m      \u001b[32m0.5944\u001b[0m        \u001b[35m0.9833\u001b[0m  0.7144\n",
            "      3      \u001b[36m0.8466\u001b[0m      \u001b[32m0.8188\u001b[0m        \u001b[35m0.4903\u001b[0m  0.7198\n",
            "      4      \u001b[36m0.9735\u001b[0m      \u001b[32m0.9728\u001b[0m        \u001b[35m0.1597\u001b[0m  0.7146\n",
            "      5      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0611\u001b[0m  0.7130\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0307\u001b[0m  0.7123\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0180\u001b[0m  0.7240\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0117\u001b[0m  0.7148\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0081\u001b[0m  0.7265\n",
            "     10      1.0000      1.0000        \u001b[35m0.0059\u001b[0m  0.7277\n",
            "     11      1.0000      1.0000        \u001b[35m0.0045\u001b[0m  0.7222\n",
            "     12      1.0000      1.0000        \u001b[35m0.0035\u001b[0m  0.7156\n",
            "     13      1.0000      1.0000        \u001b[35m0.0028\u001b[0m  0.7297\n",
            "     14      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.7154\n",
            "     15      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  0.7285\n",
            "     16      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.7292\n",
            "     17      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.7272\n",
            "     18      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.7246\n",
            "     19      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7101\n",
            "     20      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7093\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4691\u001b[0m      \u001b[32m0.3663\u001b[0m        \u001b[35m1.2873\u001b[0m  0.7265\n",
            "      2      \u001b[36m0.6589\u001b[0m      \u001b[32m0.5897\u001b[0m        \u001b[35m0.9891\u001b[0m  0.7276\n",
            "      3      \u001b[36m0.8451\u001b[0m      \u001b[32m0.8150\u001b[0m        \u001b[35m0.5034\u001b[0m  0.7265\n",
            "      4      \u001b[36m0.9691\u001b[0m      \u001b[32m0.9682\u001b[0m        \u001b[35m0.1759\u001b[0m  0.7289\n",
            "      5      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0674\u001b[0m  0.7315\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0339\u001b[0m  0.7288\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0201\u001b[0m  0.7299\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0132\u001b[0m  0.7307\n",
            "      9      0.9996      0.9996        \u001b[35m0.0092\u001b[0m  0.7368\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0067\u001b[0m  0.7313\n",
            "     11      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  0.7315\n",
            "     12      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  0.7262\n",
            "     13      1.0000      1.0000        \u001b[35m0.0032\u001b[0m  0.7172\n",
            "     14      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  0.6978\n",
            "     15      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  0.6701\n",
            "     16      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  0.6427\n",
            "     17      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.6235\n",
            "     18      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.6142\n",
            "     19      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.7099\n",
            "     20      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7309\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4606\u001b[0m      \u001b[32m0.3599\u001b[0m        \u001b[35m1.2789\u001b[0m  0.7295\n",
            "      2      \u001b[36m0.6700\u001b[0m      \u001b[32m0.6015\u001b[0m        \u001b[35m0.9672\u001b[0m  0.7306\n",
            "      3      \u001b[36m0.8532\u001b[0m      \u001b[32m0.8263\u001b[0m        \u001b[35m0.4802\u001b[0m  0.7308\n",
            "      4      \u001b[36m0.9669\u001b[0m      \u001b[32m0.9657\u001b[0m        \u001b[35m0.1670\u001b[0m  0.7333\n",
            "      5      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0649\u001b[0m  0.7342\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0322\u001b[0m  0.7322\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0188\u001b[0m  0.7326\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0122\u001b[0m  0.7321\n",
            "      9      1.0000      1.0000        \u001b[35m0.0084\u001b[0m  0.7318\n",
            "     10      1.0000      1.0000        \u001b[35m0.0061\u001b[0m  0.7274\n",
            "     11      1.0000      1.0000        \u001b[35m0.0046\u001b[0m  0.7134\n",
            "     12      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  0.7127\n",
            "     13      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  0.7123\n",
            "     14      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  0.7283\n",
            "     15      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  0.7298\n",
            "     16      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.7315\n",
            "     17      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.7324\n",
            "     18      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.7210\n",
            "     19      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.6951\n",
            "     20      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.6709\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4825\u001b[0m      \u001b[32m0.3309\u001b[0m        \u001b[35m1.2763\u001b[0m  0.6836\n",
            "      2      \u001b[36m0.6580\u001b[0m      \u001b[32m0.5872\u001b[0m        \u001b[35m0.9792\u001b[0m  0.6786\n",
            "      3      \u001b[36m0.8514\u001b[0m      \u001b[32m0.8260\u001b[0m        \u001b[35m0.4814\u001b[0m  0.6650\n",
            "      4      \u001b[36m0.9724\u001b[0m      \u001b[32m0.9718\u001b[0m        \u001b[35m0.1615\u001b[0m  0.6514\n",
            "      5      \u001b[36m0.9949\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0627\u001b[0m  0.6405\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0321\u001b[0m  0.6312\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0193\u001b[0m  0.6269\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0128\u001b[0m  0.6272\n",
            "      9      0.9996      0.9996        \u001b[35m0.0090\u001b[0m  0.6268\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0066\u001b[0m  0.7335\n",
            "     11      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  0.7299\n",
            "     12      1.0000      1.0000        \u001b[35m0.0039\u001b[0m  0.7291\n",
            "     13      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  0.7296\n",
            "     14      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  0.7200\n",
            "     15      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  0.7141\n",
            "     16      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  0.7122\n",
            "     17      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.7300\n",
            "     18      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.7308\n",
            "     19      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7301\n",
            "     20      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7314\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4763\u001b[0m      \u001b[32m0.3674\u001b[0m        \u001b[35m1.2771\u001b[0m  0.7335\n",
            "      2      \u001b[36m0.6598\u001b[0m      \u001b[32m0.5905\u001b[0m        \u001b[35m0.9712\u001b[0m  0.7334\n",
            "      3      \u001b[36m0.8591\u001b[0m      \u001b[32m0.8366\u001b[0m        \u001b[35m0.4649\u001b[0m  0.7296\n",
            "      4      \u001b[36m0.9809\u001b[0m      \u001b[32m0.9804\u001b[0m        \u001b[35m0.1458\u001b[0m  0.7295\n",
            "      5      \u001b[36m0.9949\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0554\u001b[0m  0.7328\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0282\u001b[0m  0.7314\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0169\u001b[0m  0.7311\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0111\u001b[0m  0.7194\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0078\u001b[0m  0.7350\n",
            "     10      1.0000      1.0000        \u001b[35m0.0057\u001b[0m  0.7273\n",
            "     11      1.0000      1.0000        \u001b[35m0.0043\u001b[0m  0.7287\n",
            "     12      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  0.7320\n",
            "     13      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  0.7295\n",
            "     14      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.7319\n",
            "     15      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  0.7293\n",
            "     16      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.7298\n",
            "     17      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.7337\n",
            "     18      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.7272\n",
            "     19      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7318\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     20      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7313\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4794\u001b[0m      \u001b[32m0.4082\u001b[0m        \u001b[35m1.2617\u001b[0m  1.0805\n",
            "      2      \u001b[36m0.7104\u001b[0m      \u001b[32m0.6474\u001b[0m        \u001b[35m0.8446\u001b[0m  1.0655\n",
            "      3      \u001b[36m0.9283\u001b[0m      \u001b[32m0.9234\u001b[0m        \u001b[35m0.2664\u001b[0m  1.0708\n",
            "      4      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9911\u001b[0m        \u001b[35m0.0670\u001b[0m  1.0765\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0272\u001b[0m  1.0780\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0142\u001b[0m  1.0887\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0086\u001b[0m  1.0781\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0057\u001b[0m  1.0833\n",
            "      9      1.0000      1.0000        \u001b[35m0.0041\u001b[0m  1.0788\n",
            "     10      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.0784\n",
            "     11      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  1.0785\n",
            "     12      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.0435\n",
            "     13      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  1.0517\n",
            "     14      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.0779\n",
            "     15      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.0779\n",
            "     16      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.0771\n",
            "     17      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.0791\n",
            "     18      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.0796\n",
            "     19      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0795\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.1158\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4761\u001b[0m      \u001b[32m0.3735\u001b[0m        \u001b[35m1.2634\u001b[0m  1.0772\n",
            "      2      \u001b[36m0.7035\u001b[0m      \u001b[32m0.6433\u001b[0m        \u001b[35m0.8566\u001b[0m  1.0809\n",
            "      3      \u001b[36m0.9253\u001b[0m      \u001b[32m0.9202\u001b[0m        \u001b[35m0.2802\u001b[0m  1.0635\n",
            "      4      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9907\u001b[0m        \u001b[35m0.0720\u001b[0m  1.0614\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0293\u001b[0m  1.0605\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0158\u001b[0m  1.0559\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0097\u001b[0m  1.0014\n",
            "      8      0.9996      0.9996        \u001b[35m0.0064\u001b[0m  0.9742\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0046\u001b[0m  0.9735\n",
            "     10      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  1.0050\n",
            "     11      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  1.0826\n",
            "     12      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  1.0823\n",
            "     13      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.0809\n",
            "     14      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.0688\n",
            "     15      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  1.0134\n",
            "     16      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.0559\n",
            "     17      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.0638\n",
            "     18      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.0593\n",
            "     19      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0769\n",
            "     20      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0770\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4882\u001b[0m      \u001b[32m0.3381\u001b[0m        \u001b[35m1.2614\u001b[0m  1.0605\n",
            "      2      \u001b[36m0.7093\u001b[0m      \u001b[32m0.6477\u001b[0m        \u001b[35m0.8419\u001b[0m  1.0625\n",
            "      3      \u001b[36m0.9323\u001b[0m      \u001b[32m0.9280\u001b[0m        \u001b[35m0.2721\u001b[0m  1.0552\n",
            "      4      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9918\u001b[0m        \u001b[35m0.0703\u001b[0m  1.0634\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0274\u001b[0m  1.0634\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0143\u001b[0m  1.0815\n",
            "      7      1.0000      1.0000        \u001b[35m0.0086\u001b[0m  1.0819\n",
            "      8      1.0000      1.0000        \u001b[35m0.0057\u001b[0m  1.0795\n",
            "      9      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  1.0797\n",
            "     10      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.0799\n",
            "     11      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  1.0808\n",
            "     12      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.0825\n",
            "     13      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  1.0762\n",
            "     14      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.0725\n",
            "     15      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.0660\n",
            "     16      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.0662\n",
            "     17      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.0700\n",
            "     18      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.0853\n",
            "     19      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0780\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0739\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4829\u001b[0m      \u001b[32m0.3491\u001b[0m        \u001b[35m1.2543\u001b[0m  1.0823\n",
            "      2      \u001b[36m0.7131\u001b[0m      \u001b[32m0.6485\u001b[0m        \u001b[35m0.8515\u001b[0m  1.0827\n",
            "      3      \u001b[36m0.9184\u001b[0m      \u001b[32m0.9127\u001b[0m        \u001b[35m0.2864\u001b[0m  1.0662\n",
            "      4      \u001b[36m0.9904\u001b[0m      \u001b[32m0.9904\u001b[0m        \u001b[35m0.0716\u001b[0m  1.0762\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0282\u001b[0m  1.0644\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0151\u001b[0m  1.0054\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0092\u001b[0m  1.0660\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0062\u001b[0m  1.0812\n",
            "      9      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  1.0817\n",
            "     10      1.0000      1.0000        \u001b[35m0.0032\u001b[0m  1.0799\n",
            "     11      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  1.0820\n",
            "     12      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  1.0692\n",
            "     13      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.0719\n",
            "     14      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.0751\n",
            "     15      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.0231\n",
            "     16      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.0343\n",
            "     17      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.0613\n",
            "     18      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.0592\n",
            "     19      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0621\n",
            "     20      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0616\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4807\u001b[0m      \u001b[32m0.3359\u001b[0m        \u001b[35m1.2657\u001b[0m  1.0742\n",
            "      2      \u001b[36m0.7072\u001b[0m      \u001b[32m0.6455\u001b[0m        \u001b[35m0.8319\u001b[0m  1.0651\n",
            "      3      \u001b[36m0.9338\u001b[0m      \u001b[32m0.9303\u001b[0m        \u001b[35m0.2526\u001b[0m  1.0687\n",
            "      4      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0634\u001b[0m  1.0657\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0257\u001b[0m  1.0665\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0138\u001b[0m  1.0782\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0085\u001b[0m  1.0824\n",
            "      8      1.0000      1.0000        \u001b[35m0.0057\u001b[0m  1.0824\n",
            "      9      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  1.0741\n",
            "     10      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.0664\n",
            "     11      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  1.0689\n",
            "     12      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.0763\n",
            "     13      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  1.0717\n",
            "     14      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.0186\n",
            "     15      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.9865\n",
            "     16      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.9861\n",
            "     17      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.9865\n",
            "     18      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9867\n",
            "     19      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.9867\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0645\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4823\u001b[0m      \u001b[32m0.3966\u001b[0m        \u001b[35m1.2473\u001b[0m  1.7978\n",
            "      2      \u001b[36m0.7535\u001b[0m      \u001b[32m0.7069\u001b[0m        \u001b[35m0.7000\u001b[0m  1.7696\n",
            "      3      \u001b[36m0.9695\u001b[0m      \u001b[32m0.9688\u001b[0m        \u001b[35m0.1433\u001b[0m  1.7940\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0330\u001b[0m  1.7530\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0138\u001b[0m  1.7994\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0074\u001b[0m  1.7966\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0046\u001b[0m  1.7852\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      8      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.7941\n",
            "      9      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  1.7897\n",
            "     10      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.7420\n",
            "     11      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.7256\n",
            "     12      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.7243\n",
            "     13      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.7257\n",
            "     14      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.7256\n",
            "     15      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7252\n",
            "     16      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7254\n",
            "     17      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7246\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7221\n",
            "     19      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7250\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7279\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4996\u001b[0m      \u001b[32m0.3882\u001b[0m        \u001b[35m1.2427\u001b[0m  1.7837\n",
            "      2      \u001b[36m0.7575\u001b[0m      \u001b[32m0.7142\u001b[0m        \u001b[35m0.6950\u001b[0m  1.7928\n",
            "      3      \u001b[36m0.9654\u001b[0m      \u001b[32m0.9648\u001b[0m        \u001b[35m0.1444\u001b[0m  1.7720\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0331\u001b[0m  1.7223\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0145\u001b[0m  1.7232\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0080\u001b[0m  1.7390\n",
            "      7      0.9996      0.9996        \u001b[35m0.0050\u001b[0m  1.7849\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0034\u001b[0m  1.7846\n",
            "      9      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.7763\n",
            "     10      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.7962\n",
            "     11      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  1.8000\n",
            "     12      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  1.7676\n",
            "     13      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.7186\n",
            "     14      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.7547\n",
            "     15      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.7791\n",
            "     16      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7324\n",
            "     17      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7944\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7856\n",
            "     19      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7327\n",
            "     20      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7894\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4923\u001b[0m      \u001b[32m0.3959\u001b[0m        \u001b[35m1.2388\u001b[0m  1.8008\n",
            "      2      \u001b[36m0.7726\u001b[0m      \u001b[32m0.7291\u001b[0m        \u001b[35m0.6827\u001b[0m  1.8029\n",
            "      3      \u001b[36m0.9647\u001b[0m      \u001b[32m0.9638\u001b[0m        \u001b[35m0.1454\u001b[0m  1.7962\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0321\u001b[0m  1.7847\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0133\u001b[0m  1.7851\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0071\u001b[0m  1.7983\n",
            "      7      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  1.7939\n",
            "      8      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.7959\n",
            "      9      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.7238\n",
            "     10      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.7153\n",
            "     11      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.7247\n",
            "     12      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.7265\n",
            "     13      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.7268\n",
            "     14      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.7255\n",
            "     15      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7259\n",
            "     16      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7336\n",
            "     17      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.8017\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7824\n",
            "     19      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7856\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.8038\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5028\u001b[0m      \u001b[32m0.4039\u001b[0m        \u001b[35m1.2351\u001b[0m  1.7954\n",
            "      2      \u001b[36m0.7620\u001b[0m      \u001b[32m0.7127\u001b[0m        \u001b[35m0.6956\u001b[0m  1.7852\n",
            "      3      \u001b[36m0.9632\u001b[0m      \u001b[32m0.9624\u001b[0m        \u001b[35m0.1521\u001b[0m  1.7826\n",
            "      4      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0336\u001b[0m  1.7275\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0144\u001b[0m  1.7985\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0079\u001b[0m  1.7770\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0049\u001b[0m  1.7865\n",
            "      8      1.0000      1.0000        \u001b[35m0.0033\u001b[0m  1.7850\n",
            "      9      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.8013\n",
            "     10      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.7631\n",
            "     11      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.7238\n",
            "     12      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.7238\n",
            "     13      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.7240\n",
            "     14      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.7230\n",
            "     15      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.7233\n",
            "     16      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7182\n",
            "     17      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7399\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7881\n",
            "     19      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7630\n",
            "     20      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7238\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4976\u001b[0m      \u001b[32m0.3757\u001b[0m        \u001b[35m1.2354\u001b[0m  1.7772\n",
            "      2      \u001b[36m0.7602\u001b[0m      \u001b[32m0.7173\u001b[0m        \u001b[35m0.6836\u001b[0m  1.7469\n",
            "      3      \u001b[36m0.9676\u001b[0m      \u001b[32m0.9668\u001b[0m        \u001b[35m0.1383\u001b[0m  1.7399\n",
            "      4      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0307\u001b[0m  1.7952\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0131\u001b[0m  1.7693\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0072\u001b[0m  1.7940\n",
            "      7      1.0000      1.0000        \u001b[35m0.0045\u001b[0m  1.7981\n",
            "      8      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.7998\n",
            "      9      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.7474\n",
            "     10      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.7231\n",
            "     11      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.7219\n",
            "     12      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.7214\n",
            "     13      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.7435\n",
            "     14      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.7743\n",
            "     15      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7914\n",
            "     16      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7305\n",
            "     17      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7464\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7959\n",
            "     19      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7557\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7850\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4908\u001b[0m      \u001b[32m0.4164\u001b[0m        \u001b[35m1.2344\u001b[0m  3.2824\n",
            "      2      \u001b[36m0.8050\u001b[0m      \u001b[32m0.7794\u001b[0m        \u001b[35m0.5492\u001b[0m  3.2676\n",
            "      3      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9829\u001b[0m        \u001b[35m0.0769\u001b[0m  3.2682\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0161\u001b[0m  3.2682\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0070\u001b[0m  3.2642\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0039\u001b[0m  3.2714\n",
            "      7      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  3.3028\n",
            "      8      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  3.2746\n",
            "      9      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  3.3182\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  3.3051\n",
            "     11      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  3.2716\n",
            "     12      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  3.2729\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.2716\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.3057\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2809\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.2680\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3220\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3370\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.2695\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3159\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4945\u001b[0m      \u001b[32m0.4157\u001b[0m        \u001b[35m1.2278\u001b[0m  3.3456\n",
            "      2      \u001b[36m0.8068\u001b[0m      \u001b[32m0.7854\u001b[0m        \u001b[35m0.5476\u001b[0m  3.3393\n",
            "      3      \u001b[36m0.9820\u001b[0m      \u001b[32m0.9819\u001b[0m        \u001b[35m0.0764\u001b[0m  3.3018\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0168\u001b[0m  3.3147\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0077\u001b[0m  3.3391\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0044\u001b[0m  3.2874\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0028\u001b[0m  3.2691\n",
            "      8      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  3.3016\n",
            "      9      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  3.3095\n",
            "     10      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  3.2645\n",
            "     11      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  3.2838\n",
            "     12      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  3.2558\n",
            "     13      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  3.2989\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.2860\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.3088\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2721\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.2719\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.2984\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3291\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2706\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5048\u001b[0m      \u001b[32m0.4203\u001b[0m        \u001b[35m1.2279\u001b[0m  3.3173\n",
            "      2      \u001b[36m0.8142\u001b[0m      \u001b[32m0.7911\u001b[0m        \u001b[35m0.5399\u001b[0m  3.3342\n",
            "      3      \u001b[36m0.9812\u001b[0m      \u001b[32m0.9811\u001b[0m        \u001b[35m0.0822\u001b[0m  3.2879\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0155\u001b[0m  3.3140\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0068\u001b[0m  3.3362\n",
            "      6      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  3.3457\n",
            "      7      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  3.2793\n",
            "      8      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  3.2681\n",
            "      9      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  3.2669\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  3.2625\n",
            "     11      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  3.3255\n",
            "     12      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  3.2972\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.2891\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.3472\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2754\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2606\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3298\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.2850\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.2692\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2691\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4965\u001b[0m      \u001b[32m0.4097\u001b[0m        \u001b[35m1.2308\u001b[0m  3.3175\n",
            "      2      \u001b[36m0.8073\u001b[0m      \u001b[32m0.7814\u001b[0m        \u001b[35m0.5567\u001b[0m  3.2700\n",
            "      3      \u001b[36m0.9834\u001b[0m      \u001b[32m0.9833\u001b[0m        \u001b[35m0.0809\u001b[0m  3.2864\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0168\u001b[0m  3.3008\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0076\u001b[0m  3.2669\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0043\u001b[0m  3.3169\n",
            "      7      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  3.2688\n",
            "      8      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  3.2685\n",
            "      9      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  3.2927\n",
            "     10      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  3.3086\n",
            "     11      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  3.3035\n",
            "     12      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  3.2683\n",
            "     13      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  3.2689\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.2700\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2663\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2668\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.2670\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3293\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3293\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3175\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4998\u001b[0m      \u001b[32m0.4150\u001b[0m        \u001b[35m1.2280\u001b[0m  3.3166\n",
            "      2      \u001b[36m0.8183\u001b[0m      \u001b[32m0.7977\u001b[0m        \u001b[35m0.5390\u001b[0m  3.3408\n",
            "      3      \u001b[36m0.9857\u001b[0m      \u001b[32m0.9855\u001b[0m        \u001b[35m0.0721\u001b[0m  3.3368\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0152\u001b[0m  3.3133\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0069\u001b[0m  3.2602\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0039\u001b[0m  3.2687\n",
            "      7      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  3.3118\n",
            "      8      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  3.2988\n",
            "      9      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  3.2724\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  3.2714\n",
            "     11      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  3.2705\n",
            "     12      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  3.3217\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.2711\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  3.2706\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2704\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  3.2698\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3119\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3156\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3377\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3464\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5077\u001b[0m      \u001b[32m0.4473\u001b[0m        \u001b[35m1.1906\u001b[0m  0.7257\n",
            "      2      \u001b[36m0.9180\u001b[0m      \u001b[32m0.9145\u001b[0m        \u001b[35m0.2407\u001b[0m  0.7334\n",
            "      3      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0139\u001b[0m  0.7296\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.7317\n",
            "      5      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7694\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7773\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7771\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7771\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7426\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7399\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5085\u001b[0m      \u001b[32m0.4431\u001b[0m        \u001b[35m1.1854\u001b[0m  0.7282\n",
            "      2      \u001b[36m0.9191\u001b[0m      \u001b[32m0.9166\u001b[0m        \u001b[35m0.2444\u001b[0m  0.7309\n",
            "      3      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0086\u001b[0m  0.7303\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  0.7327\n",
            "      5      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7320\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7331\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7297\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7289\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7288\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7288\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5088\u001b[0m      \u001b[32m0.4433\u001b[0m        \u001b[35m1.1844\u001b[0m  0.7328\n",
            "      2      \u001b[36m0.9327\u001b[0m      \u001b[32m0.9315\u001b[0m        \u001b[35m0.2119\u001b[0m  0.7341\n",
            "      3      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0092\u001b[0m  0.7279\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.7266\n",
            "      5      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7325\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7309\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7299\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7319\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7130\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7433\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5127\u001b[0m      \u001b[32m0.4507\u001b[0m        \u001b[35m1.1899\u001b[0m  0.7266\n",
            "      2      \u001b[36m0.9298\u001b[0m      \u001b[32m0.9283\u001b[0m        \u001b[35m0.2173\u001b[0m  0.7287\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0103\u001b[0m  0.7283\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  0.7286\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7093\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6831\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6594\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6433\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7366\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7304\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5105\u001b[0m      \u001b[32m0.4414\u001b[0m        \u001b[35m1.1854\u001b[0m  0.7272\n",
            "      2      \u001b[36m0.9253\u001b[0m      \u001b[32m0.9238\u001b[0m        \u001b[35m0.2191\u001b[0m  0.7116\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0081\u001b[0m  0.7121\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  0.7110\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7200\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7291\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7290\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7281\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7267\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7202\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5052\u001b[0m      \u001b[32m0.4474\u001b[0m        \u001b[35m1.1957\u001b[0m  1.0837\n",
            "      2      \u001b[36m0.9338\u001b[0m      \u001b[32m0.9316\u001b[0m        \u001b[35m0.2100\u001b[0m  1.0787\n",
            "      3      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0145\u001b[0m  1.0824\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.0787\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0806\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0646\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0650\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0631\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0570\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0049\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5055\u001b[0m      \u001b[32m0.4441\u001b[0m        \u001b[35m1.1859\u001b[0m  1.0807\n",
            "      2      \u001b[36m0.9408\u001b[0m      \u001b[32m0.9400\u001b[0m        \u001b[35m0.1834\u001b[0m  1.0794\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0090\u001b[0m  1.0632\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.0839\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0866\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0843\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0700\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0137\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0266\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0744\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5052\u001b[0m      \u001b[32m0.4413\u001b[0m        \u001b[35m1.1892\u001b[0m  1.0808\n",
            "      2      \u001b[36m0.9378\u001b[0m      \u001b[32m0.9367\u001b[0m        \u001b[35m0.1817\u001b[0m  1.0828\n",
            "      3      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0188\u001b[0m  1.0426\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  0.9967\n",
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9919\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0377\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0703\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0803\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0902\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0842\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5164\u001b[0m      \u001b[32m0.4533\u001b[0m        \u001b[35m1.1952\u001b[0m  1.0802\n",
            "      2      \u001b[36m0.9423\u001b[0m      \u001b[32m0.9413\u001b[0m        \u001b[35m0.1789\u001b[0m  1.0805\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0169\u001b[0m  1.0394\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  0.9961\n",
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9919\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0503\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0830\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0834\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0772\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0652\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5153\u001b[0m      \u001b[32m0.4536\u001b[0m        \u001b[35m1.1881\u001b[0m  1.0813\n",
            "      2      \u001b[36m0.9448\u001b[0m      \u001b[32m0.9442\u001b[0m        \u001b[35m0.1666\u001b[0m  1.0825\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0077\u001b[0m  1.0828\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0008\u001b[0m  1.0768\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.0817\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0825\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0795\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0630\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0623\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0134\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5048\u001b[0m      \u001b[32m0.4466\u001b[0m        \u001b[35m1.1931\u001b[0m  1.7330\n",
            "      2      \u001b[36m0.9316\u001b[0m      \u001b[32m0.9301\u001b[0m        \u001b[35m0.1940\u001b[0m  1.7282\n",
            "      3      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0221\u001b[0m  1.7888\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.7910\n",
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7684\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7915\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8197\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8069\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7671\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7493\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5059\u001b[0m      \u001b[32m0.4467\u001b[0m        \u001b[35m1.1933\u001b[0m  1.7963\n",
            "      2      \u001b[36m0.9371\u001b[0m      \u001b[32m0.9364\u001b[0m        \u001b[35m0.1824\u001b[0m  1.7429\n",
            "      3      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9912\u001b[0m        \u001b[35m0.0308\u001b[0m  1.7160\n",
            "      4      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0082\u001b[0m  1.7896\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0009\u001b[0m  1.7801\n",
            "      6      0.9996      0.9996        \u001b[35m0.0005\u001b[0m  1.7911\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0000\u001b[0m  1.8020\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7711\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8076\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7742\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4948\u001b[0m      \u001b[32m0.4401\u001b[0m        \u001b[35m1.1995\u001b[0m  1.7945\n",
            "      2      \u001b[36m0.9430\u001b[0m      \u001b[32m0.9423\u001b[0m        \u001b[35m0.1758\u001b[0m  1.7686\n",
            "      3      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9912\u001b[0m        \u001b[35m0.0265\u001b[0m  1.7316\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0077\u001b[0m  1.8248\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  1.8115\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7564\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7316\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7316\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7296\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7280\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5075\u001b[0m      \u001b[32m0.4488\u001b[0m        \u001b[35m1.2067\u001b[0m  1.7934\n",
            "      2      \u001b[36m0.9437\u001b[0m      \u001b[32m0.9429\u001b[0m        \u001b[35m0.1756\u001b[0m  1.8026\n",
            "      3      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0228\u001b[0m  1.7930\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0015\u001b[0m  1.8024\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.7893\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8010\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8023\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8003\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7923\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7848\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5061\u001b[0m      \u001b[32m0.4471\u001b[0m        \u001b[35m1.1939\u001b[0m  1.7184\n",
            "      2      \u001b[36m0.9452\u001b[0m      \u001b[32m0.9448\u001b[0m        \u001b[35m0.1580\u001b[0m  1.7108\n",
            "      3      \u001b[36m0.9879\u001b[0m      \u001b[32m0.9879\u001b[0m        \u001b[35m0.0377\u001b[0m  1.7110\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0061\u001b[0m  1.7107\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.7356\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7854\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7871\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8026\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7620\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7270\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5044\u001b[0m      \u001b[32m0.4456\u001b[0m        \u001b[35m1.2001\u001b[0m  3.3126\n",
            "      2      \u001b[36m0.9330\u001b[0m      \u001b[32m0.9320\u001b[0m        \u001b[35m0.2033\u001b[0m  3.2832\n",
            "      3      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.0516\u001b[0m  3.3005\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0044\u001b[0m  3.2717\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.2714\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2702\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2712\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2697\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2691\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2700\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5004\u001b[0m      \u001b[32m0.4440\u001b[0m        \u001b[35m1.2032\u001b[0m  3.2701\n",
            "      2      \u001b[36m0.9330\u001b[0m      \u001b[32m0.9327\u001b[0m        \u001b[35m0.1991\u001b[0m  3.2724\n",
            "      3      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9867\u001b[0m        \u001b[35m0.0430\u001b[0m  3.2722\n",
            "      4      \u001b[36m0.9923\u001b[0m      \u001b[32m0.9923\u001b[0m        \u001b[35m0.0194\u001b[0m  3.2720\n",
            "      5      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0117\u001b[0m  3.2708\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  3.2698\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2713\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3228\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2949\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2690\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4941\u001b[0m      \u001b[32m0.4397\u001b[0m        \u001b[35m1.2066\u001b[0m  3.2776\n",
            "      2      \u001b[36m0.9386\u001b[0m      \u001b[32m0.9380\u001b[0m        \u001b[35m0.1909\u001b[0m  3.3159\n",
            "      3      \u001b[36m0.9772\u001b[0m      \u001b[32m0.9772\u001b[0m        \u001b[35m0.0687\u001b[0m  3.2988\n",
            "      4      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.0624\u001b[0m  3.2697\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0053\u001b[0m  3.3153\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0031\u001b[0m  3.2748\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  3.3146\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2706\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3167\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2692\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5002\u001b[0m      \u001b[32m0.4411\u001b[0m        \u001b[35m1.2129\u001b[0m  3.3317\n",
            "      2      \u001b[36m0.9331\u001b[0m      \u001b[32m0.9324\u001b[0m        \u001b[35m0.2258\u001b[0m  3.2741\n",
            "      3      \u001b[36m0.9842\u001b[0m      \u001b[32m0.9842\u001b[0m        \u001b[35m0.0546\u001b[0m  3.2589\n",
            "      4      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0062\u001b[0m  3.2584\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.2630\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3209\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3235\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2889\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2619\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2602\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4987\u001b[0m      \u001b[32m0.4418\u001b[0m        \u001b[35m1.2033\u001b[0m  3.3069\n",
            "      2      \u001b[36m0.9367\u001b[0m      \u001b[32m0.9363\u001b[0m        \u001b[35m0.1783\u001b[0m  3.2864\n",
            "      3      \u001b[36m0.9801\u001b[0m      \u001b[32m0.9802\u001b[0m        \u001b[35m0.0712\u001b[0m  3.2989\n",
            "      4      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0223\u001b[0m  3.2956\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  3.3278\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2695\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3381\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2797\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2687\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2684\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5007\u001b[0m      \u001b[32m0.4427\u001b[0m        \u001b[35m1.1896\u001b[0m  0.6231\n",
            "      2      \u001b[36m0.9246\u001b[0m      \u001b[32m0.9221\u001b[0m        \u001b[35m0.2264\u001b[0m  0.6248\n",
            "      3      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0100\u001b[0m  0.6262\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  0.6259\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.6253\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6271\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6258\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6265\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6277\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7329\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7299\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7309\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7307\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7255\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7311\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7309\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7306\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7299\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7291\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7243\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5136\u001b[0m      \u001b[32m0.4477\u001b[0m        \u001b[35m1.1813\u001b[0m  0.7305\n",
            "      2      \u001b[36m0.9227\u001b[0m      \u001b[32m0.9207\u001b[0m        \u001b[35m0.2283\u001b[0m  0.7328\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0085\u001b[0m  0.7328\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.7327\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7337\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7206\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7139\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7145\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7138\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7082\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7258\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7130\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7289\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7281\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7334\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7309\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7281\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7303\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7322\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7210\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5037\u001b[0m      \u001b[32m0.4347\u001b[0m        \u001b[35m1.1926\u001b[0m  0.7124\n",
            "      2      \u001b[36m0.9301\u001b[0m      \u001b[32m0.9287\u001b[0m        \u001b[35m0.2105\u001b[0m  0.7340\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0077\u001b[0m  0.7339\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  0.7311\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7132\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7118\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7275\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7312\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7232\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7122\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7126\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7131\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7128\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7118\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7120\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7129\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7120\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7112\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7115\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7127\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5120\u001b[0m      \u001b[32m0.4436\u001b[0m        \u001b[35m1.1950\u001b[0m  0.7240\n",
            "      2      \u001b[36m0.9195\u001b[0m      \u001b[32m0.9169\u001b[0m        \u001b[35m0.2482\u001b[0m  0.7283\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0115\u001b[0m  0.7270\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.7313\n",
            "      5      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7295\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7136\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7132\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7128\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7142\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6919\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6699\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6495\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6263\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6297\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.6408\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7324\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7178\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7172\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7158\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7132\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5105\u001b[0m      \u001b[32m0.4463\u001b[0m        \u001b[35m1.1892\u001b[0m  0.7291\n",
            "      2      \u001b[36m0.9169\u001b[0m      \u001b[32m0.9150\u001b[0m        \u001b[35m0.2327\u001b[0m  0.7291\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0094\u001b[0m  0.7292\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.7287\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7145\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6878\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6653\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6491\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6362\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6286\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6260\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6251\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.6251\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7243\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7239\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7156\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7241\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7303\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7228\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.7143\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5037\u001b[0m      \u001b[32m0.4438\u001b[0m        \u001b[35m1.1942\u001b[0m  1.0766\n",
            "      2      \u001b[36m0.9294\u001b[0m      \u001b[32m0.9275\u001b[0m        \u001b[35m0.2153\u001b[0m  1.0792\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0130\u001b[0m  1.0788\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.0773\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0767\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0661\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0679\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0691\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0790\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0775\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0742\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0214\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9877\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9888\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9883\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9872\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9869\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9867\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9880\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9938\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5000\u001b[0m      \u001b[32m0.4384\u001b[0m        \u001b[35m1.1869\u001b[0m  1.0787\n",
            "      2      \u001b[36m0.9397\u001b[0m      \u001b[32m0.9388\u001b[0m        \u001b[35m0.1887\u001b[0m  1.0819\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0147\u001b[0m  1.0805\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.0512\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0806\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0828\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0800\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0791\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0445\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0831\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0833\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0830\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0815\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0706\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0653\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0527\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0023\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9875\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0632\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0851\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5063\u001b[0m      \u001b[32m0.4459\u001b[0m        \u001b[35m1.1895\u001b[0m  1.0850\n",
            "      2      \u001b[36m0.9448\u001b[0m      \u001b[32m0.9442\u001b[0m        \u001b[35m0.1672\u001b[0m  1.0822\n",
            "      3      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0106\u001b[0m  1.0830\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0007\u001b[0m  1.0733\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  1.0781\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0665\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0023\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9770\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0210\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0639\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0646\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0559\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0823\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0828\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0819\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0811\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0349\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9892\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9865\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9859\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5097\u001b[0m      \u001b[32m0.4468\u001b[0m        \u001b[35m1.1958\u001b[0m  0.9849\n",
            "      2      \u001b[36m0.9360\u001b[0m      \u001b[32m0.9345\u001b[0m        \u001b[35m0.1926\u001b[0m  0.9896\n",
            "      3      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0144\u001b[0m  0.9900\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  0.9907\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9945\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9915\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9884\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9917\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9911\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9924\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9914\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9912\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9906\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9907\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9914\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9905\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9911\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9902\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9922\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9908\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5138\u001b[0m      \u001b[32m0.4493\u001b[0m        \u001b[35m1.1857\u001b[0m  1.0398\n",
            "      2      \u001b[36m0.9470\u001b[0m      \u001b[32m0.9464\u001b[0m        \u001b[35m0.1599\u001b[0m  1.0661\n",
            "      3      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0146\u001b[0m  1.0561\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  1.0535\n",
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0651\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0665\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0652\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0816\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0804\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0786\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0829\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0835\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0814\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0808\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0852\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0812\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0803\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0800\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0612\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.0809\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5077\u001b[0m      \u001b[32m0.4484\u001b[0m        \u001b[35m1.1918\u001b[0m  1.7987\n",
            "      2      \u001b[36m0.9349\u001b[0m      \u001b[32m0.9335\u001b[0m        \u001b[35m0.1911\u001b[0m  1.8003\n",
            "      3      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0240\u001b[0m  1.7951\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0014\u001b[0m  1.8015\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.7937\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7322\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7253\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7254\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7257\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7247\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7269\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7261\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7265\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7269\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7255\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7258\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7273\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7177\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7123\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7550\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4993\u001b[0m      \u001b[32m0.4379\u001b[0m        \u001b[35m1.1911\u001b[0m  1.7971\n",
            "      2      \u001b[36m0.9345\u001b[0m      \u001b[32m0.9337\u001b[0m        \u001b[35m0.1842\u001b[0m  1.7578\n",
            "      3      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9912\u001b[0m        \u001b[35m0.0236\u001b[0m  1.7286\n",
            "      4      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0071\u001b[0m  1.7289\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0012\u001b[0m  1.7889\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.7453\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7265\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7551\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7909\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7320\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7269\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7501\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7869\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7303\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7282\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7278\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7290\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7277\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7272\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7273\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5022\u001b[0m      \u001b[32m0.4465\u001b[0m        \u001b[35m1.1979\u001b[0m  1.7958\n",
            "      2      \u001b[36m0.9393\u001b[0m      \u001b[32m0.9387\u001b[0m        \u001b[35m0.1777\u001b[0m  1.7848\n",
            "      3      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9893\u001b[0m        \u001b[35m0.0277\u001b[0m  1.7814\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0013\u001b[0m  1.7546\n",
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7944\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8011\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8056\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7869\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7555\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7219\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7218\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7223\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7214\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7573\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7624\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7151\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7209\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8006\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7976\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7935\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5097\u001b[0m      \u001b[32m0.4511\u001b[0m        \u001b[35m1.2050\u001b[0m  1.7946\n",
            "      2      \u001b[36m0.9389\u001b[0m      \u001b[32m0.9380\u001b[0m        \u001b[35m0.1822\u001b[0m  1.7415\n",
            "      3      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0227\u001b[0m  1.7248\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.7364\n",
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7843\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7793\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7325\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7852\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7823\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7298\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7496\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7914\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7294\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7259\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7253\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7251\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7259\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7353\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7984\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7450\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5120\u001b[0m      \u001b[32m0.4512\u001b[0m        \u001b[35m1.1919\u001b[0m  1.7862\n",
            "      2      \u001b[36m0.9478\u001b[0m      \u001b[32m0.9474\u001b[0m        \u001b[35m0.1512\u001b[0m  1.7830\n",
            "      3      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0252\u001b[0m  1.7245\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0017\u001b[0m  1.7113\n",
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7114\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7636\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7810\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7839\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.8011\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7916\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7654\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7904\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7398\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7292\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7254\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7250\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7529\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7962\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7325\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7244\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5052\u001b[0m      \u001b[32m0.4460\u001b[0m        \u001b[35m1.1995\u001b[0m  3.3453\n",
            "      2      \u001b[36m0.9323\u001b[0m      \u001b[32m0.9313\u001b[0m        \u001b[35m0.2115\u001b[0m  3.3273\n",
            "      3      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9867\u001b[0m        \u001b[35m0.0388\u001b[0m  3.3162\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0014\u001b[0m  3.2825\n",
            "      5      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3461\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2978\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2687\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2653\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2656\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2809\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3429\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2752\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2701\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2685\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2715\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2680\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3055\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2815\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2649\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3021\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5040\u001b[0m      \u001b[32m0.4491\u001b[0m        \u001b[35m1.2013\u001b[0m  3.3399\n",
            "      2      \u001b[36m0.9279\u001b[0m      \u001b[32m0.9272\u001b[0m        \u001b[35m0.2179\u001b[0m  3.2752\n",
            "      3      \u001b[36m0.9801\u001b[0m      \u001b[32m0.9801\u001b[0m        \u001b[35m0.0574\u001b[0m  3.2674\n",
            "      4      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9949\u001b[0m        \u001b[35m0.0115\u001b[0m  3.2664\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0007\u001b[0m  3.2667\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0000\u001b[0m  3.2676\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2983\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3421\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2722\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2852\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2958\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2639\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2644\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2640\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2596\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2599\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3331\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3092\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2686\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2679\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4967\u001b[0m      \u001b[32m0.4429\u001b[0m        \u001b[35m1.2105\u001b[0m  3.3409\n",
            "      2      \u001b[36m0.9367\u001b[0m      \u001b[32m0.9362\u001b[0m        \u001b[35m0.2066\u001b[0m  3.3538\n",
            "      3      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.0523\u001b[0m  3.3484\n",
            "      4      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0118\u001b[0m  3.3471\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.3456\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3501\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3043\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2668\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2656\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3248\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3068\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2848\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3011\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2983\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2680\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2703\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2791\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3173\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3549\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3193\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4950\u001b[0m      \u001b[32m0.4373\u001b[0m        \u001b[35m1.2166\u001b[0m  3.3555\n",
            "      2      \u001b[36m0.9401\u001b[0m      \u001b[32m0.9394\u001b[0m        \u001b[35m0.1922\u001b[0m  3.2918\n",
            "      3      \u001b[36m0.9890\u001b[0m      \u001b[32m0.9890\u001b[0m        \u001b[35m0.0399\u001b[0m  3.3008\n",
            "      4      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0103\u001b[0m  3.3012\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  3.3266\n",
            "      6      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2707\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2824\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3484\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3139\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2951\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3315\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3314\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2885\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2722\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2710\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2710\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2728\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2722\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3134\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3313\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4987\u001b[0m      \u001b[32m0.4416\u001b[0m        \u001b[35m1.2017\u001b[0m  3.2891\n",
            "      2      \u001b[36m0.9463\u001b[0m      \u001b[32m0.9460\u001b[0m        \u001b[35m0.1744\u001b[0m  3.2550\n",
            "      3      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9886\u001b[0m        \u001b[35m0.0321\u001b[0m  3.2549\n",
            "      4      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0174\u001b[0m  3.3233\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0023\u001b[0m  3.2824\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.2686\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2689\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2671\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3101\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2781\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3337\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3171\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3425\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2817\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2718\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2882\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2908\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2732\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2651\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3127\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4731\u001b[0m      \u001b[32m0.4144\u001b[0m        \u001b[35m1.2406\u001b[0m  0.7182\n",
            "      2      \u001b[36m0.7631\u001b[0m      \u001b[32m0.7489\u001b[0m        \u001b[35m0.6719\u001b[0m  0.7288\n",
            "      3      \u001b[36m0.8804\u001b[0m      \u001b[32m0.8777\u001b[0m        \u001b[35m0.3456\u001b[0m  0.7285\n",
            "      4      \u001b[36m0.9551\u001b[0m      \u001b[32m0.9550\u001b[0m        \u001b[35m0.1354\u001b[0m  0.7320\n",
            "      5      \u001b[36m0.9842\u001b[0m      \u001b[32m0.9841\u001b[0m        \u001b[35m0.0476\u001b[0m  0.7321\n",
            "      6      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0140\u001b[0m  0.7373\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0050\u001b[0m  0.7334\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0029\u001b[0m  0.7340\n",
            "      9      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  0.7370\n",
            "     10      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.7428\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4875\u001b[0m      \u001b[32m0.4281\u001b[0m        \u001b[35m1.2407\u001b[0m  0.7267\n",
            "      2      \u001b[36m0.7546\u001b[0m      \u001b[32m0.7401\u001b[0m        \u001b[35m0.7256\u001b[0m  0.7296\n",
            "      3      \u001b[36m0.8775\u001b[0m      \u001b[32m0.8745\u001b[0m        \u001b[35m0.3371\u001b[0m  0.7291\n",
            "      4      \u001b[36m0.9507\u001b[0m      \u001b[32m0.9503\u001b[0m        \u001b[35m0.1511\u001b[0m  0.7298\n",
            "      5      \u001b[36m0.9790\u001b[0m      \u001b[32m0.9790\u001b[0m        \u001b[35m0.0637\u001b[0m  0.7341\n",
            "      6      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0269\u001b[0m  0.7348\n",
            "      7      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0085\u001b[0m  0.7372\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0036\u001b[0m  0.7327\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0019\u001b[0m  0.7330\n",
            "     10      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.7323\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4735\u001b[0m      \u001b[32m0.4137\u001b[0m        \u001b[35m1.2444\u001b[0m  0.7117\n",
            "      2      \u001b[36m0.7410\u001b[0m      \u001b[32m0.7245\u001b[0m        \u001b[35m0.7289\u001b[0m  0.7140\n",
            "      3      \u001b[36m0.8760\u001b[0m      \u001b[32m0.8724\u001b[0m        \u001b[35m0.3847\u001b[0m  0.7137\n",
            "      4      \u001b[36m0.9408\u001b[0m      \u001b[32m0.9397\u001b[0m        \u001b[35m0.1851\u001b[0m  0.7143\n",
            "      5      \u001b[36m0.9761\u001b[0m      \u001b[32m0.9759\u001b[0m        \u001b[35m0.0799\u001b[0m  0.7135\n",
            "      6      \u001b[36m0.9897\u001b[0m      \u001b[32m0.9897\u001b[0m        \u001b[35m0.0393\u001b[0m  0.7147\n",
            "      7      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0201\u001b[0m  0.7128\n",
            "      8      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0081\u001b[0m  0.7136\n",
            "      9      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0059\u001b[0m  0.7116\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0039\u001b[0m  0.7189\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4844\u001b[0m      \u001b[32m0.4212\u001b[0m        \u001b[35m1.2388\u001b[0m  0.7299\n",
            "      2      \u001b[36m0.7477\u001b[0m      \u001b[32m0.7363\u001b[0m        \u001b[35m0.7591\u001b[0m  0.7311\n",
            "      3      \u001b[36m0.8691\u001b[0m      \u001b[32m0.8661\u001b[0m        \u001b[35m0.4063\u001b[0m  0.7322\n",
            "      4      \u001b[36m0.9393\u001b[0m      \u001b[32m0.9390\u001b[0m        \u001b[35m0.1722\u001b[0m  0.7332\n",
            "      5      \u001b[36m0.9879\u001b[0m      \u001b[32m0.9879\u001b[0m        \u001b[35m0.0379\u001b[0m  0.7201\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0035\u001b[0m  0.7153\n",
            "      7      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7143\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7142\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7137\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7210\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4836\u001b[0m      \u001b[32m0.4204\u001b[0m        \u001b[35m1.2397\u001b[0m  0.7282\n",
            "      2      \u001b[36m0.7554\u001b[0m      \u001b[32m0.7391\u001b[0m        \u001b[35m0.7280\u001b[0m  0.7284\n",
            "      3      \u001b[36m0.8757\u001b[0m      \u001b[32m0.8721\u001b[0m        \u001b[35m0.3901\u001b[0m  0.7261\n",
            "      4      \u001b[36m0.9511\u001b[0m      \u001b[32m0.9507\u001b[0m        \u001b[35m0.1542\u001b[0m  0.7124\n",
            "      5      \u001b[36m0.9790\u001b[0m      \u001b[32m0.9789\u001b[0m        \u001b[35m0.0605\u001b[0m  0.7115\n",
            "      6      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0135\u001b[0m  0.7105\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0046\u001b[0m  0.7147\n",
            "      8      0.9989      0.9989        \u001b[35m0.0034\u001b[0m  0.6961\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0026\u001b[0m  0.6729\n",
            "     10      0.9996      0.9996        \u001b[35m0.0021\u001b[0m  0.7336\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4834\u001b[0m      \u001b[32m0.4340\u001b[0m        \u001b[35m1.2623\u001b[0m  1.0944\n",
            "      2      \u001b[36m0.8201\u001b[0m      \u001b[32m0.8108\u001b[0m        \u001b[35m0.5444\u001b[0m  1.0851\n",
            "      3      \u001b[36m0.9400\u001b[0m      \u001b[32m0.9393\u001b[0m        \u001b[35m0.1973\u001b[0m  1.0850\n",
            "      4      \u001b[36m0.9772\u001b[0m      \u001b[32m0.9771\u001b[0m        \u001b[35m0.0677\u001b[0m  1.0835\n",
            "      5      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0153\u001b[0m  1.0729\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0024\u001b[0m  1.0210\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.0675\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0678\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0671\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0626\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4776\u001b[0m      \u001b[32m0.4161\u001b[0m        \u001b[35m1.2617\u001b[0m  1.0649\n",
            "      2      \u001b[36m0.7233\u001b[0m      \u001b[32m0.7104\u001b[0m        \u001b[35m0.8213\u001b[0m  1.0625\n",
            "      3      \u001b[36m0.8679\u001b[0m      \u001b[32m0.8657\u001b[0m        \u001b[35m0.3743\u001b[0m  1.0411\n",
            "      4      \u001b[36m0.9397\u001b[0m      \u001b[32m0.9392\u001b[0m        \u001b[35m0.1764\u001b[0m  1.0658\n",
            "      5      \u001b[36m0.9680\u001b[0m      \u001b[32m0.9679\u001b[0m        \u001b[35m0.0778\u001b[0m  1.0667\n",
            "      6      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0237\u001b[0m  1.0661\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0061\u001b[0m  1.0650\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0021\u001b[0m  1.0665\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  1.0809\n",
            "     10      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0672\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4838\u001b[0m      \u001b[32m0.4205\u001b[0m        \u001b[35m1.2570\u001b[0m  1.0788\n",
            "      2      \u001b[36m0.7403\u001b[0m      \u001b[32m0.7321\u001b[0m        \u001b[35m0.8029\u001b[0m  1.0686\n",
            "      3      \u001b[36m0.8985\u001b[0m      \u001b[32m0.8968\u001b[0m        \u001b[35m0.3223\u001b[0m  1.0598\n",
            "      4      \u001b[36m0.9448\u001b[0m      \u001b[32m0.9446\u001b[0m        \u001b[35m0.1701\u001b[0m  1.0695\n",
            "      5      \u001b[36m0.9897\u001b[0m      \u001b[32m0.9897\u001b[0m        \u001b[35m0.0355\u001b[0m  1.0652\n",
            "      6      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0109\u001b[0m  1.0640\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0033\u001b[0m  1.0647\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.0318\n",
            "      9      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.0677\n",
            "     10      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.0638\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4656\u001b[0m      \u001b[32m0.4042\u001b[0m        \u001b[35m1.2796\u001b[0m  1.0786\n",
            "      2      \u001b[36m0.7562\u001b[0m      \u001b[32m0.7487\u001b[0m        \u001b[35m0.7290\u001b[0m  1.0786\n",
            "      3      \u001b[36m0.9117\u001b[0m      \u001b[32m0.9108\u001b[0m        \u001b[35m0.2678\u001b[0m  1.0659\n",
            "      4      \u001b[36m0.9739\u001b[0m      \u001b[32m0.9739\u001b[0m        \u001b[35m0.0782\u001b[0m  1.0787\n",
            "      5      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0123\u001b[0m  1.0788\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0021\u001b[0m  1.0790\n",
            "      7      0.9993      0.9993        \u001b[35m0.0020\u001b[0m  1.0394\n",
            "      8      0.9996      0.9996        \u001b[35m0.0014\u001b[0m  0.9927\n",
            "      9      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.9899\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.9873\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4814\u001b[0m      \u001b[32m0.4197\u001b[0m        \u001b[35m1.2481\u001b[0m  0.9867\n",
            "      2      \u001b[36m0.7698\u001b[0m      \u001b[32m0.7634\u001b[0m        \u001b[35m0.7208\u001b[0m  0.9877\n",
            "      3      \u001b[36m0.8948\u001b[0m      \u001b[32m0.8940\u001b[0m        \u001b[35m0.3337\u001b[0m  1.0739\n",
            "      4      \u001b[36m0.9426\u001b[0m      \u001b[32m0.9421\u001b[0m        \u001b[35m0.1820\u001b[0m  1.0775\n",
            "      5      \u001b[36m0.9853\u001b[0m      \u001b[32m0.9853\u001b[0m        \u001b[35m0.0425\u001b[0m  1.0525\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0094\u001b[0m  1.0623\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0012\u001b[0m  1.0631\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0615\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0421\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0631\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4676\u001b[0m      \u001b[32m0.4240\u001b[0m        \u001b[35m1.3599\u001b[0m  1.7998\n",
            "      2      \u001b[36m0.8256\u001b[0m      \u001b[32m0.8202\u001b[0m        \u001b[35m0.5433\u001b[0m  1.8002\n",
            "      3      \u001b[36m0.9268\u001b[0m      \u001b[32m0.9264\u001b[0m        \u001b[35m0.2208\u001b[0m  1.7641\n",
            "      4      \u001b[36m0.9772\u001b[0m      \u001b[32m0.9771\u001b[0m        \u001b[35m0.0663\u001b[0m  1.7130\n",
            "      5      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0113\u001b[0m  1.7192\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  1.7838\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7787\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7882\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7885\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7331\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4713\u001b[0m      \u001b[32m0.4162\u001b[0m        \u001b[35m1.3142\u001b[0m  1.7973\n",
            "      2      \u001b[36m0.7299\u001b[0m      \u001b[32m0.7211\u001b[0m        \u001b[35m0.9498\u001b[0m  1.7458\n",
            "      3      \u001b[36m0.8848\u001b[0m      \u001b[32m0.8832\u001b[0m        \u001b[35m0.3765\u001b[0m  1.7252\n",
            "      4      \u001b[36m0.9397\u001b[0m      \u001b[32m0.9394\u001b[0m        \u001b[35m0.1839\u001b[0m  1.7387\n",
            "      5      \u001b[36m0.9753\u001b[0m      \u001b[32m0.9753\u001b[0m        \u001b[35m0.0822\u001b[0m  1.7906\n",
            "      6      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0217\u001b[0m  1.7916\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  1.7689\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7551\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7945\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7952\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4816\u001b[0m      \u001b[32m0.4265\u001b[0m        \u001b[35m1.3047\u001b[0m  1.7930\n",
            "      2      \u001b[36m0.7653\u001b[0m      \u001b[32m0.7585\u001b[0m        \u001b[35m0.7151\u001b[0m  1.7405\n",
            "      3      \u001b[36m0.8922\u001b[0m      \u001b[32m0.8912\u001b[0m        \u001b[35m0.3329\u001b[0m  1.7222\n",
            "      4      \u001b[36m0.9669\u001b[0m      \u001b[32m0.9668\u001b[0m        \u001b[35m0.1004\u001b[0m  1.7212\n",
            "      5      \u001b[36m0.9853\u001b[0m      \u001b[32m0.9853\u001b[0m        \u001b[35m0.0327\u001b[0m  1.7219\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0068\u001b[0m  1.7210\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7225\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7251\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7207\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7367\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4708\u001b[0m      \u001b[32m0.4169\u001b[0m        \u001b[35m1.3238\u001b[0m  1.7200\n",
            "      2      \u001b[36m0.7587\u001b[0m      \u001b[32m0.7460\u001b[0m        \u001b[35m0.8246\u001b[0m  1.7260\n",
            "      3      \u001b[36m0.9000\u001b[0m      \u001b[32m0.8978\u001b[0m        \u001b[35m0.3226\u001b[0m  1.7240\n",
            "      4      \u001b[36m0.9595\u001b[0m      \u001b[32m0.9593\u001b[0m        \u001b[35m0.1264\u001b[0m  1.7245\n",
            "      5      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.0448\u001b[0m  1.8000\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0078\u001b[0m  1.7755\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  1.7675\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7546\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7098\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7078\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4763\u001b[0m      \u001b[32m0.4174\u001b[0m        \u001b[35m1.2867\u001b[0m  1.7945\n",
            "      2      \u001b[36m0.7613\u001b[0m      \u001b[32m0.7538\u001b[0m        \u001b[35m0.8223\u001b[0m  1.7397\n",
            "      3      \u001b[36m0.8889\u001b[0m      \u001b[32m0.8874\u001b[0m        \u001b[35m0.3864\u001b[0m  1.7208\n",
            "      4      \u001b[36m0.9570\u001b[0m      \u001b[32m0.9568\u001b[0m        \u001b[35m0.1350\u001b[0m  1.7563\n",
            "      5      \u001b[36m0.9897\u001b[0m      \u001b[32m0.9897\u001b[0m        \u001b[35m0.0315\u001b[0m  1.7910\n",
            "      6      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0135\u001b[0m  1.7844\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0018\u001b[0m  1.7768\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.7164\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7100\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7083\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4684\u001b[0m      \u001b[32m0.4269\u001b[0m        \u001b[35m1.4485\u001b[0m  3.2824\n",
            "      2      \u001b[36m0.8411\u001b[0m      \u001b[32m0.8384\u001b[0m        \u001b[35m0.5481\u001b[0m  3.3047\n",
            "      3      \u001b[36m0.9441\u001b[0m      \u001b[32m0.9436\u001b[0m        \u001b[35m0.1764\u001b[0m  3.2691\n",
            "      4      \u001b[36m0.9923\u001b[0m      \u001b[32m0.9923\u001b[0m        \u001b[35m0.0254\u001b[0m  3.2693\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  3.2671\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2679\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3101\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3422\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2734\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2694\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4779\u001b[0m      \u001b[32m0.4259\u001b[0m        \u001b[35m1.4011\u001b[0m  3.3078\n",
            "      2      \u001b[36m0.7472\u001b[0m      \u001b[32m0.7417\u001b[0m        \u001b[35m0.8451\u001b[0m  3.3231\n",
            "      3      \u001b[36m0.8937\u001b[0m      \u001b[32m0.8928\u001b[0m        \u001b[35m0.3646\u001b[0m  3.3017\n",
            "      4      \u001b[36m0.9636\u001b[0m      \u001b[32m0.9635\u001b[0m        \u001b[35m0.1310\u001b[0m  3.3276\n",
            "      5      \u001b[36m0.9871\u001b[0m      \u001b[32m0.9871\u001b[0m        \u001b[35m0.0415\u001b[0m  3.2686\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0029\u001b[0m  3.2652\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.3031\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2508\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2619\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2979\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4816\u001b[0m      \u001b[32m0.4292\u001b[0m        \u001b[35m1.4302\u001b[0m  3.3072\n",
            "      2      \u001b[36m0.7870\u001b[0m      \u001b[32m0.7790\u001b[0m        \u001b[35m0.6805\u001b[0m  3.2831\n",
            "      3      \u001b[36m0.9139\u001b[0m      \u001b[32m0.9133\u001b[0m        \u001b[35m0.2665\u001b[0m  3.2983\n",
            "      4      \u001b[36m0.9547\u001b[0m      \u001b[32m0.9546\u001b[0m        \u001b[35m0.1447\u001b[0m  3.2607\n",
            "      5      \u001b[36m0.9842\u001b[0m      \u001b[32m0.9842\u001b[0m        \u001b[35m0.0486\u001b[0m  3.2635\n",
            "      6      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0130\u001b[0m  3.2675\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0010\u001b[0m  3.2627\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  3.2654\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2701\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3451\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4777\u001b[0m      \u001b[32m0.4244\u001b[0m        \u001b[35m1.3981\u001b[0m  3.3298\n",
            "      2      \u001b[36m0.7525\u001b[0m      \u001b[32m0.7473\u001b[0m        \u001b[35m0.8567\u001b[0m  3.2673\n",
            "      3      \u001b[36m0.8926\u001b[0m      \u001b[32m0.8916\u001b[0m        \u001b[35m0.3554\u001b[0m  3.2678\n",
            "      4      \u001b[36m0.9735\u001b[0m      \u001b[32m0.9735\u001b[0m        \u001b[35m0.0804\u001b[0m  3.2668\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0083\u001b[0m  3.2688\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  3.2667\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  3.3128\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2668\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2694\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2681\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4579\u001b[0m      \u001b[32m0.4073\u001b[0m        \u001b[35m1.4388\u001b[0m  3.2696\n",
            "      2      \u001b[36m0.7267\u001b[0m      \u001b[32m0.7186\u001b[0m        \u001b[35m0.9496\u001b[0m  3.3248\n",
            "      3      \u001b[36m0.8680\u001b[0m      \u001b[32m0.8670\u001b[0m        \u001b[35m0.4759\u001b[0m  3.2740\n",
            "      4      \u001b[36m0.9562\u001b[0m      \u001b[32m0.9561\u001b[0m        \u001b[35m0.1388\u001b[0m  3.3297\n",
            "      5      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9867\u001b[0m        \u001b[35m0.0372\u001b[0m  3.2753\n",
            "      6      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0263\u001b[0m  3.3297\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0018\u001b[0m  3.2706\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.2658\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2664\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2665\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4761\u001b[0m      \u001b[32m0.4203\u001b[0m        \u001b[35m1.2457\u001b[0m  0.7351\n",
            "      2      \u001b[36m0.7770\u001b[0m      \u001b[32m0.7665\u001b[0m        \u001b[35m0.6914\u001b[0m  0.7305\n",
            "      3      \u001b[36m0.8859\u001b[0m      \u001b[32m0.8846\u001b[0m        \u001b[35m0.3435\u001b[0m  0.7302\n",
            "      4      \u001b[36m0.9507\u001b[0m      \u001b[32m0.9505\u001b[0m        \u001b[35m0.1292\u001b[0m  0.7328\n",
            "      5      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9886\u001b[0m        \u001b[35m0.0372\u001b[0m  0.7331\n",
            "      6      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0115\u001b[0m  0.7330\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0052\u001b[0m  0.7248\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0023\u001b[0m  0.7345\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  0.7336\n",
            "     10      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7337\n",
            "     11      1.0000      1.0000        0.0009  0.7787\n",
            "     12      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7365\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7342\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7346\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7319\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7190\n",
            "     17      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.6896\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6648\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6737\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7189\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4739\u001b[0m      \u001b[32m0.4165\u001b[0m        \u001b[35m1.2464\u001b[0m  0.7335\n",
            "      2      \u001b[36m0.7299\u001b[0m      \u001b[32m0.7209\u001b[0m        \u001b[35m0.8129\u001b[0m  0.7213\n",
            "      3      \u001b[36m0.8731\u001b[0m      \u001b[32m0.8712\u001b[0m        \u001b[35m0.3780\u001b[0m  0.7477\n",
            "      4      \u001b[36m0.9533\u001b[0m      \u001b[32m0.9530\u001b[0m        \u001b[35m0.1378\u001b[0m  0.7798\n",
            "      5      \u001b[36m0.9834\u001b[0m      \u001b[32m0.9835\u001b[0m        \u001b[35m0.0496\u001b[0m  0.7476\n",
            "      6      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0164\u001b[0m  0.7410\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0074\u001b[0m  0.7379\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0041\u001b[0m  0.7401\n",
            "      9      0.9989      0.9989        \u001b[35m0.0030\u001b[0m  0.7346\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0023\u001b[0m  0.7378\n",
            "     11      0.9996      0.9996        \u001b[35m0.0016\u001b[0m  0.7370\n",
            "     12      0.9996      0.9996        \u001b[35m0.0013\u001b[0m  0.7331\n",
            "     13      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  0.7310\n",
            "     14      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7281\n",
            "     15      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7583\n",
            "     16      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7557\n",
            "     17      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7561\n",
            "     18      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7496\n",
            "     19      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7348\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7344\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4783\u001b[0m      \u001b[32m0.4194\u001b[0m        \u001b[35m1.2421\u001b[0m  0.7238\n",
            "      2      \u001b[36m0.7899\u001b[0m      \u001b[32m0.7793\u001b[0m        \u001b[35m0.6162\u001b[0m  0.7382\n",
            "      3      \u001b[36m0.8966\u001b[0m      \u001b[32m0.8948\u001b[0m        \u001b[35m0.3199\u001b[0m  0.7362\n",
            "      4      \u001b[36m0.9551\u001b[0m      \u001b[32m0.9547\u001b[0m        \u001b[35m0.1238\u001b[0m  0.7330\n",
            "      5      \u001b[36m0.9904\u001b[0m      \u001b[32m0.9904\u001b[0m        \u001b[35m0.0400\u001b[0m  0.7322\n",
            "      6      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0117\u001b[0m  0.7319\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0044\u001b[0m  0.7328\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0023\u001b[0m  0.7322\n",
            "      9      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.7317\n",
            "     10      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.7292\n",
            "     11      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7086\n",
            "     12      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7208\n",
            "     13      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7304\n",
            "     14      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7351\n",
            "     15      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7349\n",
            "     16      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7344\n",
            "     17      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7300\n",
            "     18      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7180\n",
            "     19      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7171\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7233\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4800\u001b[0m      \u001b[32m0.4168\u001b[0m        \u001b[35m1.2516\u001b[0m  0.6979\n",
            "      2      \u001b[36m0.7128\u001b[0m      \u001b[32m0.6960\u001b[0m        \u001b[35m0.8438\u001b[0m  0.7159\n",
            "      3      \u001b[36m0.8477\u001b[0m      \u001b[32m0.8435\u001b[0m        \u001b[35m0.4657\u001b[0m  0.7147\n",
            "      4      \u001b[36m0.9312\u001b[0m      \u001b[32m0.9306\u001b[0m        \u001b[35m0.2045\u001b[0m  0.7145\n",
            "      5      \u001b[36m0.9687\u001b[0m      \u001b[32m0.9686\u001b[0m        \u001b[35m0.0944\u001b[0m  0.7338\n",
            "      6      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9886\u001b[0m        \u001b[35m0.0297\u001b[0m  0.7328\n",
            "      7      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0107\u001b[0m  0.7310\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0059\u001b[0m  0.7317\n",
            "      9      0.9989      0.9989        \u001b[35m0.0043\u001b[0m  0.7316\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0035\u001b[0m  0.7119\n",
            "     11      0.9993      0.9993        \u001b[35m0.0029\u001b[0m  0.6799\n",
            "     12      0.9993      0.9993        \u001b[35m0.0025\u001b[0m  0.6520\n",
            "     13      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0017\u001b[0m  0.6370\n",
            "     14      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.6368\n",
            "     15      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.6960\n",
            "     16      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7329\n",
            "     17      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7365\n",
            "     18      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7336\n",
            "     19      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7331\n",
            "     20      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7162\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4722\u001b[0m      \u001b[32m0.4105\u001b[0m        \u001b[35m1.2453\u001b[0m  0.7100\n",
            "      2      \u001b[36m0.7367\u001b[0m      \u001b[32m0.7256\u001b[0m        \u001b[35m0.7994\u001b[0m  0.7128\n",
            "      3      \u001b[36m0.8724\u001b[0m      \u001b[32m0.8710\u001b[0m        \u001b[35m0.3912\u001b[0m  0.7137\n",
            "      4      \u001b[36m0.9603\u001b[0m      \u001b[32m0.9600\u001b[0m        \u001b[35m0.1214\u001b[0m  0.7059\n",
            "      5      \u001b[36m0.9823\u001b[0m      \u001b[32m0.9823\u001b[0m        \u001b[35m0.0515\u001b[0m  0.6832\n",
            "      6      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0113\u001b[0m  0.6685\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0034\u001b[0m  0.6529\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0016\u001b[0m  0.6416\n",
            "      9      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.6324\n",
            "     10      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.6288\n",
            "     11      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.6309\n",
            "     12      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.6294\n",
            "     13      1.0000      1.0000        0.0007  0.6780\n",
            "     14      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7273\n",
            "     15      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7142\n",
            "     16      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7297\n",
            "     17      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7303\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7300\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7168\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6890\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4757\u001b[0m      \u001b[32m0.4251\u001b[0m        \u001b[35m1.2848\u001b[0m  1.0004\n",
            "      2      \u001b[36m0.8068\u001b[0m      \u001b[32m0.7950\u001b[0m        \u001b[35m0.5864\u001b[0m  0.9910\n",
            "      3      \u001b[36m0.9213\u001b[0m      \u001b[32m0.9203\u001b[0m        \u001b[35m0.2297\u001b[0m  0.9873\n",
            "      4      \u001b[36m0.9617\u001b[0m      \u001b[32m0.9614\u001b[0m        \u001b[35m0.1100\u001b[0m  0.9793\n",
            "      5      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9908\u001b[0m        \u001b[35m0.0243\u001b[0m  1.0678\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0059\u001b[0m  1.0798\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0024\u001b[0m  1.0742\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0019\u001b[0m  1.0217\n",
            "      9      0.9996      0.9996        \u001b[35m0.0011\u001b[0m  0.9909\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  0.9894\n",
            "     11      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9900\n",
            "     12      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9893\n",
            "     13      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9895\n",
            "     14      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0335\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0875\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0807\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0326\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0017\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0831\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0804\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4893\u001b[0m      \u001b[32m0.4361\u001b[0m        \u001b[35m1.2516\u001b[0m  1.0813\n",
            "      2      \u001b[36m0.7701\u001b[0m      \u001b[32m0.7632\u001b[0m        \u001b[35m0.7113\u001b[0m  1.0829\n",
            "      3      \u001b[36m0.8948\u001b[0m      \u001b[32m0.8933\u001b[0m        \u001b[35m0.3071\u001b[0m  1.0620\n",
            "      4      \u001b[36m0.9647\u001b[0m      \u001b[32m0.9645\u001b[0m        \u001b[35m0.1122\u001b[0m  0.9947\n",
            "      5      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0183\u001b[0m  0.9777\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0023\u001b[0m  0.9767\n",
            "      7      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.9765\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9762\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0603\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0874\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0879\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0841\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0838\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0835\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0841\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0881\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0860\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0846\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0736\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0169\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4798\u001b[0m      \u001b[32m0.4207\u001b[0m        \u001b[35m1.2609\u001b[0m  1.0770\n",
            "      2      \u001b[36m0.7815\u001b[0m      \u001b[32m0.7733\u001b[0m        \u001b[35m0.6611\u001b[0m  1.0796\n",
            "      3      \u001b[36m0.9047\u001b[0m      \u001b[32m0.9030\u001b[0m        \u001b[35m0.3166\u001b[0m  1.0590\n",
            "      4      \u001b[36m0.9503\u001b[0m      \u001b[32m0.9500\u001b[0m        \u001b[35m0.1579\u001b[0m  1.0080\n",
            "      5      \u001b[36m0.9834\u001b[0m      \u001b[32m0.9834\u001b[0m        \u001b[35m0.0475\u001b[0m  0.9880\n",
            "      6      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0068\u001b[0m  0.9876\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0014\u001b[0m  0.9882\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  0.9870\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0698\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0725\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0659\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0800\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0892\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0670\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0660\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0639\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0639\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0710\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0824\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0788\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4759\u001b[0m      \u001b[32m0.4222\u001b[0m        \u001b[35m1.2704\u001b[0m  1.0553\n",
            "      2      \u001b[36m0.7459\u001b[0m      \u001b[32m0.7337\u001b[0m        \u001b[35m0.8245\u001b[0m  1.0691\n",
            "      3      \u001b[36m0.8860\u001b[0m      \u001b[32m0.8836\u001b[0m        \u001b[35m0.3757\u001b[0m  1.0800\n",
            "      4      \u001b[36m0.9515\u001b[0m      \u001b[32m0.9512\u001b[0m        \u001b[35m0.1502\u001b[0m  1.0784\n",
            "      5      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9908\u001b[0m        \u001b[35m0.0305\u001b[0m  1.0366\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0055\u001b[0m  0.9925\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0025\u001b[0m  0.9906\n",
            "      8      0.9996      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0017\u001b[0m  0.9913\n",
            "      9      0.9996      0.9996        \u001b[35m0.0013\u001b[0m  0.9907\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  0.9776\n",
            "     11      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9744\n",
            "     12      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0177\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0854\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0783\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0822\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0703\n",
            "     17      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0139\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9899\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0188\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0639\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4759\u001b[0m      \u001b[32m0.4212\u001b[0m        \u001b[35m1.2668\u001b[0m  1.0812\n",
            "      2      \u001b[36m0.7532\u001b[0m      \u001b[32m0.7451\u001b[0m        \u001b[35m0.7545\u001b[0m  1.0824\n",
            "      3      \u001b[36m0.8867\u001b[0m      \u001b[32m0.8855\u001b[0m        \u001b[35m0.3377\u001b[0m  1.0759\n",
            "      4      \u001b[36m0.9353\u001b[0m      \u001b[32m0.9349\u001b[0m        \u001b[35m0.1941\u001b[0m  1.0662\n",
            "      5      \u001b[36m0.9816\u001b[0m      \u001b[32m0.9815\u001b[0m        \u001b[35m0.0512\u001b[0m  1.0600\n",
            "      6      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0115\u001b[0m  1.0198\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0019\u001b[0m  1.0675\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  1.0646\n",
            "      9      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.0462\n",
            "     10      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.0725\n",
            "     11      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0649\n",
            "     12      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.0662\n",
            "     13      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0720\n",
            "     14      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0812\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0451\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9972\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0362\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0777\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0656\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0636\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4801\u001b[0m      \u001b[32m0.4323\u001b[0m        \u001b[35m1.3332\u001b[0m  1.8003\n",
            "      2      \u001b[36m0.8061\u001b[0m      \u001b[32m0.7990\u001b[0m        \u001b[35m0.6005\u001b[0m  1.7967\n",
            "      3      \u001b[36m0.9327\u001b[0m      \u001b[32m0.9321\u001b[0m        \u001b[35m0.2028\u001b[0m  1.7716\n",
            "      4      \u001b[36m0.9834\u001b[0m      \u001b[32m0.9834\u001b[0m        \u001b[35m0.0563\u001b[0m  1.7274\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0070\u001b[0m  1.7249\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  1.7267\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7269\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7250\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7719\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7770\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7246\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7242\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7834\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7994\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7983\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7833\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7830\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7852\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7313\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7221\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4742\u001b[0m      \u001b[32m0.4162\u001b[0m        \u001b[35m1.2981\u001b[0m  1.7860\n",
            "      2      \u001b[36m0.7498\u001b[0m      \u001b[32m0.7393\u001b[0m        \u001b[35m0.8035\u001b[0m  1.7308\n",
            "      3      \u001b[36m0.8723\u001b[0m      \u001b[32m0.8707\u001b[0m        \u001b[35m0.4006\u001b[0m  1.7254\n",
            "      4      \u001b[36m0.9496\u001b[0m      \u001b[32m0.9495\u001b[0m        \u001b[35m0.1528\u001b[0m  1.7231\n",
            "      5      \u001b[36m0.9864\u001b[0m      \u001b[32m0.9864\u001b[0m        \u001b[35m0.0424\u001b[0m  1.7489\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0057\u001b[0m  1.7825\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  1.7253\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7222\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7120\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7509\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7797\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7566\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7972\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7342\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7250\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7209\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7205\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7215\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7204\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7208\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4893\u001b[0m      \u001b[32m0.4371\u001b[0m        \u001b[35m1.2984\u001b[0m  1.7207\n",
            "      2      \u001b[36m0.7822\u001b[0m      \u001b[32m0.7747\u001b[0m        \u001b[35m0.6702\u001b[0m  1.7250\n",
            "      3      \u001b[36m0.9169\u001b[0m      \u001b[32m0.9163\u001b[0m        \u001b[35m0.2566\u001b[0m  1.7237\n",
            "      4      \u001b[36m0.9665\u001b[0m      \u001b[32m0.9665\u001b[0m        \u001b[35m0.1019\u001b[0m  1.7272\n",
            "      5      \u001b[36m0.9901\u001b[0m      \u001b[32m0.9901\u001b[0m        \u001b[35m0.0261\u001b[0m  1.7347\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0043\u001b[0m  1.8012\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0008\u001b[0m  1.7416\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  1.7214\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7246\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7860\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7689\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7246\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7280\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7960\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7355\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7259\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7256\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7257\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7098\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7726\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4822\u001b[0m      \u001b[32m0.4286\u001b[0m        \u001b[35m1.3136\u001b[0m  1.7585\n",
            "      2      \u001b[36m0.7525\u001b[0m      \u001b[32m0.7420\u001b[0m        \u001b[35m0.7692\u001b[0m  1.7243\n",
            "      3      \u001b[36m0.9029\u001b[0m      \u001b[32m0.9014\u001b[0m        \u001b[35m0.2918\u001b[0m  1.7235\n",
            "      4      \u001b[36m0.9548\u001b[0m      \u001b[32m0.9546\u001b[0m        \u001b[35m0.1163\u001b[0m  1.7247\n",
            "      5      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9927\u001b[0m        \u001b[35m0.0242\u001b[0m  1.7538\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0021\u001b[0m  1.7824\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.7638\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7998\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7925\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7867\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7702\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7140\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7132\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7478\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7830\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7816\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7816\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7891\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7499\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7949\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4759\u001b[0m      \u001b[32m0.4239\u001b[0m        \u001b[35m1.3291\u001b[0m  1.7305\n",
            "      2      \u001b[36m0.7705\u001b[0m      \u001b[32m0.7634\u001b[0m        \u001b[35m0.7540\u001b[0m  1.7270\n",
            "      3      \u001b[36m0.8952\u001b[0m      \u001b[32m0.8943\u001b[0m        \u001b[35m0.3424\u001b[0m  1.7257\n",
            "      4      \u001b[36m0.9540\u001b[0m      \u001b[32m0.9540\u001b[0m        \u001b[35m0.1379\u001b[0m  1.7236\n",
            "      5      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9868\u001b[0m        \u001b[35m0.0402\u001b[0m  1.7727\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0067\u001b[0m  1.8016\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  1.7820\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7228\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7264\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7306\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.8013\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7473\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7261\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7237\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7225\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7222\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7251\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7816\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7899\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7997\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4753\u001b[0m      \u001b[32m0.4382\u001b[0m        \u001b[35m1.4777\u001b[0m  3.3318\n",
            "      2      \u001b[36m0.8223\u001b[0m      \u001b[32m0.8190\u001b[0m        \u001b[35m0.6403\u001b[0m  3.3142\n",
            "      3      \u001b[36m0.9352\u001b[0m      \u001b[32m0.9349\u001b[0m        \u001b[35m0.2248\u001b[0m  3.3427\n",
            "      4      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0309\u001b[0m  3.2822\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0011\u001b[0m  3.3392\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.2741\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3213\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3123\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3203\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3037\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3201\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2659\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3209\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2638\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2601\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3207\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2681\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2710\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3154\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2668\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4798\u001b[0m      \u001b[32m0.4227\u001b[0m        \u001b[35m1.4098\u001b[0m  3.3458\n",
            "      2      \u001b[36m0.7469\u001b[0m      \u001b[32m0.7399\u001b[0m        \u001b[35m0.9426\u001b[0m  3.2911\n",
            "      3      \u001b[36m0.8896\u001b[0m      \u001b[32m0.8886\u001b[0m        \u001b[35m0.3866\u001b[0m  3.3189\n",
            "      4      \u001b[36m0.9610\u001b[0m      \u001b[32m0.9609\u001b[0m        \u001b[35m0.1331\u001b[0m  3.2689\n",
            "      5      \u001b[36m0.9915\u001b[0m      \u001b[32m0.9915\u001b[0m        \u001b[35m0.0234\u001b[0m  3.3439\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0050\u001b[0m  3.3240\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  3.2674\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2699\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3216\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3279\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3351\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2898\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2669\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3181\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2694\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2673\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2671\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3169\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2699\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2674\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4735\u001b[0m      \u001b[32m0.4245\u001b[0m        \u001b[35m1.3829\u001b[0m  3.3185\n",
            "      2      \u001b[36m0.7873\u001b[0m      \u001b[32m0.7816\u001b[0m        \u001b[35m0.7755\u001b[0m  3.2702\n",
            "      3      \u001b[36m0.8999\u001b[0m      \u001b[32m0.8993\u001b[0m        \u001b[35m0.3329\u001b[0m  3.2663\n",
            "      4      \u001b[36m0.9673\u001b[0m      \u001b[32m0.9672\u001b[0m        \u001b[35m0.1137\u001b[0m  3.2658\n",
            "      5      \u001b[36m0.9915\u001b[0m      \u001b[32m0.9915\u001b[0m        \u001b[35m0.0234\u001b[0m  3.2682\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  3.2673\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.2674\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2676\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2686\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2639\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3326\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3038\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2905\n",
            "     14      1.0000      1.0000        0.0000  3.3083\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3072\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.2701\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3158\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3377\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3237\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3143\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4822\u001b[0m      \u001b[32m0.4309\u001b[0m        \u001b[35m1.4257\u001b[0m  3.3073\n",
            "      2      \u001b[36m0.7937\u001b[0m      \u001b[32m0.7876\u001b[0m        \u001b[35m0.7289\u001b[0m  3.6151\n",
            "      3      \u001b[36m0.9011\u001b[0m      \u001b[32m0.9004\u001b[0m        \u001b[35m0.3322\u001b[0m  3.2617\n",
            "      4      \u001b[36m0.9684\u001b[0m      \u001b[32m0.9683\u001b[0m        \u001b[35m0.0960\u001b[0m  3.2603\n",
            "      5      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.0472\u001b[0m  3.2610\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0026\u001b[0m  3.2605\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  3.2597\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3074\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3417\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.3592\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3379\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.3203\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.4777\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  3.7945\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.2662\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.1683\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  5.6992\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.3842\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9600\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9663\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4833\u001b[0m      \u001b[32m0.4320\u001b[0m        \u001b[35m1.3943\u001b[0m  7.9802\n",
            "      2      \u001b[36m0.7841\u001b[0m      \u001b[32m0.7791\u001b[0m        \u001b[35m0.7932\u001b[0m  7.9769\n",
            "      3      \u001b[36m0.8996\u001b[0m      \u001b[32m0.8991\u001b[0m        \u001b[35m0.3480\u001b[0m  7.9648\n",
            "      4      \u001b[36m0.9629\u001b[0m      \u001b[32m0.9628\u001b[0m        \u001b[35m0.1274\u001b[0m  7.9630\n",
            "      5      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9893\u001b[0m        \u001b[35m0.0380\u001b[0m  7.9847\n",
            "      6      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0108\u001b[0m  7.9451\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  7.9790\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  8.0370\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9834\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9805\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  8.0041\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9713\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9274\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9474\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9634\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  8.0169\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9764\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9700\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9811\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  7.9644\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4198\u001b[0m      \u001b[32m0.3907\u001b[0m        \u001b[35m1.3569\u001b[0m  1.3598\n",
            "      2      \u001b[36m0.5890\u001b[0m      \u001b[32m0.4989\u001b[0m        \u001b[35m1.0940\u001b[0m  1.3724\n",
            "      3      \u001b[36m0.7605\u001b[0m      \u001b[32m0.6974\u001b[0m        \u001b[35m0.7638\u001b[0m  1.3688\n",
            "      4      \u001b[36m0.8988\u001b[0m      \u001b[32m0.8869\u001b[0m        \u001b[35m0.3807\u001b[0m  1.3786\n",
            "      5      \u001b[36m0.9779\u001b[0m      \u001b[32m0.9775\u001b[0m        \u001b[35m0.1683\u001b[0m  1.3884\n",
            "      6      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0849\u001b[0m  1.3667\n",
            "      7      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0496\u001b[0m  1.3826\n",
            "      8      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0321\u001b[0m  1.3675\n",
            "      9      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0222\u001b[0m  1.3758\n",
            "     10      0.9993      0.9993        \u001b[35m0.0162\u001b[0m  1.3474\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4415\u001b[0m      \u001b[32m0.3932\u001b[0m        \u001b[35m1.3480\u001b[0m  1.3770\n",
            "      2      \u001b[36m0.5721\u001b[0m      \u001b[32m0.4742\u001b[0m        \u001b[35m1.0980\u001b[0m  1.3815\n",
            "      3      \u001b[36m0.7568\u001b[0m      \u001b[32m0.6916\u001b[0m        \u001b[35m0.7701\u001b[0m  1.3572\n",
            "      4      \u001b[36m0.8966\u001b[0m      \u001b[32m0.8838\u001b[0m        \u001b[35m0.3892\u001b[0m  1.3620\n",
            "      5      \u001b[36m0.9709\u001b[0m      \u001b[32m0.9703\u001b[0m        \u001b[35m0.1742\u001b[0m  1.3523\n",
            "      6      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9911\u001b[0m        \u001b[35m0.0881\u001b[0m  1.4004\n",
            "      7      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0517\u001b[0m  1.3825\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0337\u001b[0m  1.3752\n",
            "      9      0.9989      0.9989        \u001b[35m0.0236\u001b[0m  1.3381\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0173\u001b[0m  1.3670\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4610\u001b[0m      \u001b[32m0.3922\u001b[0m        \u001b[35m1.3331\u001b[0m  1.3819\n",
            "      2      \u001b[36m0.5809\u001b[0m      \u001b[32m0.4877\u001b[0m        \u001b[35m1.0937\u001b[0m  1.3908\n",
            "      3      \u001b[36m0.7524\u001b[0m      \u001b[32m0.6881\u001b[0m        \u001b[35m0.7518\u001b[0m  1.3798\n",
            "      4      \u001b[36m0.9091\u001b[0m      \u001b[32m0.9003\u001b[0m        \u001b[35m0.3681\u001b[0m  1.3832\n",
            "      5      \u001b[36m0.9765\u001b[0m      \u001b[32m0.9760\u001b[0m        \u001b[35m0.1634\u001b[0m  1.3774\n",
            "      6      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0824\u001b[0m  1.3773\n",
            "      7      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0477\u001b[0m  1.3708\n",
            "      8      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0307\u001b[0m  1.3872\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0213\u001b[0m  1.3935\n",
            "     10      1.0000      1.0000        \u001b[35m0.0155\u001b[0m  1.3849\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4277\u001b[0m      \u001b[32m0.3276\u001b[0m        \u001b[35m1.3595\u001b[0m  1.3790\n",
            "      2      \u001b[36m0.5756\u001b[0m      \u001b[32m0.4792\u001b[0m        \u001b[35m1.1020\u001b[0m  1.3742\n",
            "      3      \u001b[36m0.7598\u001b[0m      \u001b[32m0.6912\u001b[0m        \u001b[35m0.7774\u001b[0m  1.3922\n",
            "      4      \u001b[36m0.8978\u001b[0m      \u001b[32m0.8856\u001b[0m        \u001b[35m0.3931\u001b[0m  1.3773\n",
            "      5      \u001b[36m0.9739\u001b[0m      \u001b[32m0.9732\u001b[0m        \u001b[35m0.1771\u001b[0m  1.3619\n",
            "      6      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9918\u001b[0m        \u001b[35m0.0895\u001b[0m  1.3604\n",
            "      7      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0524\u001b[0m  1.3732\n",
            "      8      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0341\u001b[0m  1.3619\n",
            "      9      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0238\u001b[0m  1.3673\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0174\u001b[0m  1.3727\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4899\u001b[0m      \u001b[32m0.3258\u001b[0m        \u001b[35m1.3264\u001b[0m  1.3857\n",
            "      2      \u001b[36m0.5748\u001b[0m      \u001b[32m0.4798\u001b[0m        \u001b[35m1.0976\u001b[0m  1.3558\n",
            "      3      \u001b[36m0.7613\u001b[0m      \u001b[32m0.6976\u001b[0m        \u001b[35m0.7493\u001b[0m  1.3678\n",
            "      4      \u001b[36m0.9040\u001b[0m      \u001b[32m0.8929\u001b[0m        \u001b[35m0.3631\u001b[0m  1.3791\n",
            "      5      \u001b[36m0.9776\u001b[0m      \u001b[32m0.9770\u001b[0m        \u001b[35m0.1605\u001b[0m  1.3634\n",
            "      6      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9933\u001b[0m        \u001b[35m0.0808\u001b[0m  1.3726\n",
            "      7      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0472\u001b[0m  1.3863\n",
            "      8      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0307\u001b[0m  1.3594\n",
            "      9      0.9985      0.9985        \u001b[35m0.0213\u001b[0m  1.3678\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0156\u001b[0m  1.3850\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4592\u001b[0m      \u001b[32m0.4109\u001b[0m        \u001b[35m1.3071\u001b[0m  1.7606\n",
            "      2      \u001b[36m0.6748\u001b[0m      \u001b[32m0.6059\u001b[0m        \u001b[35m0.9949\u001b[0m  1.7407\n",
            "      3      \u001b[36m0.8396\u001b[0m      \u001b[32m0.8082\u001b[0m        \u001b[35m0.5183\u001b[0m  1.7470\n",
            "      4      \u001b[36m0.9662\u001b[0m      \u001b[32m0.9651\u001b[0m        \u001b[35m0.1783\u001b[0m  1.7509\n",
            "      5      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9892\u001b[0m        \u001b[35m0.0720\u001b[0m  1.7399\n",
            "      6      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0375\u001b[0m  1.7288\n",
            "      7      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0226\u001b[0m  1.7221\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0149\u001b[0m  1.7414\n",
            "      9      0.9996      0.9996        \u001b[35m0.0105\u001b[0m  1.7569\n",
            "     10      0.9996      0.9996        \u001b[35m0.0078\u001b[0m  1.7400\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4798\u001b[0m      \u001b[32m0.3335\u001b[0m        \u001b[35m1.3032\u001b[0m  1.7458\n",
            "      2      \u001b[36m0.6571\u001b[0m      \u001b[32m0.5867\u001b[0m        \u001b[35m1.0002\u001b[0m  1.7628\n",
            "      3      \u001b[36m0.8322\u001b[0m      \u001b[32m0.7986\u001b[0m        \u001b[35m0.5252\u001b[0m  1.7490\n",
            "      4      \u001b[36m0.9658\u001b[0m      \u001b[32m0.9648\u001b[0m        \u001b[35m0.1791\u001b[0m  1.7597\n",
            "      5      \u001b[36m0.9915\u001b[0m      \u001b[32m0.9915\u001b[0m        \u001b[35m0.0711\u001b[0m  1.7645\n",
            "      6      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0372\u001b[0m  1.7616\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0228\u001b[0m  1.7547\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0153\u001b[0m  1.7266\n",
            "      9      0.9996      0.9996        \u001b[35m0.0109\u001b[0m  1.7425\n",
            "     10      0.9996      0.9996        \u001b[35m0.0081\u001b[0m  1.7483\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4724\u001b[0m      \u001b[32m0.3258\u001b[0m        \u001b[35m1.3049\u001b[0m  1.7272\n",
            "      2      \u001b[36m0.6413\u001b[0m      \u001b[32m0.5691\u001b[0m        \u001b[35m1.0075\u001b[0m  1.7316\n",
            "      3      \u001b[36m0.8403\u001b[0m      \u001b[32m0.8129\u001b[0m        \u001b[35m0.5179\u001b[0m  1.7555\n",
            "      4      \u001b[36m0.9643\u001b[0m      \u001b[32m0.9631\u001b[0m        \u001b[35m0.1785\u001b[0m  1.7469\n",
            "      5      \u001b[36m0.9923\u001b[0m      \u001b[32m0.9922\u001b[0m        \u001b[35m0.0712\u001b[0m  1.7208\n",
            "      6      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0365\u001b[0m  1.7435\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0219\u001b[0m  1.7397\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0145\u001b[0m  1.7347\n",
            "      9      1.0000      1.0000        \u001b[35m0.0102\u001b[0m  1.7078\n",
            "     10      1.0000      1.0000        \u001b[35m0.0075\u001b[0m  1.7233\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4840\u001b[0m      \u001b[32m0.3316\u001b[0m        \u001b[35m1.2985\u001b[0m  1.7250\n",
            "      2      \u001b[36m0.6657\u001b[0m      \u001b[32m0.5956\u001b[0m        \u001b[35m1.0024\u001b[0m  1.7410\n",
            "      3      \u001b[36m0.8275\u001b[0m      \u001b[32m0.7906\u001b[0m        \u001b[35m0.5427\u001b[0m  1.7257\n",
            "      4      \u001b[36m0.9643\u001b[0m      \u001b[32m0.9632\u001b[0m        \u001b[35m0.1888\u001b[0m  1.7638\n",
            "      5      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9918\u001b[0m        \u001b[35m0.0730\u001b[0m  1.7354\n",
            "      6      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0375\u001b[0m  1.7143\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0228\u001b[0m  1.7341\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0152\u001b[0m  1.7424\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0107\u001b[0m  1.7191\n",
            "     10      0.9996      0.9996        \u001b[35m0.0080\u001b[0m  1.7611\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4759\u001b[0m      \u001b[32m0.3333\u001b[0m        \u001b[35m1.3056\u001b[0m  1.7595\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      2      \u001b[36m0.6513\u001b[0m      \u001b[32m0.5788\u001b[0m        \u001b[35m1.0029\u001b[0m  1.7342\n",
            "      3      \u001b[36m0.8308\u001b[0m      \u001b[32m0.7967\u001b[0m        \u001b[35m0.5438\u001b[0m  1.7372\n",
            "      4      \u001b[36m0.9621\u001b[0m      \u001b[32m0.9606\u001b[0m        \u001b[35m0.1956\u001b[0m  1.7371\n",
            "      5      \u001b[36m0.9923\u001b[0m      \u001b[32m0.9922\u001b[0m        \u001b[35m0.0755\u001b[0m  1.7267\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0380\u001b[0m  1.7534\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0227\u001b[0m  1.7687\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0150\u001b[0m  1.7473\n",
            "      9      0.9996      0.9996        \u001b[35m0.0105\u001b[0m  1.7206\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0078\u001b[0m  1.7455\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4742\u001b[0m      \u001b[32m0.4148\u001b[0m        \u001b[35m1.2880\u001b[0m  2.4822\n",
            "      2      \u001b[36m0.7241\u001b[0m      \u001b[32m0.6568\u001b[0m        \u001b[35m0.8740\u001b[0m  2.4878\n",
            "      3      \u001b[36m0.9102\u001b[0m      \u001b[32m0.9019\u001b[0m        \u001b[35m0.3134\u001b[0m  2.4786\n",
            "      4      \u001b[36m0.9838\u001b[0m      \u001b[32m0.9836\u001b[0m        \u001b[35m0.0830\u001b[0m  2.4616\n",
            "      5      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0338\u001b[0m  2.5007\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0178\u001b[0m  2.4532\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0108\u001b[0m  2.4921\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0072\u001b[0m  2.4937\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0051\u001b[0m  2.4660\n",
            "     10      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  2.5071\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4971\u001b[0m      \u001b[32m0.3460\u001b[0m        \u001b[35m1.2765\u001b[0m  2.5004\n",
            "      2      \u001b[36m0.7060\u001b[0m      \u001b[32m0.6383\u001b[0m        \u001b[35m0.8798\u001b[0m  2.4403\n",
            "      3      \u001b[36m0.9065\u001b[0m      \u001b[32m0.8979\u001b[0m        \u001b[35m0.3217\u001b[0m  2.4111\n",
            "      4      \u001b[36m0.9864\u001b[0m      \u001b[32m0.9862\u001b[0m        \u001b[35m0.0853\u001b[0m  2.4621\n",
            "      5      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0346\u001b[0m  2.4642\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0189\u001b[0m  2.4425\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0117\u001b[0m  2.4568\n",
            "      8      0.9996      0.9996        \u001b[35m0.0079\u001b[0m  2.4462\n",
            "      9      0.9996      0.9996        \u001b[35m0.0057\u001b[0m  2.4550\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0042\u001b[0m  2.4224\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4831\u001b[0m      \u001b[32m0.3600\u001b[0m        \u001b[35m1.2770\u001b[0m  2.4589\n",
            "      2      \u001b[36m0.7123\u001b[0m      \u001b[32m0.6456\u001b[0m        \u001b[35m0.8675\u001b[0m  2.4499\n",
            "      3      \u001b[36m0.9146\u001b[0m      \u001b[32m0.9077\u001b[0m        \u001b[35m0.3096\u001b[0m  2.4709\n",
            "      4      \u001b[36m0.9882\u001b[0m      \u001b[32m0.9881\u001b[0m        \u001b[35m0.0840\u001b[0m  2.4410\n",
            "      5      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0328\u001b[0m  2.4510\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0173\u001b[0m  2.4528\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0106\u001b[0m  2.4508\n",
            "      8      1.0000      1.0000        \u001b[35m0.0071\u001b[0m  2.4495\n",
            "      9      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  2.4577\n",
            "     10      1.0000      1.0000        \u001b[35m0.0037\u001b[0m  2.4741\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4792\u001b[0m      \u001b[32m0.3454\u001b[0m        \u001b[35m1.2751\u001b[0m  2.4767\n",
            "      2      \u001b[36m0.7120\u001b[0m      \u001b[32m0.6445\u001b[0m        \u001b[35m0.8789\u001b[0m  2.4821\n",
            "      3      \u001b[36m0.9092\u001b[0m      \u001b[32m0.9009\u001b[0m        \u001b[35m0.3208\u001b[0m  2.4850\n",
            "      4      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9885\u001b[0m        \u001b[35m0.0841\u001b[0m  2.4582\n",
            "      5      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0342\u001b[0m  2.4488\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0186\u001b[0m  2.4831\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0115\u001b[0m  2.4968\n",
            "      8      0.9996      0.9996        \u001b[35m0.0078\u001b[0m  2.4710\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0056\u001b[0m  2.4461\n",
            "     10      1.0000      1.0000        \u001b[35m0.0041\u001b[0m  2.4826\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4925\u001b[0m      \u001b[32m0.3377\u001b[0m        \u001b[35m1.2696\u001b[0m  2.4802\n",
            "      2      \u001b[36m0.7087\u001b[0m      \u001b[32m0.6412\u001b[0m        \u001b[35m0.8701\u001b[0m  2.4999\n",
            "      3      \u001b[36m0.9132\u001b[0m      \u001b[32m0.9061\u001b[0m        \u001b[35m0.3096\u001b[0m  2.4615\n",
            "      4      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9884\u001b[0m        \u001b[35m0.0809\u001b[0m  2.4693\n",
            "      5      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0323\u001b[0m  2.4617\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0174\u001b[0m  2.4843\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0107\u001b[0m  2.4718\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0072\u001b[0m  2.4808\n",
            "      9      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  2.5105\n",
            "     10      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  2.4977\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4809\u001b[0m      \u001b[32m0.3998\u001b[0m        \u001b[35m1.2590\u001b[0m  4.0083\n",
            "      2      \u001b[36m0.7553\u001b[0m      \u001b[32m0.7022\u001b[0m        \u001b[35m0.7346\u001b[0m  4.0266\n",
            "      3      \u001b[36m0.9606\u001b[0m      \u001b[32m0.9594\u001b[0m        \u001b[35m0.1669\u001b[0m  4.0344\n",
            "      4      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0391\u001b[0m  4.0486\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0165\u001b[0m  4.0614\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0090\u001b[0m  4.0411\n",
            "      7      0.9996      0.9996        \u001b[35m0.0056\u001b[0m  3.9875\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0038\u001b[0m  4.0094\n",
            "      9      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  4.0126\n",
            "     10      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  4.0288\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4956\u001b[0m      \u001b[32m0.3946\u001b[0m        \u001b[35m1.2629\u001b[0m  4.0465\n",
            "      2      \u001b[36m0.7513\u001b[0m      \u001b[32m0.6986\u001b[0m        \u001b[35m0.7357\u001b[0m  4.0442\n",
            "      3      \u001b[36m0.9592\u001b[0m      \u001b[32m0.9581\u001b[0m        \u001b[35m0.1735\u001b[0m  4.0378\n",
            "      4      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0408\u001b[0m  4.0317\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0178\u001b[0m  4.0327\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0100\u001b[0m  4.0350\n",
            "      7      0.9996      0.9996        \u001b[35m0.0063\u001b[0m  4.0265\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0043\u001b[0m  4.0513\n",
            "      9      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  4.0891\n",
            "     10      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  4.1054\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4919\u001b[0m      \u001b[32m0.3822\u001b[0m        \u001b[35m1.2554\u001b[0m  4.0789\n",
            "      2      \u001b[36m0.7583\u001b[0m      \u001b[32m0.7078\u001b[0m        \u001b[35m0.7176\u001b[0m  4.0739\n",
            "      3      \u001b[36m0.9573\u001b[0m      \u001b[32m0.9559\u001b[0m        \u001b[35m0.1649\u001b[0m  4.0459\n",
            "      4      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0386\u001b[0m  4.0378\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0159\u001b[0m  4.0344\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0087\u001b[0m  4.0238\n",
            "      7      1.0000      1.0000        \u001b[35m0.0054\u001b[0m  4.0179\n",
            "      8      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  4.0360\n",
            "      9      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  4.0175\n",
            "     10      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  4.0066\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4928\u001b[0m      \u001b[32m0.3750\u001b[0m        \u001b[35m1.2563\u001b[0m  4.0222\n",
            "      2      \u001b[36m0.7532\u001b[0m      \u001b[32m0.6977\u001b[0m        \u001b[35m0.7358\u001b[0m  4.0271\n",
            "      3      \u001b[36m0.9566\u001b[0m      \u001b[32m0.9555\u001b[0m        \u001b[35m0.1740\u001b[0m  4.0423\n",
            "      4      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0395\u001b[0m  4.0364\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0171\u001b[0m  4.0318\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0095\u001b[0m  4.0388\n",
            "      7      0.9996      0.9996        \u001b[35m0.0060\u001b[0m  3.9955\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0041\u001b[0m  4.0058\n",
            "      9      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  4.0159\n",
            "     10      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  4.0371\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4987\u001b[0m      \u001b[32m0.3780\u001b[0m        \u001b[35m1.2538\u001b[0m  4.0005\n",
            "      2      \u001b[36m0.7565\u001b[0m      \u001b[32m0.7058\u001b[0m        \u001b[35m0.7195\u001b[0m  4.0238\n",
            "      3      \u001b[36m0.9603\u001b[0m      \u001b[32m0.9589\u001b[0m        \u001b[35m0.1594\u001b[0m  4.0522\n",
            "      4      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0362\u001b[0m  4.0308\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0158\u001b[0m  4.0606\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0088\u001b[0m  4.0332\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0055\u001b[0m  4.0394\n",
            "      8      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  4.0449\n",
            "      9      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  4.0320\n",
            "     10      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  4.0303\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4323\u001b[0m      \u001b[32m0.3752\u001b[0m        \u001b[35m1.3599\u001b[0m  1.3745\n",
            "      2      \u001b[36m0.5990\u001b[0m      \u001b[32m0.5125\u001b[0m        \u001b[35m1.0960\u001b[0m  1.3906\n",
            "      3      \u001b[36m0.7609\u001b[0m      \u001b[32m0.6957\u001b[0m        \u001b[35m0.7621\u001b[0m  1.3816\n",
            "      4      \u001b[36m0.9043\u001b[0m      \u001b[32m0.8943\u001b[0m        \u001b[35m0.3794\u001b[0m  1.3732\n",
            "      5      \u001b[36m0.9776\u001b[0m      \u001b[32m0.9771\u001b[0m        \u001b[35m0.1657\u001b[0m  1.3682\n",
            "      6      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0836\u001b[0m  1.3701\n",
            "      7      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0491\u001b[0m  1.3740\n",
            "      8      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0319\u001b[0m  1.3493\n",
            "      9      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0222\u001b[0m  1.3713\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0162\u001b[0m  1.3552\n",
            "     11      0.9996      0.9996        \u001b[35m0.0123\u001b[0m  1.3455\n",
            "     12      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0096\u001b[0m  1.3588\n",
            "     13      1.0000      1.0000        \u001b[35m0.0077\u001b[0m  1.3560\n",
            "     14      1.0000      1.0000        \u001b[35m0.0063\u001b[0m  1.3814\n",
            "     15      1.0000      1.0000        \u001b[35m0.0052\u001b[0m  1.3901\n",
            "     16      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  1.3670\n",
            "     17      1.0000      1.0000        \u001b[35m0.0037\u001b[0m  1.3880\n",
            "     18      1.0000      1.0000        \u001b[35m0.0032\u001b[0m  1.3875\n",
            "     19      1.0000      1.0000        \u001b[35m0.0028\u001b[0m  1.3872\n",
            "     20      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.3679\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4349\u001b[0m      \u001b[32m0.3934\u001b[0m        \u001b[35m1.3608\u001b[0m  1.3804\n",
            "      2      \u001b[36m0.5747\u001b[0m      \u001b[32m0.4782\u001b[0m        \u001b[35m1.1067\u001b[0m  1.3705\n",
            "      3      \u001b[36m0.7631\u001b[0m      \u001b[32m0.6972\u001b[0m        \u001b[35m0.7881\u001b[0m  1.3691\n",
            "      4      \u001b[36m0.8999\u001b[0m      \u001b[32m0.8882\u001b[0m        \u001b[35m0.3954\u001b[0m  1.3934\n",
            "      5      \u001b[36m0.9761\u001b[0m      \u001b[32m0.9756\u001b[0m        \u001b[35m0.1748\u001b[0m  1.3607\n",
            "      6      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9918\u001b[0m        \u001b[35m0.0883\u001b[0m  1.3792\n",
            "      7      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0518\u001b[0m  1.3691\n",
            "      8      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0338\u001b[0m  1.3581\n",
            "      9      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0236\u001b[0m  1.3741\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0173\u001b[0m  1.3630\n",
            "     11      0.9996      0.9996        \u001b[35m0.0132\u001b[0m  1.3676\n",
            "     12      0.9996      0.9996        \u001b[35m0.0103\u001b[0m  1.3848\n",
            "     13      0.9996      0.9996        \u001b[35m0.0083\u001b[0m  1.3559\n",
            "     14      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0068\u001b[0m  1.3556\n",
            "     15      1.0000      1.0000        \u001b[35m0.0057\u001b[0m  1.3744\n",
            "     16      1.0000      1.0000        \u001b[35m0.0048\u001b[0m  1.3626\n",
            "     17      1.0000      1.0000        \u001b[35m0.0041\u001b[0m  1.3600\n",
            "     18      1.0000      1.0000        \u001b[35m0.0035\u001b[0m  1.3517\n",
            "     19      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.3845\n",
            "     20      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  1.3807\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4503\u001b[0m      \u001b[32m0.3165\u001b[0m        \u001b[35m1.3489\u001b[0m  1.3659\n",
            "      2      \u001b[36m0.5673\u001b[0m      \u001b[32m0.4683\u001b[0m        \u001b[35m1.0921\u001b[0m  1.3675\n",
            "      3      \u001b[36m0.7586\u001b[0m      \u001b[32m0.6948\u001b[0m        \u001b[35m0.7602\u001b[0m  1.3906\n",
            "      4      \u001b[36m0.9018\u001b[0m      \u001b[32m0.8926\u001b[0m        \u001b[35m0.3818\u001b[0m  1.3962\n",
            "      5      \u001b[36m0.9735\u001b[0m      \u001b[32m0.9729\u001b[0m        \u001b[35m0.1715\u001b[0m  1.3650\n",
            "      6      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9933\u001b[0m        \u001b[35m0.0859\u001b[0m  1.3809\n",
            "      7      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0494\u001b[0m  1.3494\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0316\u001b[0m  1.3699\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0218\u001b[0m  1.3540\n",
            "     10      1.0000      1.0000        \u001b[35m0.0158\u001b[0m  1.3685\n",
            "     11      1.0000      1.0000        \u001b[35m0.0119\u001b[0m  1.3770\n",
            "     12      1.0000      1.0000        \u001b[35m0.0093\u001b[0m  1.3646\n",
            "     13      1.0000      1.0000        \u001b[35m0.0074\u001b[0m  1.3492\n",
            "     14      1.0000      1.0000        \u001b[35m0.0061\u001b[0m  1.3518\n",
            "     15      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  1.3546\n",
            "     16      1.0000      1.0000        \u001b[35m0.0043\u001b[0m  1.3883\n",
            "     17      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  1.3826\n",
            "     18      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.3622\n",
            "     19      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  1.3663\n",
            "     20      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.3667\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4862\u001b[0m      \u001b[32m0.3338\u001b[0m        \u001b[35m1.3220\u001b[0m  1.3705\n",
            "      2      \u001b[36m0.5991\u001b[0m      \u001b[32m0.5142\u001b[0m        \u001b[35m1.0860\u001b[0m  1.3799\n",
            "      3      \u001b[36m0.7672\u001b[0m      \u001b[32m0.6993\u001b[0m        \u001b[35m0.7504\u001b[0m  1.3625\n",
            "      4      \u001b[36m0.8967\u001b[0m      \u001b[32m0.8833\u001b[0m        \u001b[35m0.3800\u001b[0m  1.3712\n",
            "      5      \u001b[36m0.9743\u001b[0m      \u001b[32m0.9736\u001b[0m        \u001b[35m0.1716\u001b[0m  1.3438\n",
            "      6      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0856\u001b[0m  1.3566\n",
            "      7      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0496\u001b[0m  1.3668\n",
            "      8      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0321\u001b[0m  1.3614\n",
            "      9      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0223\u001b[0m  1.3496\n",
            "     10      0.9993      0.9993        \u001b[35m0.0163\u001b[0m  1.3841\n",
            "     11      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0124\u001b[0m  1.3562\n",
            "     12      0.9996      0.9996        \u001b[35m0.0097\u001b[0m  1.3505\n",
            "     13      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0078\u001b[0m  1.3912\n",
            "     14      1.0000      1.0000        \u001b[35m0.0064\u001b[0m  1.3736\n",
            "     15      1.0000      1.0000        \u001b[35m0.0053\u001b[0m  1.3783\n",
            "     16      1.0000      1.0000        \u001b[35m0.0045\u001b[0m  1.3788\n",
            "     17      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  1.3771\n",
            "     18      1.0000      1.0000        \u001b[35m0.0033\u001b[0m  1.3472\n",
            "     19      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.3578\n",
            "     20      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  1.3633\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4678\u001b[0m      \u001b[32m0.3578\u001b[0m        \u001b[35m1.3189\u001b[0m  1.3763\n",
            "      2      \u001b[36m0.5668\u001b[0m      \u001b[32m0.4648\u001b[0m        \u001b[35m1.0918\u001b[0m  1.3773\n",
            "      3      \u001b[36m0.7580\u001b[0m      \u001b[32m0.6923\u001b[0m        \u001b[35m0.7603\u001b[0m  1.3603\n",
            "      4      \u001b[36m0.9110\u001b[0m      \u001b[32m0.9025\u001b[0m        \u001b[35m0.3680\u001b[0m  1.3640\n",
            "      5      \u001b[36m0.9812\u001b[0m      \u001b[32m0.9809\u001b[0m        \u001b[35m0.1592\u001b[0m  1.3610\n",
            "      6      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0789\u001b[0m  1.3653\n",
            "      7      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0460\u001b[0m  1.3899\n",
            "      8      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0299\u001b[0m  1.3656\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0209\u001b[0m  1.3710\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0153\u001b[0m  1.3576\n",
            "     11      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0116\u001b[0m  1.3866\n",
            "     12      1.0000      1.0000        \u001b[35m0.0091\u001b[0m  1.3611\n",
            "     13      1.0000      1.0000        \u001b[35m0.0073\u001b[0m  1.3776\n",
            "     14      1.0000      1.0000        \u001b[35m0.0060\u001b[0m  1.3550\n",
            "     15      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  1.3891\n",
            "     16      1.0000      1.0000        \u001b[35m0.0042\u001b[0m  1.3951\n",
            "     17      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  1.3772\n",
            "     18      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.3698\n",
            "     19      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  1.3913\n",
            "     20      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  1.3684\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4680\u001b[0m      \u001b[32m0.3836\u001b[0m        \u001b[35m1.3071\u001b[0m  1.7574\n",
            "      2      \u001b[36m0.6600\u001b[0m      \u001b[32m0.5889\u001b[0m        \u001b[35m1.0111\u001b[0m  1.7469\n",
            "      3      \u001b[36m0.8429\u001b[0m      \u001b[32m0.8144\u001b[0m        \u001b[35m0.5260\u001b[0m  1.7458\n",
            "      4      \u001b[36m0.9687\u001b[0m      \u001b[32m0.9679\u001b[0m        \u001b[35m0.1753\u001b[0m  1.7404\n",
            "      5      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0697\u001b[0m  1.7286\n",
            "      6      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0362\u001b[0m  1.7303\n",
            "      7      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0218\u001b[0m  1.7457\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0144\u001b[0m  1.7459\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0102\u001b[0m  1.7403\n",
            "     10      0.9996      0.9996        \u001b[35m0.0075\u001b[0m  1.7300\n",
            "     11      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0058\u001b[0m  1.7387\n",
            "     12      1.0000      1.0000        \u001b[35m0.0046\u001b[0m  1.7474\n",
            "     13      1.0000      1.0000        \u001b[35m0.0037\u001b[0m  1.7485\n",
            "     14      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.7462\n",
            "     15      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  1.7279\n",
            "     16      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.7228\n",
            "     17      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.7421\n",
            "     18      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.7324\n",
            "     19      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  1.7324\n",
            "     20      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.7498\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4772\u001b[0m      \u001b[32m0.3726\u001b[0m        \u001b[35m1.3011\u001b[0m  1.7443\n",
            "      2      \u001b[36m0.6604\u001b[0m      \u001b[32m0.5898\u001b[0m        \u001b[35m0.9845\u001b[0m  1.7420\n",
            "      3      \u001b[36m0.8429\u001b[0m      \u001b[32m0.8113\u001b[0m        \u001b[35m0.5096\u001b[0m  1.7304\n",
            "      4      \u001b[36m0.9639\u001b[0m      \u001b[32m0.9628\u001b[0m        \u001b[35m0.1821\u001b[0m  1.7249\n",
            "      5      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9911\u001b[0m        \u001b[35m0.0746\u001b[0m  1.7475\n",
            "      6      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0389\u001b[0m  1.7347\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0238\u001b[0m  1.7447\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0159\u001b[0m  1.7371\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0112\u001b[0m  1.7385\n",
            "     10      0.9996      0.9996        \u001b[35m0.0083\u001b[0m  1.7269\n",
            "     11      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0064\u001b[0m  1.7335\n",
            "     12      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  1.7380\n",
            "     13      1.0000      1.0000        \u001b[35m0.0041\u001b[0m  1.7279\n",
            "     14      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  1.7334\n",
            "     15      1.0000      1.0000        \u001b[35m0.0028\u001b[0m  1.7158\n",
            "     16      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.7117\n",
            "     17      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  1.7261\n",
            "     18      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.7215\n",
            "     19      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.7272\n",
            "     20      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.7285\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4750\u001b[0m      \u001b[32m0.3425\u001b[0m        \u001b[35m1.2999\u001b[0m  1.7263\n",
            "      2      \u001b[36m0.6582\u001b[0m      \u001b[32m0.5868\u001b[0m        \u001b[35m0.9984\u001b[0m  1.7422\n",
            "      3      \u001b[36m0.8366\u001b[0m      \u001b[32m0.8033\u001b[0m        \u001b[35m0.5221\u001b[0m  1.7560\n",
            "      4      \u001b[36m0.9588\u001b[0m      \u001b[32m0.9572\u001b[0m        \u001b[35m0.1797\u001b[0m  1.7619\n",
            "      5      \u001b[36m0.9923\u001b[0m      \u001b[32m0.9922\u001b[0m        \u001b[35m0.0708\u001b[0m  1.7312\n",
            "      6      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0359\u001b[0m  1.7429\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0215\u001b[0m  1.7215\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0141\u001b[0m  1.7497\n",
            "      9      1.0000      1.0000        \u001b[35m0.0099\u001b[0m  1.7330\n",
            "     10      1.0000      1.0000        \u001b[35m0.0073\u001b[0m  1.7360\n",
            "     11      1.0000      1.0000        \u001b[35m0.0056\u001b[0m  1.7382\n",
            "     12      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  1.7204\n",
            "     13      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  1.7591\n",
            "     14      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.7354\n",
            "     15      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  1.7561\n",
            "     16      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.7415\n",
            "     17      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.7366\n",
            "     18      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.7453\n",
            "     19      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.7390\n",
            "     20      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.7624\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4505\u001b[0m      \u001b[32m0.3642\u001b[0m        \u001b[35m1.3004\u001b[0m  1.7401\n",
            "      2      \u001b[36m0.6675\u001b[0m      \u001b[32m0.5974\u001b[0m        \u001b[35m0.9988\u001b[0m  1.7295\n",
            "      3      \u001b[36m0.8264\u001b[0m      \u001b[32m0.7930\u001b[0m        \u001b[35m0.5326\u001b[0m  1.7273\n",
            "      4      \u001b[36m0.9658\u001b[0m      \u001b[32m0.9648\u001b[0m        \u001b[35m0.1835\u001b[0m  1.7356\n",
            "      5      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0711\u001b[0m  1.7295\n",
            "      6      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0367\u001b[0m  1.7490\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0223\u001b[0m  1.7393\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0148\u001b[0m  1.7314\n",
            "      9      0.9996      0.9996        \u001b[35m0.0104\u001b[0m  1.7383\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0077\u001b[0m  1.7410\n",
            "     11      1.0000      1.0000        \u001b[35m0.0059\u001b[0m  1.7400\n",
            "     12      1.0000      1.0000        \u001b[35m0.0047\u001b[0m  1.7520\n",
            "     13      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  1.7201\n",
            "     14      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.7157\n",
            "     15      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  1.7279\n",
            "     16      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  1.7218\n",
            "     17      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  1.7105\n",
            "     18      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.7182\n",
            "     19      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  1.6999\n",
            "     20      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.7333\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4833\u001b[0m      \u001b[32m0.3358\u001b[0m        \u001b[35m1.2934\u001b[0m  1.7304\n",
            "      2      \u001b[36m0.6712\u001b[0m      \u001b[32m0.6014\u001b[0m        \u001b[35m0.9905\u001b[0m  1.7108\n",
            "      3      \u001b[36m0.8448\u001b[0m      \u001b[32m0.8149\u001b[0m        \u001b[35m0.5159\u001b[0m  1.7329\n",
            "      4      \u001b[36m0.9691\u001b[0m      \u001b[32m0.9681\u001b[0m        \u001b[35m0.1731\u001b[0m  1.7229\n",
            "      5      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0666\u001b[0m  1.7257\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0341\u001b[0m  1.7134\n",
            "      7      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0206\u001b[0m  1.7082\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0137\u001b[0m  1.7403\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0097\u001b[0m  1.7410\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0072\u001b[0m  1.7191\n",
            "     11      1.0000      1.0000        \u001b[35m0.0055\u001b[0m  1.7148\n",
            "     12      1.0000      1.0000        \u001b[35m0.0043\u001b[0m  1.7246\n",
            "     13      1.0000      1.0000        \u001b[35m0.0035\u001b[0m  1.7308\n",
            "     14      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.7233\n",
            "     15      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.7314\n",
            "     16      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  1.7418\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     17      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.7529\n",
            "     18      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.7364\n",
            "     19      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.7320\n",
            "     20      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.7289\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4673\u001b[0m      \u001b[32m0.4071\u001b[0m        \u001b[35m1.2871\u001b[0m  2.4762\n",
            "      2      \u001b[36m0.7152\u001b[0m      \u001b[32m0.6484\u001b[0m        \u001b[35m0.8895\u001b[0m  2.4452\n",
            "      3      \u001b[36m0.9099\u001b[0m      \u001b[32m0.9015\u001b[0m        \u001b[35m0.3200\u001b[0m  2.4603\n",
            "      4      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9866\u001b[0m        \u001b[35m0.0839\u001b[0m  2.4605\n",
            "      5      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0343\u001b[0m  2.4207\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0181\u001b[0m  2.4186\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0111\u001b[0m  2.4573\n",
            "      8      0.9996      0.9996        \u001b[35m0.0074\u001b[0m  2.4564\n",
            "      9      0.9996      0.9996        \u001b[35m0.0053\u001b[0m  2.4546\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0040\u001b[0m  2.4588\n",
            "     11      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  2.4428\n",
            "     12      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  2.4590\n",
            "     13      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  2.4537\n",
            "     14      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  2.4714\n",
            "     15      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  2.4834\n",
            "     16      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  2.4840\n",
            "     17      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  2.4311\n",
            "     18      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  2.4518\n",
            "     19      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  2.4506\n",
            "     20      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  2.4470\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4875\u001b[0m      \u001b[32m0.3605\u001b[0m        \u001b[35m1.2813\u001b[0m  2.5023\n",
            "      2      \u001b[36m0.7013\u001b[0m      \u001b[32m0.6350\u001b[0m        \u001b[35m0.8791\u001b[0m  2.4759\n",
            "      3      \u001b[36m0.9073\u001b[0m      \u001b[32m0.8996\u001b[0m        \u001b[35m0.3138\u001b[0m  2.4737\n",
            "      4      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9885\u001b[0m        \u001b[35m0.0825\u001b[0m  2.4719\n",
            "      5      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0337\u001b[0m  2.4658\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0184\u001b[0m  2.4885\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0115\u001b[0m  2.4774\n",
            "      8      0.9996      0.9996        \u001b[35m0.0078\u001b[0m  2.4749\n",
            "      9      0.9996      0.9996        \u001b[35m0.0056\u001b[0m  2.4731\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0042\u001b[0m  2.4784\n",
            "     11      1.0000      1.0000        \u001b[35m0.0032\u001b[0m  2.4844\n",
            "     12      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  2.4654\n",
            "     13      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  2.4806\n",
            "     14      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  2.4872\n",
            "     15      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  2.4797\n",
            "     16      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  2.4566\n",
            "     17      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  2.4460\n",
            "     18      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  2.4332\n",
            "     19      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  2.4574\n",
            "     20      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  2.4677\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4787\u001b[0m      \u001b[32m0.3774\u001b[0m        \u001b[35m1.2791\u001b[0m  2.4864\n",
            "      2      \u001b[36m0.7130\u001b[0m      \u001b[32m0.6466\u001b[0m        \u001b[35m0.8681\u001b[0m  2.4322\n",
            "      3      \u001b[36m0.9154\u001b[0m      \u001b[32m0.9090\u001b[0m        \u001b[35m0.3107\u001b[0m  2.4719\n",
            "      4      \u001b[36m0.9879\u001b[0m      \u001b[32m0.9877\u001b[0m        \u001b[35m0.0841\u001b[0m  2.4393\n",
            "      5      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0328\u001b[0m  2.4398\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0173\u001b[0m  2.4622\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0106\u001b[0m  2.4687\n",
            "      8      1.0000      1.0000        \u001b[35m0.0071\u001b[0m  2.4775\n",
            "      9      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  2.4773\n",
            "     10      1.0000      1.0000        \u001b[35m0.0037\u001b[0m  2.4639\n",
            "     11      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  2.4665\n",
            "     12      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  2.4959\n",
            "     13      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  2.4938\n",
            "     14      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  2.4544\n",
            "     15      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  2.4798\n",
            "     16      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  2.4877\n",
            "     17      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  2.4895\n",
            "     18      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  2.4417\n",
            "     19      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  2.4823\n",
            "     20      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  2.4518\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4947\u001b[0m      \u001b[32m0.3552\u001b[0m        \u001b[35m1.2657\u001b[0m  2.4374\n",
            "      2      \u001b[36m0.7124\u001b[0m      \u001b[32m0.6451\u001b[0m        \u001b[35m0.8763\u001b[0m  2.4545\n",
            "      3      \u001b[36m0.9073\u001b[0m      \u001b[32m0.8994\u001b[0m        \u001b[35m0.3150\u001b[0m  2.4582\n",
            "      4      \u001b[36m0.9882\u001b[0m      \u001b[32m0.9881\u001b[0m        \u001b[35m0.0817\u001b[0m  2.4499\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0331\u001b[0m  2.4848\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0180\u001b[0m  2.4622\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0111\u001b[0m  2.4852\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0075\u001b[0m  2.4637\n",
            "      9      1.0000      1.0000        \u001b[35m0.0053\u001b[0m  2.4972\n",
            "     10      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  2.4796\n",
            "     11      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  2.4977\n",
            "     12      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  2.4892\n",
            "     13      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  2.4786\n",
            "     14      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  2.4809\n",
            "     15      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  2.4859\n",
            "     16      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  2.4936\n",
            "     17      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  2.5143\n",
            "     18      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  2.5171\n",
            "     19      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  2.4880\n",
            "     20      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  2.4855\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4895\u001b[0m      \u001b[32m0.3340\u001b[0m        \u001b[35m1.2756\u001b[0m  2.4900\n",
            "      2      \u001b[36m0.7028\u001b[0m      \u001b[32m0.6357\u001b[0m        \u001b[35m0.8775\u001b[0m  2.5087\n",
            "      3      \u001b[36m0.9114\u001b[0m      \u001b[32m0.9047\u001b[0m        \u001b[35m0.3076\u001b[0m  2.4899\n",
            "      4      \u001b[36m0.9901\u001b[0m      \u001b[32m0.9899\u001b[0m        \u001b[35m0.0778\u001b[0m  2.4867\n",
            "      5      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0315\u001b[0m  2.4990\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0171\u001b[0m  2.4780\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0106\u001b[0m  2.4893\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0071\u001b[0m  2.4950\n",
            "      9      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  2.4603\n",
            "     10      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  2.5025\n",
            "     11      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  2.4704\n",
            "     12      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  2.4612\n",
            "     13      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  2.4663\n",
            "     14      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  2.4602\n",
            "     15      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  2.4702\n",
            "     16      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  2.4506\n",
            "     17      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  2.4786\n",
            "     18      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  2.4970\n",
            "     19      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  2.4457\n",
            "     20      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  2.4473\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4783\u001b[0m      \u001b[32m0.4081\u001b[0m        \u001b[35m1.2639\u001b[0m  4.0611\n",
            "      2      \u001b[36m0.7590\u001b[0m      \u001b[32m0.7058\u001b[0m        \u001b[35m0.7359\u001b[0m  4.0545\n",
            "      3      \u001b[36m0.9566\u001b[0m      \u001b[32m0.9552\u001b[0m        \u001b[35m0.1700\u001b[0m  4.0525\n",
            "      4      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0408\u001b[0m  4.0714\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0173\u001b[0m  4.1229\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0094\u001b[0m  4.0979\n",
            "      7      0.9996      0.9996        \u001b[35m0.0058\u001b[0m  4.0794\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0040\u001b[0m  4.0721\n",
            "      9      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  4.0771\n",
            "     10      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  4.0834\n",
            "     11      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  4.0821\n",
            "     12      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  4.0646\n",
            "     13      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  4.0367\n",
            "     14      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  4.0524\n",
            "     15      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  4.0803\n",
            "     16      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  4.0652\n",
            "     17      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  4.0438\n",
            "     18      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0366\n",
            "     19      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0071\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0235\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4963\u001b[0m      \u001b[32m0.3782\u001b[0m        \u001b[35m1.2585\u001b[0m  4.0513\n",
            "      2      \u001b[36m0.7465\u001b[0m      \u001b[32m0.6933\u001b[0m        \u001b[35m0.7389\u001b[0m  4.0163\n",
            "      3      \u001b[36m0.9603\u001b[0m      \u001b[32m0.9593\u001b[0m        \u001b[35m0.1729\u001b[0m  4.0557\n",
            "      4      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0400\u001b[0m  4.0205\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0174\u001b[0m  4.0218\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0097\u001b[0m  4.0143\n",
            "      7      0.9996      0.9996        \u001b[35m0.0061\u001b[0m  4.0051\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0042\u001b[0m  4.0096\n",
            "      9      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  4.0278\n",
            "     10      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  4.0363\n",
            "     11      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  4.0540\n",
            "     12      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  4.0308\n",
            "     13      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  4.0368\n",
            "     14      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  3.9929\n",
            "     15      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  4.0501\n",
            "     16      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  4.0167\n",
            "     17      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  4.0196\n",
            "     18      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0307\n",
            "     19      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0461\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0926\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4974\u001b[0m      \u001b[32m0.3635\u001b[0m        \u001b[35m1.2570\u001b[0m  4.0624\n",
            "      2      \u001b[36m0.7609\u001b[0m      \u001b[32m0.7104\u001b[0m        \u001b[35m0.7147\u001b[0m  3.9919\n",
            "      3      \u001b[36m0.9558\u001b[0m      \u001b[32m0.9542\u001b[0m        \u001b[35m0.1637\u001b[0m  4.0154\n",
            "      4      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0380\u001b[0m  4.0228\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0156\u001b[0m  4.0632\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0085\u001b[0m  4.0513\n",
            "      7      1.0000      1.0000        \u001b[35m0.0053\u001b[0m  4.0548\n",
            "      8      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  4.0605\n",
            "      9      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  4.0767\n",
            "     10      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  4.0583\n",
            "     11      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  4.0136\n",
            "     12      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  4.0385\n",
            "     13      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  4.0527\n",
            "     14      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  4.0181\n",
            "     15      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  4.0405\n",
            "     16      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  4.0171\n",
            "     17      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0422\n",
            "     18      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0243\n",
            "     19      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0282\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0209\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5002\u001b[0m      \u001b[32m0.3959\u001b[0m        \u001b[35m1.2518\u001b[0m  4.0282\n",
            "      2      \u001b[36m0.7580\u001b[0m      \u001b[32m0.7027\u001b[0m        \u001b[35m0.7317\u001b[0m  4.0369\n",
            "      3      \u001b[36m0.9577\u001b[0m      \u001b[32m0.9566\u001b[0m        \u001b[35m0.1735\u001b[0m  4.0375\n",
            "      4      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0393\u001b[0m  4.0170\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0170\u001b[0m  4.0457\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0094\u001b[0m  4.0529\n",
            "      7      0.9996      0.9996        \u001b[35m0.0059\u001b[0m  4.0199\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0040\u001b[0m  4.0408\n",
            "      9      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  4.0551\n",
            "     10      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  3.6591\n",
            "     11      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  4.0551\n",
            "     12      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  4.0260\n",
            "     13      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  4.0539\n",
            "     14      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  4.0343\n",
            "     15      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  4.0406\n",
            "     16      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  4.0277\n",
            "     17      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  4.0495\n",
            "     18      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0214\n",
            "     19      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0270\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0441\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4961\u001b[0m      \u001b[32m0.3620\u001b[0m        \u001b[35m1.2554\u001b[0m  4.0811\n",
            "      2      \u001b[36m0.7484\u001b[0m      \u001b[32m0.6961\u001b[0m        \u001b[35m0.7238\u001b[0m  4.0836\n",
            "      3      \u001b[36m0.9625\u001b[0m      \u001b[32m0.9613\u001b[0m        \u001b[35m0.1623\u001b[0m  4.0932\n",
            "      4      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0365\u001b[0m  4.1229\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0158\u001b[0m  4.0818\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0087\u001b[0m  4.1026\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0055\u001b[0m  4.0945\n",
            "      8      1.0000      1.0000        \u001b[35m0.0037\u001b[0m  4.0730\n",
            "      9      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  4.0750\n",
            "     10      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  4.0870\n",
            "     11      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  4.0655\n",
            "     12      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  4.0496\n",
            "     13      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  4.0465\n",
            "     14      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  4.0513\n",
            "     15      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  4.0380\n",
            "     16      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  4.0453\n",
            "     17      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0449\n",
            "     18      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0566\n",
            "     19      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0677\n",
            "     20      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0545\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4923\u001b[0m      \u001b[32m0.4295\u001b[0m        \u001b[35m1.2077\u001b[0m  1.3907\n",
            "      2      \u001b[36m0.9058\u001b[0m      \u001b[32m0.9016\u001b[0m        \u001b[35m0.2815\u001b[0m  1.3534\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0116\u001b[0m  1.3859\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3696\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3867\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3822\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3823\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3727\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3724\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3815\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5004\u001b[0m      \u001b[32m0.4377\u001b[0m        \u001b[35m1.2003\u001b[0m  1.3699\n",
            "      2      \u001b[36m0.9095\u001b[0m      \u001b[32m0.9051\u001b[0m        \u001b[35m0.2879\u001b[0m  1.3687\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0106\u001b[0m  1.3586\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0013\u001b[0m  1.3742\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3481\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3734\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3607\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3745\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3777\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3710\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5055\u001b[0m      \u001b[32m0.4304\u001b[0m        \u001b[35m1.1993\u001b[0m  1.3686\n",
            "      2      \u001b[36m0.8992\u001b[0m      \u001b[32m0.8919\u001b[0m        \u001b[35m0.2911\u001b[0m  1.3508\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0124\u001b[0m  1.3864\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3631\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3606\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3723\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3769\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3558\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3583\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3765\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5046\u001b[0m      \u001b[32m0.4339\u001b[0m        \u001b[35m1.2081\u001b[0m  1.3771\n",
            "      2      \u001b[36m0.8989\u001b[0m      \u001b[32m0.8924\u001b[0m        \u001b[35m0.3067\u001b[0m  1.3686\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0109\u001b[0m  1.3680\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0012\u001b[0m  1.3616\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3636\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3693\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3672\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3709\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3765\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3731\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4994\u001b[0m      \u001b[32m0.4277\u001b[0m        \u001b[35m1.2066\u001b[0m  1.3611\n",
            "      2      \u001b[36m0.8974\u001b[0m      \u001b[32m0.8904\u001b[0m        \u001b[35m0.2976\u001b[0m  1.3554\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0095\u001b[0m  1.3866\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0012\u001b[0m  1.3627\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3813\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3610\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3923\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3806\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3585\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3459\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4993\u001b[0m      \u001b[32m0.4389\u001b[0m        \u001b[35m1.2012\u001b[0m  1.7522\n",
            "      2      \u001b[36m0.9231\u001b[0m      \u001b[32m0.9213\u001b[0m        \u001b[35m0.2336\u001b[0m  1.7444\n",
            "      3      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0149\u001b[0m  1.7568\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7306\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7440\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7360\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7381\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7470\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7134\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7363\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4996\u001b[0m      \u001b[32m0.4388\u001b[0m        \u001b[35m1.1946\u001b[0m  1.7066\n",
            "      2      \u001b[36m0.9308\u001b[0m      \u001b[32m0.9293\u001b[0m        \u001b[35m0.2182\u001b[0m  1.7060\n",
            "      3      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0070\u001b[0m  1.7274\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7450\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7193\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7466\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7322\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7357\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7197\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7382\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7510\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7223\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5075\u001b[0m      \u001b[32m0.4381\u001b[0m        \u001b[35m1.2011\u001b[0m  1.7559\n",
            "      2      \u001b[36m0.9268\u001b[0m      \u001b[32m0.9248\u001b[0m        \u001b[35m0.2151\u001b[0m  1.7328\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0120\u001b[0m  1.7179\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.7289\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7251\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7208\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7345\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7272\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7120\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7365\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5127\u001b[0m      \u001b[32m0.4408\u001b[0m        \u001b[35m1.1937\u001b[0m  1.7475\n",
            "      2      \u001b[36m0.9309\u001b[0m      \u001b[32m0.9287\u001b[0m        \u001b[35m0.2100\u001b[0m  1.7285\n",
            "      3      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0096\u001b[0m  1.7286\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  1.7488\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7252\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7185\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7446\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7236\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7396\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7307\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4996\u001b[0m      \u001b[32m0.4417\u001b[0m        \u001b[35m1.1994\u001b[0m  2.4680\n",
            "      2      \u001b[36m0.9345\u001b[0m      \u001b[32m0.9336\u001b[0m        \u001b[35m0.2061\u001b[0m  2.4885\n",
            "      3      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0204\u001b[0m  2.4793\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0015\u001b[0m  2.4662\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4817\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4586\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4633\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4784\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4612\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4684\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5096\u001b[0m      \u001b[32m0.4496\u001b[0m        \u001b[35m1.1914\u001b[0m  2.4872\n",
            "      2      \u001b[36m0.9444\u001b[0m      \u001b[32m0.9438\u001b[0m        \u001b[35m0.1845\u001b[0m  2.4626\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0144\u001b[0m  2.4834\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0036\u001b[0m  2.4770\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0009\u001b[0m  2.4711\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  2.4742\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4656\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4605\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4526\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4614\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5114\u001b[0m      \u001b[32m0.4511\u001b[0m        \u001b[35m1.1853\u001b[0m  2.4409\n",
            "      2      \u001b[36m0.9448\u001b[0m      \u001b[32m0.9440\u001b[0m        \u001b[35m0.1795\u001b[0m  2.5005\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0108\u001b[0m  2.5026\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  2.4517\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4718\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4902\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4703\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4668\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4648\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4675\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5171\u001b[0m      \u001b[32m0.4543\u001b[0m        \u001b[35m1.2001\u001b[0m  2.4509\n",
            "      2      \u001b[36m0.9312\u001b[0m      \u001b[32m0.9298\u001b[0m        \u001b[35m0.1962\u001b[0m  2.4368\n",
            "      3      \u001b[36m0.9904\u001b[0m      \u001b[32m0.9904\u001b[0m        \u001b[35m0.0247\u001b[0m  2.4353\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0026\u001b[0m  2.4463\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  2.4676\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4633\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4672\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4845\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4780\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4780\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5131\u001b[0m      \u001b[32m0.4494\u001b[0m        \u001b[35m1.1944\u001b[0m  2.4658\n",
            "      2      \u001b[36m0.9448\u001b[0m      \u001b[32m0.9437\u001b[0m        \u001b[35m0.1700\u001b[0m  2.4980\n",
            "      3      \u001b[36m0.9890\u001b[0m      \u001b[32m0.9890\u001b[0m        \u001b[35m0.0233\u001b[0m  2.4764\n",
            "      4      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0133\u001b[0m  2.4870\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0018\u001b[0m  2.4919\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  2.4911\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4533\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4777\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4552\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.5085\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4993\u001b[0m      \u001b[32m0.4443\u001b[0m        \u001b[35m1.2081\u001b[0m  4.0353\n",
            "      2      \u001b[36m0.9301\u001b[0m      \u001b[32m0.9292\u001b[0m        \u001b[35m0.2263\u001b[0m  4.0328\n",
            "      3      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9893\u001b[0m        \u001b[35m0.0349\u001b[0m  4.0448\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0021\u001b[0m  4.0274\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  4.0315\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0317\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0129\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0473\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0232\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0569\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5121\u001b[0m      \u001b[32m0.4555\u001b[0m        \u001b[35m1.1922\u001b[0m  4.0010\n",
            "      2      \u001b[36m0.9397\u001b[0m      \u001b[32m0.9391\u001b[0m        \u001b[35m0.1775\u001b[0m  4.0476\n",
            "      3      \u001b[36m0.9875\u001b[0m      \u001b[32m0.9875\u001b[0m        \u001b[35m0.0357\u001b[0m  4.0389\n",
            "      4      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9886\u001b[0m        0.0404  4.0698\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0070\u001b[0m  4.0625\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  4.0242\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0561\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0578\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0389\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0385\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5110\u001b[0m      \u001b[32m0.4557\u001b[0m        \u001b[35m1.1922\u001b[0m  4.0430\n",
            "      2      \u001b[36m0.9459\u001b[0m      \u001b[32m0.9453\u001b[0m        \u001b[35m0.1710\u001b[0m  4.0691\n",
            "      3      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0244\u001b[0m  4.0635\n",
            "      4      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0064\u001b[0m  4.0514\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  4.0288\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0165\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0186\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0434\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0705\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0375\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5142\u001b[0m      \u001b[32m0.4556\u001b[0m        \u001b[35m1.2083\u001b[0m  4.0357\n",
            "      2      \u001b[36m0.9338\u001b[0m      \u001b[32m0.9329\u001b[0m        \u001b[35m0.1939\u001b[0m  4.0377\n",
            "      3      \u001b[36m0.9882\u001b[0m      \u001b[32m0.9882\u001b[0m        \u001b[35m0.0381\u001b[0m  4.0745\n",
            "      4      \u001b[36m0.9949\u001b[0m      \u001b[32m0.9949\u001b[0m        \u001b[35m0.0170\u001b[0m  4.0527\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0017\u001b[0m  4.0252\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  4.0248\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0415\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0282\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0602\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0308\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5156\u001b[0m      \u001b[32m0.4588\u001b[0m        \u001b[35m1.1997\u001b[0m  4.0581\n",
            "      2      \u001b[36m0.9445\u001b[0m      \u001b[32m0.9439\u001b[0m        \u001b[35m0.1689\u001b[0m  4.0462\n",
            "      3      \u001b[36m0.9901\u001b[0m      \u001b[32m0.9901\u001b[0m        \u001b[35m0.0316\u001b[0m  4.0627\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0089\u001b[0m  4.0607\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  4.0255\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0461\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0260\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0445\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0478\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0195\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4937\u001b[0m      \u001b[32m0.4316\u001b[0m        \u001b[35m1.2105\u001b[0m  1.3737\n",
            "      2      \u001b[36m0.8959\u001b[0m      \u001b[32m0.8892\u001b[0m        \u001b[35m0.3083\u001b[0m  1.3393\n",
            "      3      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0133\u001b[0m  1.3442\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0012\u001b[0m  1.3752\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3802\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3871\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3751\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3452\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3877\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3811\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3463\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3750\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3813\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3715\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3671\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3749\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3733\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3730\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3883\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3748\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5044\u001b[0m      \u001b[32m0.4339\u001b[0m        \u001b[35m1.1967\u001b[0m  1.3931\n",
            "      2      \u001b[36m0.9113\u001b[0m      \u001b[32m0.9081\u001b[0m        \u001b[35m0.2786\u001b[0m  1.3775\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0101\u001b[0m  1.3682\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3634\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3623\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3715\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3739\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3890\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3624\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3621\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3567\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3885\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3643\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3463\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3804\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3873\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3376\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3636\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3442\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3661\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4978\u001b[0m      \u001b[32m0.4376\u001b[0m        \u001b[35m1.2026\u001b[0m  1.3994\n",
            "      2      \u001b[36m0.9021\u001b[0m      \u001b[32m0.8959\u001b[0m        \u001b[35m0.2901\u001b[0m  1.3628\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0102\u001b[0m  1.3694\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3666\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3689\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3741\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3647\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3460\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3637\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3659\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3640\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3868\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3732\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3634\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3630\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3573\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3623\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3471\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3716\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3855\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5097\u001b[0m      \u001b[32m0.4423\u001b[0m        \u001b[35m1.2032\u001b[0m  1.3817\n",
            "      2      \u001b[36m0.9092\u001b[0m      \u001b[32m0.9048\u001b[0m        \u001b[35m0.2794\u001b[0m  1.3692\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0109\u001b[0m  1.3580\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3595\n",
            "      5      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3577\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3863\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3546\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3688\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3839\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3744\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3561\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3648\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3970\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3922\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3616\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3854\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3700\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3512\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3406\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3708\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4932\u001b[0m      \u001b[32m0.4295\u001b[0m        \u001b[35m1.2093\u001b[0m  1.4009\n",
            "      2      \u001b[36m0.9044\u001b[0m      \u001b[32m0.8993\u001b[0m        \u001b[35m0.2823\u001b[0m  1.3970\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0091\u001b[0m  1.3667\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3792\n",
            "      5      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3588\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3542\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3701\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3864\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.4024\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3869\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3873\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3849\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3744\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3718\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3746\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3584\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3717\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3713\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3761\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3801\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4989\u001b[0m      \u001b[32m0.4381\u001b[0m        \u001b[35m1.2014\u001b[0m  1.7393\n",
            "      2      \u001b[36m0.9220\u001b[0m      \u001b[32m0.9195\u001b[0m        \u001b[35m0.2407\u001b[0m  1.7236\n",
            "      3      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0149\u001b[0m  1.7438\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0022\u001b[0m  1.7448\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.7452\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7399\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7446\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7291\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7222\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7330\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7494\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7451\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7475\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7219\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7353\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7345\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7268\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7454\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7304\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7379\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5004\u001b[0m      \u001b[32m0.4414\u001b[0m        \u001b[35m1.1963\u001b[0m  1.7571\n",
            "      2      \u001b[36m0.9352\u001b[0m      \u001b[32m0.9338\u001b[0m        \u001b[35m0.2112\u001b[0m  1.7444\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0092\u001b[0m  1.7464\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7602\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7520\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7482\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7450\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7580\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7365\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7247\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7335\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7174\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7582\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7362\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7543\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7304\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7422\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7335\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7271\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7264\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5059\u001b[0m      \u001b[32m0.4408\u001b[0m        \u001b[35m1.1878\u001b[0m  1.7076\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      2      \u001b[36m0.9341\u001b[0m      \u001b[32m0.9323\u001b[0m        \u001b[35m0.2073\u001b[0m  1.7365\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0092\u001b[0m  1.7231\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  1.7075\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7332\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7193\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7499\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7269\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.6881\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7255\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7314\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7540\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7336\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7232\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7200\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7453\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7407\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7465\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7181\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7288\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5094\u001b[0m      \u001b[32m0.4453\u001b[0m        \u001b[35m1.2007\u001b[0m  1.7366\n",
            "      2      \u001b[36m0.9231\u001b[0m      \u001b[32m0.9205\u001b[0m        \u001b[35m0.2267\u001b[0m  1.7093\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0105\u001b[0m  1.7403\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7323\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7208\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7471\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7204\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7440\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7450\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7249\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7327\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7481\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7318\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7266\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7583\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7478\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7441\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7577\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7607\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7174\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5097\u001b[0m      \u001b[32m0.4451\u001b[0m        \u001b[35m1.1979\u001b[0m  1.7347\n",
            "      2      \u001b[36m0.9364\u001b[0m      \u001b[32m0.9345\u001b[0m        \u001b[35m0.2069\u001b[0m  1.7463\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0069\u001b[0m  1.7375\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7357\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7461\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7227\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7412\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7386\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7638\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7123\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7276\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7293\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7344\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7182\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7356\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7345\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7345\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7146\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7285\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.7272\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5007\u001b[0m      \u001b[32m0.4404\u001b[0m        \u001b[35m1.1974\u001b[0m  2.4699\n",
            "      2      \u001b[36m0.9341\u001b[0m      \u001b[32m0.9329\u001b[0m        \u001b[35m0.2001\u001b[0m  2.4531\n",
            "      3      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0239\u001b[0m  2.4426\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0015\u001b[0m  2.5143\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.5072\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4801\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4760\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4565\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4417\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4571\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4817\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4717\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4500\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4644\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4812\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4540\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4687\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4986\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4888\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4777\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5085\u001b[0m      \u001b[32m0.4504\u001b[0m        \u001b[35m1.1905\u001b[0m  2.4779\n",
            "      2      \u001b[36m0.9408\u001b[0m      \u001b[32m0.9401\u001b[0m        \u001b[35m0.1793\u001b[0m  2.4883\n",
            "      3      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0242\u001b[0m  2.4864\n",
            "      4      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0184\u001b[0m  2.4776\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  2.4662\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4724\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4883\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4886\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4908\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4876\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4597\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4768\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4299\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4647\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4487\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4300\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4431\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4546\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4585\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4379\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5103\u001b[0m      \u001b[32m0.4510\u001b[0m        \u001b[35m1.1860\u001b[0m  2.4226\n",
            "      2      \u001b[36m0.9404\u001b[0m      \u001b[32m0.9393\u001b[0m        \u001b[35m0.1887\u001b[0m  2.4432\n",
            "      3      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0170\u001b[0m  2.4413\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  2.4418\n",
            "      5      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4765\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4584\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4453\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4495\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4809\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4588\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4606\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4551\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4587\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4836\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4802\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4585\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4901\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4634\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4774\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4637\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5149\u001b[0m      \u001b[32m0.4561\u001b[0m        \u001b[35m1.2017\u001b[0m  2.4581\n",
            "      2      \u001b[36m0.9389\u001b[0m      \u001b[32m0.9380\u001b[0m        \u001b[35m0.1883\u001b[0m  2.4722\n",
            "      3      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9893\u001b[0m        \u001b[35m0.0284\u001b[0m  2.4627\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0041\u001b[0m  2.4943\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  2.4900\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4691\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4480\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4787\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4823\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.5029\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4772\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4815\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4743\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4964\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.5028\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4993\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4897\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.5000\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.5166\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4938\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5153\u001b[0m      \u001b[32m0.4533\u001b[0m        \u001b[35m1.1929\u001b[0m  2.4318\n",
            "      2      \u001b[36m0.9412\u001b[0m      \u001b[32m0.9401\u001b[0m        \u001b[35m0.1744\u001b[0m  2.4399\n",
            "      3      \u001b[36m0.9890\u001b[0m      \u001b[32m0.9890\u001b[0m        \u001b[35m0.0291\u001b[0m  2.4699\n",
            "      4      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0078\u001b[0m  2.4770\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0013\u001b[0m  2.4833\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  2.4830\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4980\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4908\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4643\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4710\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4753\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4719\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4995\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4477\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4450\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4526\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4603\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4606\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4707\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4814\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5004\u001b[0m      \u001b[32m0.4443\u001b[0m        \u001b[35m1.2093\u001b[0m  4.0410\n",
            "      2      \u001b[36m0.9283\u001b[0m      \u001b[32m0.9272\u001b[0m        \u001b[35m0.2224\u001b[0m  4.0452\n",
            "      3      \u001b[36m0.9904\u001b[0m      \u001b[32m0.9904\u001b[0m        \u001b[35m0.0260\u001b[0m  4.0448\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0041\u001b[0m  4.0622\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  4.0305\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0184\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0354\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0454\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0389\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0409\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0409\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0218\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0496\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0584\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0339\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0539\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0186\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0479\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0772\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0565\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5088\u001b[0m      \u001b[32m0.4531\u001b[0m        \u001b[35m1.1925\u001b[0m  4.0247\n",
            "      2      \u001b[36m0.9411\u001b[0m      \u001b[32m0.9406\u001b[0m        \u001b[35m0.1761\u001b[0m  4.0453\n",
            "      3      \u001b[36m0.9890\u001b[0m      \u001b[32m0.9890\u001b[0m        \u001b[35m0.0343\u001b[0m  4.0521\n",
            "      4      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9893\u001b[0m        \u001b[35m0.0342\u001b[0m  4.0567\n",
            "      5      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0125\u001b[0m  4.0123\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0009\u001b[0m  4.0648\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  4.0979\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0805\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0861\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0628\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0615\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0571\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0566\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.1132\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0997\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0536\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0118\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0539\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0700\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0834\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5107\u001b[0m      \u001b[32m0.4536\u001b[0m        \u001b[35m1.1939\u001b[0m  4.0684\n",
            "      2      \u001b[36m0.9400\u001b[0m      \u001b[32m0.9395\u001b[0m        \u001b[35m0.1901\u001b[0m  4.0338\n",
            "      3      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0206\u001b[0m  4.0540\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0042\u001b[0m  4.0483\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  4.0291\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0361\n",
            "      7      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0375\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0308\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0889\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0804\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0462\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0775\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0828\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0419\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0308\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0643\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0657\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0542\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0561\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0634\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5149\u001b[0m      \u001b[32m0.4555\u001b[0m        \u001b[35m1.2066\u001b[0m  4.0731\n",
            "      2      \u001b[36m0.9342\u001b[0m      \u001b[32m0.9333\u001b[0m        \u001b[35m0.1998\u001b[0m  4.0753\n",
            "      3      \u001b[36m0.9871\u001b[0m      \u001b[32m0.9871\u001b[0m        \u001b[35m0.0397\u001b[0m  4.0473\n",
            "      4      0.9823      0.9823        0.0589  4.0184\n",
            "      5      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0095\u001b[0m  4.0334\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0068\u001b[0m  4.0358\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0010\u001b[0m  4.0460\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  4.0296\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0336\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0164\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0390\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0515\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0449\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0470\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0593\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0409\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0247\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0557\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0185\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0227\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5230\u001b[0m      \u001b[32m0.4609\u001b[0m        \u001b[35m1.1993\u001b[0m  4.0809\n",
            "      2      \u001b[36m0.9470\u001b[0m      \u001b[32m0.9466\u001b[0m        \u001b[35m0.1590\u001b[0m  4.0431\n",
            "      3      \u001b[36m0.9901\u001b[0m      \u001b[32m0.9901\u001b[0m        \u001b[35m0.0282\u001b[0m  4.0732\n",
            "      4      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0139\u001b[0m  4.0668\n",
            "      5      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0083\u001b[0m  4.0761\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0021\u001b[0m  4.0388\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0000\u001b[0m  4.0752\n",
            "      8      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0664\n",
            "      9      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0388\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0350\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0219\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0235\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0225\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0337\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0744\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0426\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0432\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0552\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0007\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0399\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4746\u001b[0m      \u001b[32m0.4078\u001b[0m        \u001b[35m1.2292\u001b[0m  1.3675\n",
            "      2      \u001b[36m0.8120\u001b[0m      \u001b[32m0.8012\u001b[0m        \u001b[35m0.5365\u001b[0m  1.3632\n",
            "      3      \u001b[36m0.9352\u001b[0m      \u001b[32m0.9346\u001b[0m        \u001b[35m0.1831\u001b[0m  1.3543\n",
            "      4      \u001b[36m0.9742\u001b[0m      \u001b[32m0.9741\u001b[0m        \u001b[35m0.0676\u001b[0m  1.3682\n",
            "      5      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0170\u001b[0m  1.3639\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0039\u001b[0m  1.3872\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.3633\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3624\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3736\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3903\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4790\u001b[0m      \u001b[32m0.4259\u001b[0m        \u001b[35m1.2274\u001b[0m  1.3789\n",
            "      2      \u001b[36m0.7792\u001b[0m      \u001b[32m0.7658\u001b[0m        \u001b[35m0.6127\u001b[0m  1.3496\n",
            "      3      \u001b[36m0.9091\u001b[0m      \u001b[32m0.9068\u001b[0m        \u001b[35m0.2551\u001b[0m  1.3732\n",
            "      4      \u001b[36m0.9790\u001b[0m      \u001b[32m0.9790\u001b[0m        \u001b[35m0.0663\u001b[0m  1.3772\n",
            "      5      \u001b[36m0.9915\u001b[0m      \u001b[32m0.9915\u001b[0m        \u001b[35m0.0273\u001b[0m  1.3611\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0072\u001b[0m  1.3683\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0013\u001b[0m  1.3518\n",
            "      8      0.9996      0.9996        \u001b[35m0.0011\u001b[0m  1.3914\n",
            "      9      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3839\n",
            "     10      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3788\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4816\u001b[0m      \u001b[32m0.4287\u001b[0m        \u001b[35m1.2306\u001b[0m  1.3740\n",
            "      2      \u001b[36m0.8337\u001b[0m      \u001b[32m0.8269\u001b[0m        \u001b[35m0.4496\u001b[0m  1.3666\n",
            "      3      \u001b[36m0.9595\u001b[0m      \u001b[32m0.9593\u001b[0m        \u001b[35m0.1309\u001b[0m  1.3760\n",
            "      4      \u001b[36m0.9890\u001b[0m      \u001b[32m0.9889\u001b[0m        \u001b[35m0.0365\u001b[0m  1.3730\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0072\u001b[0m  1.3624\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0051\u001b[0m  1.3751\n",
            "      7      0.9985      0.9985        \u001b[35m0.0040\u001b[0m  1.4016\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0016\u001b[0m  1.4000\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  1.3655\n",
            "     10      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.3659\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4925\u001b[0m      \u001b[32m0.4314\u001b[0m        \u001b[35m1.2336\u001b[0m  1.3902\n",
            "      2      \u001b[36m0.7904\u001b[0m      \u001b[32m0.7733\u001b[0m        \u001b[35m0.5777\u001b[0m  1.3832\n",
            "      3      \u001b[36m0.9360\u001b[0m      \u001b[32m0.9353\u001b[0m        \u001b[35m0.2005\u001b[0m  1.3958\n",
            "      4      \u001b[36m0.9879\u001b[0m      \u001b[32m0.9879\u001b[0m        \u001b[35m0.0419\u001b[0m  1.3801\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0074\u001b[0m  1.3820\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0027\u001b[0m  1.3541\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0017\u001b[0m  1.3864\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3642\n",
            "      9      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.3776\n",
            "     10      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3707\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4818\u001b[0m      \u001b[32m0.4255\u001b[0m        \u001b[35m1.2214\u001b[0m  1.3782\n",
            "      2      \u001b[36m0.8179\u001b[0m      \u001b[32m0.8062\u001b[0m        \u001b[35m0.5471\u001b[0m  1.3859\n",
            "      3      \u001b[36m0.9275\u001b[0m      \u001b[32m0.9262\u001b[0m        \u001b[35m0.2059\u001b[0m  1.3797\n",
            "      4      \u001b[36m0.9846\u001b[0m      \u001b[32m0.9844\u001b[0m        \u001b[35m0.0489\u001b[0m  1.3678\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0075\u001b[0m  1.3748\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0022\u001b[0m  1.3820\n",
            "      7      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.3833\n",
            "      8      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.3693\n",
            "      9      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3560\n",
            "     10      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3651\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4915\u001b[0m      \u001b[32m0.4340\u001b[0m        \u001b[35m1.2531\u001b[0m  1.7310\n",
            "      2      \u001b[36m0.8308\u001b[0m      \u001b[32m0.8209\u001b[0m        \u001b[35m0.5033\u001b[0m  1.7176\n",
            "      3      \u001b[36m0.9360\u001b[0m      \u001b[32m0.9354\u001b[0m        \u001b[35m0.1739\u001b[0m  1.7299\n",
            "      4      \u001b[36m0.9860\u001b[0m      \u001b[32m0.9860\u001b[0m        \u001b[35m0.0423\u001b[0m  1.7263\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0042\u001b[0m  1.7299\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7198\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.6997\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7326\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7288\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7357\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4853\u001b[0m      \u001b[32m0.4157\u001b[0m        \u001b[35m1.2467\u001b[0m  1.7484\n",
            "      2      \u001b[36m0.7884\u001b[0m      \u001b[32m0.7816\u001b[0m        \u001b[35m0.5969\u001b[0m  1.7362\n",
            "      3      \u001b[36m0.9242\u001b[0m      \u001b[32m0.9237\u001b[0m        \u001b[35m0.2269\u001b[0m  1.7368\n",
            "      4      \u001b[36m0.9772\u001b[0m      \u001b[32m0.9771\u001b[0m        \u001b[35m0.0699\u001b[0m  1.7143\n",
            "      5      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0174\u001b[0m  1.7179\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0043\u001b[0m  1.7452\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.7325\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7207\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7250\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7333\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4720\u001b[0m      \u001b[32m0.3979\u001b[0m        \u001b[35m1.2711\u001b[0m  1.7354\n",
            "      2      \u001b[36m0.7756\u001b[0m      \u001b[32m0.7687\u001b[0m        \u001b[35m0.6167\u001b[0m  1.7302\n",
            "      3      \u001b[36m0.9444\u001b[0m      \u001b[32m0.9441\u001b[0m        \u001b[35m0.1651\u001b[0m  1.7322\n",
            "      4      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.0510\u001b[0m  1.7554\n",
            "      5      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0082\u001b[0m  1.7394\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0014\u001b[0m  1.7388\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7573\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7390\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7332\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7411\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4895\u001b[0m      \u001b[32m0.4355\u001b[0m        \u001b[35m1.2515\u001b[0m  1.7418\n",
            "      2      \u001b[36m0.7882\u001b[0m      \u001b[32m0.7760\u001b[0m        \u001b[35m0.6060\u001b[0m  1.7269\n",
            "      3      \u001b[36m0.9312\u001b[0m      \u001b[32m0.9301\u001b[0m        \u001b[35m0.2014\u001b[0m  1.7317\n",
            "      4      \u001b[36m0.9846\u001b[0m      \u001b[32m0.9844\u001b[0m        \u001b[35m0.0403\u001b[0m  1.7672\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0054\u001b[0m  1.7000\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  1.7140\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7336\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7255\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7380\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7273\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4906\u001b[0m      \u001b[32m0.4280\u001b[0m        \u001b[35m1.2502\u001b[0m  1.7343\n",
            "      2      \u001b[36m0.8073\u001b[0m      \u001b[32m0.7979\u001b[0m        \u001b[35m0.5778\u001b[0m  1.7162\n",
            "      3      \u001b[36m0.9356\u001b[0m      \u001b[32m0.9352\u001b[0m        \u001b[35m0.1876\u001b[0m  1.7227\n",
            "      4      \u001b[36m0.9746\u001b[0m      \u001b[32m0.9746\u001b[0m        \u001b[35m0.0693\u001b[0m  1.7036\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0042\u001b[0m  1.7144\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  1.7353\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7257\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7594\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7365\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7218\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4868\u001b[0m      \u001b[32m0.4310\u001b[0m        \u001b[35m1.3384\u001b[0m  2.4518\n",
            "      2      \u001b[36m0.8392\u001b[0m      \u001b[32m0.8294\u001b[0m        \u001b[35m0.5040\u001b[0m  2.4617\n",
            "      3      \u001b[36m0.9481\u001b[0m      \u001b[32m0.9475\u001b[0m        \u001b[35m0.1431\u001b[0m  2.4429\n",
            "      4      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9886\u001b[0m        \u001b[35m0.0374\u001b[0m  2.4812\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0032\u001b[0m  2.4995\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  2.4972\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.5092\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4708\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.5071\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4665\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4606\u001b[0m      \u001b[32m0.4049\u001b[0m        \u001b[35m1.3502\u001b[0m  2.4790\n",
            "      2      \u001b[36m0.7818\u001b[0m      \u001b[32m0.7726\u001b[0m        \u001b[35m0.6778\u001b[0m  2.4829\n",
            "      3      \u001b[36m0.9301\u001b[0m      \u001b[32m0.9295\u001b[0m        \u001b[35m0.2024\u001b[0m  2.4646\n",
            "      4      \u001b[36m0.9857\u001b[0m      \u001b[32m0.9856\u001b[0m        \u001b[35m0.0503\u001b[0m  2.4657\n",
            "      5      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0156\u001b[0m  2.4757\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  2.5082\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  2.4730\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4598\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4649\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4371\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4783\u001b[0m      \u001b[32m0.4212\u001b[0m        \u001b[35m1.3462\u001b[0m  2.4743\n",
            "      2      \u001b[36m0.8113\u001b[0m      \u001b[32m0.8010\u001b[0m        \u001b[35m0.5936\u001b[0m  2.4917\n",
            "      3      \u001b[36m0.9459\u001b[0m      \u001b[32m0.9452\u001b[0m        \u001b[35m0.1589\u001b[0m  2.4601\n",
            "      4      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9908\u001b[0m        \u001b[35m0.0287\u001b[0m  2.4355\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0023\u001b[0m  2.4629\n",
            "      6      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  2.4689\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  2.4524\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  2.4649\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4576\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4511\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4715\u001b[0m      \u001b[32m0.4178\u001b[0m        \u001b[35m1.3387\u001b[0m  2.4830\n",
            "      2      \u001b[36m0.7882\u001b[0m      \u001b[32m0.7786\u001b[0m        \u001b[35m0.6509\u001b[0m  2.4966\n",
            "      3      \u001b[36m0.9301\u001b[0m      \u001b[32m0.9294\u001b[0m        \u001b[35m0.2050\u001b[0m  2.4820\n",
            "      4      \u001b[36m0.9860\u001b[0m      \u001b[32m0.9860\u001b[0m        \u001b[35m0.0402\u001b[0m  2.4627\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0037\u001b[0m  2.4738\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  2.5037\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  2.4549\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4867\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4854\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4723\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4869\u001b[0m      \u001b[32m0.4354\u001b[0m        \u001b[35m1.3074\u001b[0m  2.4708\n",
            "      2      \u001b[36m0.8124\u001b[0m      \u001b[32m0.8022\u001b[0m        \u001b[35m0.5607\u001b[0m  2.4592\n",
            "      3      \u001b[36m0.9459\u001b[0m      \u001b[32m0.9452\u001b[0m        \u001b[35m0.1537\u001b[0m  2.4633\n",
            "      4      \u001b[36m0.9897\u001b[0m      \u001b[32m0.9897\u001b[0m        \u001b[35m0.0346\u001b[0m  2.4492\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0048\u001b[0m  2.4598\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  2.4397\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4391\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4328\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4558\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4515\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4713\u001b[0m      \u001b[32m0.4160\u001b[0m        \u001b[35m1.5256\u001b[0m  4.0076\n",
            "      2      \u001b[36m0.8013\u001b[0m      \u001b[32m0.7908\u001b[0m        \u001b[35m0.6393\u001b[0m  4.0337\n",
            "      3      \u001b[36m0.9529\u001b[0m      \u001b[32m0.9523\u001b[0m        \u001b[35m0.1527\u001b[0m  4.0398\n",
            "      4      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0198\u001b[0m  4.0263\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  4.0308\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0393\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0078\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0529\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0190\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0379\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4665\u001b[0m      \u001b[32m0.4218\u001b[0m        \u001b[35m1.5220\u001b[0m  4.0246\n",
            "      2      \u001b[36m0.7973\u001b[0m      \u001b[32m0.7859\u001b[0m        \u001b[35m0.6630\u001b[0m  4.0172\n",
            "      3      \u001b[36m0.9470\u001b[0m      \u001b[32m0.9464\u001b[0m        \u001b[35m0.1620\u001b[0m  4.0321\n",
            "      4      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9893\u001b[0m        \u001b[35m0.0291\u001b[0m  4.0078\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0046\u001b[0m  4.0132\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  4.0247\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0548\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0766\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0733\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0560\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4650\u001b[0m      \u001b[32m0.3918\u001b[0m        \u001b[35m1.4908\u001b[0m  4.0654\n",
            "      2      \u001b[36m0.7888\u001b[0m      \u001b[32m0.7803\u001b[0m        \u001b[35m0.6714\u001b[0m  4.0513\n",
            "      3      \u001b[36m0.9500\u001b[0m      \u001b[32m0.9497\u001b[0m        \u001b[35m0.1536\u001b[0m  4.0269\n",
            "      4      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0209\u001b[0m  4.0226\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0023\u001b[0m  4.0188\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  4.0320\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0508\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0594\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.1016\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0816\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4605\u001b[0m      \u001b[32m0.3922\u001b[0m        \u001b[35m1.5955\u001b[0m  4.0364\n",
            "      2      \u001b[36m0.7705\u001b[0m      \u001b[32m0.7565\u001b[0m        \u001b[35m0.7495\u001b[0m  4.0492\n",
            "      3      \u001b[36m0.9246\u001b[0m      \u001b[32m0.9234\u001b[0m        \u001b[35m0.2078\u001b[0m  4.0312\n",
            "      4      \u001b[36m0.9838\u001b[0m      \u001b[32m0.9837\u001b[0m        \u001b[35m0.0527\u001b[0m  4.0351\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0074\u001b[0m  4.0328\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  4.0216\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0436\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0243\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0040\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0262\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4689\u001b[0m      \u001b[32m0.4184\u001b[0m        \u001b[35m1.5361\u001b[0m  4.0524\n",
            "      2      \u001b[36m0.8025\u001b[0m      \u001b[32m0.7916\u001b[0m        \u001b[35m0.6174\u001b[0m  4.0254\n",
            "      3      \u001b[36m0.9485\u001b[0m      \u001b[32m0.9476\u001b[0m        \u001b[35m0.1609\u001b[0m  4.0415\n",
            "      4      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0266\u001b[0m  4.0443\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0038\u001b[0m  4.0606\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  4.0655\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  4.0319\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0240\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  4.0492\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0370\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4886\u001b[0m      \u001b[32m0.4258\u001b[0m        \u001b[35m1.2303\u001b[0m  1.3733\n",
            "      2      \u001b[36m0.7829\u001b[0m      \u001b[32m0.7635\u001b[0m        \u001b[35m0.5988\u001b[0m  1.3475\n",
            "      3      \u001b[36m0.9124\u001b[0m      \u001b[32m0.9109\u001b[0m        \u001b[35m0.2512\u001b[0m  1.3560\n",
            "      4      \u001b[36m0.9687\u001b[0m      \u001b[32m0.9684\u001b[0m        \u001b[35m0.0814\u001b[0m  1.3695\n",
            "      5      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9949\u001b[0m        \u001b[35m0.0208\u001b[0m  1.3620\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0031\u001b[0m  1.3655\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  1.3498\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3713\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3497\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3473\n",
            "     11      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3501\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3706\n",
            "     13      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3460\n",
            "     14      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3650\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3694\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3477\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3750\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3686\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3727\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3648\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4768\u001b[0m      \u001b[32m0.4181\u001b[0m        \u001b[35m1.2184\u001b[0m  1.3802\n",
            "      2      \u001b[36m0.8083\u001b[0m      \u001b[32m0.7977\u001b[0m        \u001b[35m0.5225\u001b[0m  1.3711\n",
            "      3      \u001b[36m0.9382\u001b[0m      \u001b[32m0.9379\u001b[0m        \u001b[35m0.1688\u001b[0m  1.3873\n",
            "      4      \u001b[36m0.9834\u001b[0m      \u001b[32m0.9834\u001b[0m        \u001b[35m0.0519\u001b[0m  1.3960\n",
            "      5      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9960\u001b[0m        \u001b[35m0.0106\u001b[0m  1.3885\n",
            "      6      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0031\u001b[0m  1.3976\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3790\n",
            "      8      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.3738\n",
            "      9      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3853\n",
            "     10      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3740\n",
            "     11      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3584\n",
            "     12      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3610\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3863\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3775\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3429\n",
            "     16      1.0000      1.0000        0.0004  1.3812\n",
            "     17      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3910\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3682\n",
            "     19      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3726\n",
            "     20      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3792\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4823\u001b[0m      \u001b[32m0.4270\u001b[0m        \u001b[35m1.2186\u001b[0m  1.4056\n",
            "      2      \u001b[36m0.8079\u001b[0m      \u001b[32m0.7945\u001b[0m        \u001b[35m0.5441\u001b[0m  1.3799\n",
            "      3      \u001b[36m0.9404\u001b[0m      \u001b[32m0.9396\u001b[0m        \u001b[35m0.1763\u001b[0m  1.3777\n",
            "      4      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9867\u001b[0m        \u001b[35m0.0464\u001b[0m  1.3893\n",
            "      5      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0129\u001b[0m  1.3843\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0026\u001b[0m  1.3968\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0012\u001b[0m  1.3603\n",
            "      8      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.3875\n",
            "      9      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3966\n",
            "     10      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3666\n",
            "     11      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3674\n",
            "     12      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3795\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3913\n",
            "     14      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3697\n",
            "     15      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3625\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3673\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3881\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3684\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3721\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3682\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4796\u001b[0m      \u001b[32m0.4172\u001b[0m        \u001b[35m1.2383\u001b[0m  1.3821\n",
            "      2      \u001b[36m0.7863\u001b[0m      \u001b[32m0.7765\u001b[0m        \u001b[35m0.6280\u001b[0m  1.3782\n",
            "      3      \u001b[36m0.9081\u001b[0m      \u001b[32m0.9067\u001b[0m        \u001b[35m0.2685\u001b[0m  1.3550\n",
            "      4      \u001b[36m0.9746\u001b[0m      \u001b[32m0.9746\u001b[0m        \u001b[35m0.0777\u001b[0m  1.3791\n",
            "      5      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0206\u001b[0m  1.3589\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0056\u001b[0m  1.3890\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0030\u001b[0m  1.3663\n",
            "      8      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  1.3711\n",
            "      9      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.3925\n",
            "     10      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  1.3794\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     11      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.4036\n",
            "     12      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3810\n",
            "     13      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3474\n",
            "     14      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3623\n",
            "     15      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3807\n",
            "     16      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3661\n",
            "     17      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3591\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3774\n",
            "     19      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3612\n",
            "     20      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3877\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4803\u001b[0m      \u001b[32m0.4135\u001b[0m        \u001b[35m1.2259\u001b[0m  1.3583\n",
            "      2      \u001b[36m0.8084\u001b[0m      \u001b[32m0.8009\u001b[0m        \u001b[35m0.5618\u001b[0m  1.3759\n",
            "      3      \u001b[36m0.9338\u001b[0m      \u001b[32m0.9333\u001b[0m        \u001b[35m0.1982\u001b[0m  1.3361\n",
            "      4      \u001b[36m0.9757\u001b[0m      \u001b[32m0.9757\u001b[0m        \u001b[35m0.0732\u001b[0m  1.3688\n",
            "      5      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0177\u001b[0m  1.3476\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0031\u001b[0m  1.3636\n",
            "      7      0.9996      0.9996        \u001b[35m0.0016\u001b[0m  1.3532\n",
            "      8      0.9996      0.9996        \u001b[35m0.0012\u001b[0m  1.3714\n",
            "      9      0.9996      0.9996        \u001b[35m0.0009\u001b[0m  1.3609\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.3763\n",
            "     11      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  1.3520\n",
            "     12      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3641\n",
            "     13      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3508\n",
            "     14      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3668\n",
            "     15      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3845\n",
            "     16      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3879\n",
            "     17      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3807\n",
            "     18      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3734\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3615\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3793\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4790\u001b[0m      \u001b[32m0.4192\u001b[0m        \u001b[35m1.2494\u001b[0m  1.7515\n",
            "      2      \u001b[36m0.8444\u001b[0m      \u001b[32m0.8385\u001b[0m        \u001b[35m0.4543\u001b[0m  1.7120\n",
            "      3      \u001b[36m0.9547\u001b[0m      \u001b[32m0.9546\u001b[0m        \u001b[35m0.1405\u001b[0m  1.7189\n",
            "      4      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0215\u001b[0m  1.7349\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0042\u001b[0m  1.7187\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.7518\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7379\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7213\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7215\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7191\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7209\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7194\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7366\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7484\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7438\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7559\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7171\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7294\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7289\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7547\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4868\u001b[0m      \u001b[32m0.4324\u001b[0m        \u001b[35m1.2397\u001b[0m  1.7446\n",
            "      2      \u001b[36m0.8124\u001b[0m      \u001b[32m0.8045\u001b[0m        \u001b[35m0.5269\u001b[0m  1.7369\n",
            "      3      \u001b[36m0.9547\u001b[0m      \u001b[32m0.9544\u001b[0m        \u001b[35m0.1179\u001b[0m  1.7177\n",
            "      4      \u001b[36m0.9897\u001b[0m      \u001b[32m0.9897\u001b[0m        \u001b[35m0.0283\u001b[0m  1.7265\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0057\u001b[0m  1.7402\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  1.7299\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7350\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7350\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7280\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7577\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7530\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7198\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7407\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7380\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7300\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7280\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7375\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7406\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7306\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7369\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4669\u001b[0m      \u001b[32m0.4125\u001b[0m        \u001b[35m1.2472\u001b[0m  1.7428\n",
            "      2      \u001b[36m0.8021\u001b[0m      \u001b[32m0.7941\u001b[0m        \u001b[35m0.5764\u001b[0m  1.7257\n",
            "      3      \u001b[36m0.9481\u001b[0m      \u001b[32m0.9476\u001b[0m        \u001b[35m0.1580\u001b[0m  1.7242\n",
            "      4      \u001b[36m0.9890\u001b[0m      \u001b[32m0.9890\u001b[0m        \u001b[35m0.0360\u001b[0m  1.7056\n",
            "      5      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0103\u001b[0m  1.7107\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0015\u001b[0m  1.7263\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.7306\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.7340\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7231\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7323\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7211\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7169\n",
            "     13      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7186\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7289\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7080\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7272\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7428\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7570\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7525\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7292\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4777\u001b[0m      \u001b[32m0.4100\u001b[0m        \u001b[35m1.2534\u001b[0m  1.7389\n",
            "      2      \u001b[36m0.8025\u001b[0m      \u001b[32m0.7940\u001b[0m        \u001b[35m0.6017\u001b[0m  1.7345\n",
            "      3      \u001b[36m0.9331\u001b[0m      \u001b[32m0.9324\u001b[0m        \u001b[35m0.1996\u001b[0m  1.7300\n",
            "      4      \u001b[36m0.9853\u001b[0m      \u001b[32m0.9853\u001b[0m        \u001b[35m0.0412\u001b[0m  1.7231\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0048\u001b[0m  1.7247\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.7406\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7291\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7452\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7373\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7461\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7305\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7521\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7356\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7324\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7364\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7121\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7345\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7098\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7285\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7225\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4752\u001b[0m      \u001b[32m0.4189\u001b[0m        \u001b[35m1.2461\u001b[0m  1.7274\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      2      \u001b[36m0.7716\u001b[0m      \u001b[32m0.7649\u001b[0m        \u001b[35m0.6597\u001b[0m  1.7227\n",
            "      3      \u001b[36m0.9246\u001b[0m      \u001b[32m0.9242\u001b[0m        \u001b[35m0.2286\u001b[0m  1.7134\n",
            "      4      \u001b[36m0.9691\u001b[0m      \u001b[32m0.9691\u001b[0m        \u001b[35m0.0823\u001b[0m  1.7223\n",
            "      5      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0144\u001b[0m  1.7199\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.7275\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.7152\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7188\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.7250\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7468\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7137\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7282\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.7402\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7392\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7706\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7338\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7382\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7599\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7352\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.7425\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4801\u001b[0m      \u001b[32m0.4207\u001b[0m        \u001b[35m1.3274\u001b[0m  2.4730\n",
            "      2      \u001b[36m0.8120\u001b[0m      \u001b[32m0.8034\u001b[0m        \u001b[35m0.5572\u001b[0m  2.4593\n",
            "      3      \u001b[36m0.9375\u001b[0m      \u001b[32m0.9369\u001b[0m        \u001b[35m0.1907\u001b[0m  2.4572\n",
            "      4      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0242\u001b[0m  2.4681\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0042\u001b[0m  2.4772\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  2.4825\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  2.4707\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  2.4818\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  2.5223\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4609\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4638\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4427\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4359\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4562\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4468\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4376\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4372\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4489\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4328\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4497\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4823\u001b[0m      \u001b[32m0.4314\u001b[0m        \u001b[35m1.2854\u001b[0m  2.4970\n",
            "      2      \u001b[36m0.8050\u001b[0m      \u001b[32m0.7995\u001b[0m        \u001b[35m0.5825\u001b[0m  2.4714\n",
            "      3      \u001b[36m0.9257\u001b[0m      \u001b[32m0.9254\u001b[0m        \u001b[35m0.2221\u001b[0m  2.4745\n",
            "      4      \u001b[36m0.9779\u001b[0m      \u001b[32m0.9779\u001b[0m        \u001b[35m0.0662\u001b[0m  2.4817\n",
            "      5      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0222\u001b[0m  2.4545\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0039\u001b[0m  2.4554\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  2.4771\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4683\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4715\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4636\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4849\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4679\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4671\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4768\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4896\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4808\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4982\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4745\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4954\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4360\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4746\u001b[0m      \u001b[32m0.4227\u001b[0m        \u001b[35m1.3247\u001b[0m  2.4627\n",
            "      2      \u001b[36m0.8289\u001b[0m      \u001b[32m0.8148\u001b[0m        \u001b[35m0.5486\u001b[0m  2.4413\n",
            "      3      \u001b[36m0.9463\u001b[0m      \u001b[32m0.9458\u001b[0m        \u001b[35m0.1586\u001b[0m  2.4550\n",
            "      4      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0247\u001b[0m  2.4796\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0022\u001b[0m  2.5087\n",
            "      6      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  2.4820\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  2.5191\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  2.4876\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  2.4990\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4822\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4814\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4787\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4702\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4524\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4610\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.5029\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4551\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4641\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4588\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4497\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4792\u001b[0m      \u001b[32m0.4275\u001b[0m        \u001b[35m1.3354\u001b[0m  2.4324\n",
            "      2      \u001b[36m0.8271\u001b[0m      \u001b[32m0.8162\u001b[0m        \u001b[35m0.5424\u001b[0m  2.4538\n",
            "      3      \u001b[36m0.9592\u001b[0m      \u001b[32m0.9589\u001b[0m        \u001b[35m0.1101\u001b[0m  2.4665\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0177\u001b[0m  2.4629\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0023\u001b[0m  2.4438\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  2.4516\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4848\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4786\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4589\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4709\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4743\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4355\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4754\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4479\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4517\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4592\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4818\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4512\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4756\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4648\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4814\u001b[0m      \u001b[32m0.4239\u001b[0m        \u001b[35m1.3151\u001b[0m  2.4428\n",
            "      2      \u001b[36m0.7808\u001b[0m      \u001b[32m0.7729\u001b[0m        \u001b[35m0.6626\u001b[0m  2.4843\n",
            "      3      \u001b[36m0.9022\u001b[0m      \u001b[32m0.9017\u001b[0m        \u001b[35m0.2777\u001b[0m  2.4614\n",
            "      4      \u001b[36m0.9842\u001b[0m      \u001b[32m0.9842\u001b[0m        \u001b[35m0.0560\u001b[0m  2.4735\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0038\u001b[0m  2.4755\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  2.4749\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.4692\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4678\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4871\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4859\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4780\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4690\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4775\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4918\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4509\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4542\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4914\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4780\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.4697\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.4756\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4831\u001b[0m      \u001b[32m0.4248\u001b[0m        \u001b[35m1.4820\u001b[0m  4.0469\n",
            "      2      \u001b[36m0.7792\u001b[0m      \u001b[32m0.7693\u001b[0m        \u001b[35m0.6988\u001b[0m  4.0346\n",
            "      3      \u001b[36m0.9433\u001b[0m      \u001b[32m0.9429\u001b[0m        \u001b[35m0.1706\u001b[0m  4.0469\n",
            "      4      \u001b[36m0.9845\u001b[0m      \u001b[32m0.9845\u001b[0m        \u001b[35m0.0423\u001b[0m  4.0400\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0057\u001b[0m  4.0569\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  4.0594\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  4.0640\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0551\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0678\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0370\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0726\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0633\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0594\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0507\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0716\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0420\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0678\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0324\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0201\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0194\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4547\u001b[0m      \u001b[32m0.3983\u001b[0m        \u001b[35m1.5049\u001b[0m  4.0118\n",
            "      2      \u001b[36m0.7546\u001b[0m      \u001b[32m0.7439\u001b[0m        \u001b[35m0.7748\u001b[0m  4.0418\n",
            "      3      \u001b[36m0.9308\u001b[0m      \u001b[32m0.9295\u001b[0m        \u001b[35m0.2089\u001b[0m  4.0331\n",
            "      4      \u001b[36m0.9845\u001b[0m      \u001b[32m0.9845\u001b[0m        \u001b[35m0.0442\u001b[0m  4.0704\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0051\u001b[0m  4.0780\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  4.0450\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  4.0059\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  4.0368\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0367\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0495\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0012\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0276\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0354\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0067\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0265\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0385\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0089\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0457\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0535\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0130\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4713\u001b[0m      \u001b[32m0.4135\u001b[0m        \u001b[35m1.5147\u001b[0m  4.0046\n",
            "      2      \u001b[36m0.7770\u001b[0m      \u001b[32m0.7685\u001b[0m        \u001b[35m0.7018\u001b[0m  3.9998\n",
            "      3      \u001b[36m0.9238\u001b[0m      \u001b[32m0.9232\u001b[0m        \u001b[35m0.2090\u001b[0m  4.0111\n",
            "      4      \u001b[36m0.9871\u001b[0m      \u001b[32m0.9871\u001b[0m        \u001b[35m0.0378\u001b[0m  4.1448\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0046\u001b[0m  4.0584\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  4.0491\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0457\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0415\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0014\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  3.9956\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0101\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0411\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0471\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0572\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0315\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0284\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0200\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0254\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0620\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0157\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4686\u001b[0m      \u001b[32m0.4209\u001b[0m        \u001b[35m1.5732\u001b[0m  4.0163\n",
            "      2      \u001b[36m0.7915\u001b[0m      \u001b[32m0.7775\u001b[0m        \u001b[35m0.6655\u001b[0m  4.0126\n",
            "      3      \u001b[36m0.9334\u001b[0m      \u001b[32m0.9325\u001b[0m        \u001b[35m0.1980\u001b[0m  4.0435\n",
            "      4      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9886\u001b[0m        \u001b[35m0.0391\u001b[0m  4.0312\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0033\u001b[0m  4.0426\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  4.0333\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0678\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0541\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0365\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0235\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0204\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0142\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0193\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0239\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0284\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0268\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0271\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0292\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0269\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  4.0157\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4730\u001b[0m      \u001b[32m0.4284\u001b[0m        \u001b[35m1.5368\u001b[0m  4.0022\n",
            "      2      \u001b[36m0.7999\u001b[0m      \u001b[32m0.7903\u001b[0m        \u001b[35m0.6249\u001b[0m  4.0435\n",
            "      3      \u001b[36m0.9386\u001b[0m      \u001b[32m0.9380\u001b[0m        \u001b[35m0.1812\u001b[0m  4.0420\n",
            "      4      \u001b[36m0.9860\u001b[0m      \u001b[32m0.9860\u001b[0m        \u001b[35m0.0355\u001b[0m  4.0475\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0026\u001b[0m  4.0110\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  4.0375\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0339\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0498\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  4.0355\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0277\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0305\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0117\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0314\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0306\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0287\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0233\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0378\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0539\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0454\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  4.0585\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4231\u001b[0m      \u001b[32m0.3644\u001b[0m        \u001b[35m1.4723\u001b[0m  0.7284\n",
            "      2      \u001b[36m0.5173\u001b[0m      \u001b[32m0.3784\u001b[0m        \u001b[35m1.1634\u001b[0m  0.7080\n",
            "      3      \u001b[36m0.7016\u001b[0m      \u001b[32m0.6335\u001b[0m        \u001b[35m0.9944\u001b[0m  0.7196\n",
            "      4      \u001b[36m0.7888\u001b[0m      \u001b[32m0.7237\u001b[0m        \u001b[35m0.7277\u001b[0m  0.6959\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5      \u001b[36m0.8874\u001b[0m      \u001b[32m0.8690\u001b[0m        \u001b[35m0.4434\u001b[0m  0.7097\n",
            "      6      \u001b[36m0.9595\u001b[0m      \u001b[32m0.9581\u001b[0m        \u001b[35m0.2451\u001b[0m  0.7139\n",
            "      7      \u001b[36m0.9834\u001b[0m      \u001b[32m0.9832\u001b[0m        \u001b[35m0.1414\u001b[0m  0.7053\n",
            "      8      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9908\u001b[0m        \u001b[35m0.0895\u001b[0m  0.7140\n",
            "      9      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0611\u001b[0m  0.7215\n",
            "     10      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0439\u001b[0m  0.7131\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4805\u001b[0m      \u001b[32m0.3377\u001b[0m        \u001b[35m1.3959\u001b[0m  0.7177\n",
            "      2      \u001b[36m0.5265\u001b[0m      \u001b[32m0.3952\u001b[0m        \u001b[35m1.1438\u001b[0m  0.7183\n",
            "      3      \u001b[36m0.7068\u001b[0m      \u001b[32m0.6385\u001b[0m        \u001b[35m0.9696\u001b[0m  0.7101\n",
            "      4      \u001b[36m0.7958\u001b[0m      \u001b[32m0.7282\u001b[0m        \u001b[35m0.6940\u001b[0m  0.7192\n",
            "      5      \u001b[36m0.8911\u001b[0m      \u001b[32m0.8756\u001b[0m        \u001b[35m0.4179\u001b[0m  0.7069\n",
            "      6      \u001b[36m0.9617\u001b[0m      \u001b[32m0.9604\u001b[0m        \u001b[35m0.2368\u001b[0m  0.7039\n",
            "      7      \u001b[36m0.9860\u001b[0m      \u001b[32m0.9858\u001b[0m        \u001b[35m0.1405\u001b[0m  0.7176\n",
            "      8      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9911\u001b[0m        \u001b[35m0.0900\u001b[0m  0.7045\n",
            "      9      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0619\u001b[0m  0.7189\n",
            "     10      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0449\u001b[0m  0.7220\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.3867\u001b[0m      \u001b[32m0.3727\u001b[0m        \u001b[35m1.4593\u001b[0m  0.7861\n",
            "      2      \u001b[36m0.5143\u001b[0m      \u001b[32m0.3740\u001b[0m        \u001b[35m1.1703\u001b[0m  0.7958\n",
            "      3      \u001b[36m0.6913\u001b[0m      \u001b[32m0.6223\u001b[0m        \u001b[35m0.9944\u001b[0m  0.7471\n",
            "      4      \u001b[36m0.7855\u001b[0m      \u001b[32m0.7211\u001b[0m        \u001b[35m0.7140\u001b[0m  0.7203\n",
            "      5      \u001b[36m0.8804\u001b[0m      \u001b[32m0.8595\u001b[0m        \u001b[35m0.4349\u001b[0m  0.7430\n",
            "      6      \u001b[36m0.9577\u001b[0m      \u001b[32m0.9559\u001b[0m        \u001b[35m0.2477\u001b[0m  0.7141\n",
            "      7      \u001b[36m0.9849\u001b[0m      \u001b[32m0.9847\u001b[0m        \u001b[35m0.1461\u001b[0m  0.7264\n",
            "      8      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0927\u001b[0m  0.7090\n",
            "      9      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0629\u001b[0m  0.7526\n",
            "     10      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0450\u001b[0m  0.8011\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4833\u001b[0m      \u001b[32m0.3247\u001b[0m        \u001b[35m1.4007\u001b[0m  0.7167\n",
            "      2      \u001b[36m0.5149\u001b[0m      \u001b[32m0.3745\u001b[0m        \u001b[35m1.1558\u001b[0m  0.7844\n",
            "      3      \u001b[36m0.6690\u001b[0m      \u001b[32m0.5981\u001b[0m        \u001b[35m0.9856\u001b[0m  0.7193\n",
            "      4      \u001b[36m0.7790\u001b[0m      \u001b[32m0.7200\u001b[0m        \u001b[35m0.7018\u001b[0m  0.7209\n",
            "      5      \u001b[36m0.8908\u001b[0m      \u001b[32m0.8771\u001b[0m        \u001b[35m0.4170\u001b[0m  0.7168\n",
            "      6      \u001b[36m0.9618\u001b[0m      \u001b[32m0.9607\u001b[0m        \u001b[35m0.2328\u001b[0m  0.7929\n",
            "      7      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9866\u001b[0m        \u001b[35m0.1374\u001b[0m  0.7887\n",
            "      8      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0883\u001b[0m  0.7290\n",
            "      9      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0607\u001b[0m  0.7276\n",
            "     10      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0437\u001b[0m  0.7246\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4211\u001b[0m      \u001b[32m0.3235\u001b[0m        \u001b[35m1.4256\u001b[0m  0.7256\n",
            "      2      \u001b[36m0.5182\u001b[0m      \u001b[32m0.3826\u001b[0m        \u001b[35m1.1533\u001b[0m  0.7211\n",
            "      3      \u001b[36m0.6786\u001b[0m      \u001b[32m0.6079\u001b[0m        \u001b[35m0.9731\u001b[0m  0.7240\n",
            "      4      \u001b[36m0.7815\u001b[0m      \u001b[32m0.7163\u001b[0m        \u001b[35m0.6914\u001b[0m  0.7227\n",
            "      5      \u001b[36m0.8963\u001b[0m      \u001b[32m0.8841\u001b[0m        \u001b[35m0.4155\u001b[0m  0.7254\n",
            "      6      \u001b[36m0.9636\u001b[0m      \u001b[32m0.9623\u001b[0m        \u001b[35m0.2328\u001b[0m  0.7070\n",
            "      7      \u001b[36m0.9875\u001b[0m      \u001b[32m0.9873\u001b[0m        \u001b[35m0.1362\u001b[0m  0.7042\n",
            "      8      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0866\u001b[0m  0.7178\n",
            "      9      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0590\u001b[0m  0.7314\n",
            "     10      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0424\u001b[0m  0.7170\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4757\u001b[0m      \u001b[32m0.3653\u001b[0m        \u001b[35m1.3584\u001b[0m  0.9314\n",
            "      2      \u001b[36m0.5581\u001b[0m      \u001b[32m0.4504\u001b[0m        \u001b[35m1.1081\u001b[0m  0.9191\n",
            "      3      \u001b[36m0.7601\u001b[0m      \u001b[32m0.6898\u001b[0m        \u001b[35m0.8182\u001b[0m  0.9336\n",
            "      4      \u001b[36m0.8742\u001b[0m      \u001b[32m0.8533\u001b[0m        \u001b[35m0.4417\u001b[0m  0.9248\n",
            "      5      \u001b[36m0.9588\u001b[0m      \u001b[32m0.9574\u001b[0m        \u001b[35m0.2000\u001b[0m  0.9325\n",
            "      6      \u001b[36m0.9879\u001b[0m      \u001b[32m0.9877\u001b[0m        \u001b[35m0.1014\u001b[0m  0.9266\n",
            "      7      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0603\u001b[0m  0.9160\n",
            "      8      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0395\u001b[0m  0.9129\n",
            "      9      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0276\u001b[0m  0.9184\n",
            "     10      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0202\u001b[0m  0.9135\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4525\u001b[0m      \u001b[32m0.3290\u001b[0m        \u001b[35m1.3772\u001b[0m  0.9174\n",
            "      2      \u001b[36m0.5846\u001b[0m      \u001b[32m0.4915\u001b[0m        \u001b[35m1.1039\u001b[0m  0.9199\n",
            "      3      \u001b[36m0.7649\u001b[0m      \u001b[32m0.6957\u001b[0m        \u001b[35m0.8080\u001b[0m  0.9120\n",
            "      4      \u001b[36m0.8793\u001b[0m      \u001b[32m0.8593\u001b[0m        \u001b[35m0.4327\u001b[0m  0.9113\n",
            "      5      \u001b[36m0.9687\u001b[0m      \u001b[32m0.9677\u001b[0m        \u001b[35m0.1958\u001b[0m  0.9153\n",
            "      6      \u001b[36m0.9901\u001b[0m      \u001b[32m0.9900\u001b[0m        \u001b[35m0.0989\u001b[0m  0.9009\n",
            "      7      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0585\u001b[0m  0.9095\n",
            "      8      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0386\u001b[0m  0.8990\n",
            "      9      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0271\u001b[0m  0.8959\n",
            "     10      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0200\u001b[0m  0.9137\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4886\u001b[0m      \u001b[32m0.3244\u001b[0m        \u001b[35m1.3391\u001b[0m  0.9030\n",
            "      2      \u001b[36m0.5574\u001b[0m      \u001b[32m0.4502\u001b[0m        \u001b[35m1.1073\u001b[0m  0.9252\n",
            "      3      \u001b[36m0.7502\u001b[0m      \u001b[32m0.6807\u001b[0m        \u001b[35m0.8212\u001b[0m  0.9120\n",
            "      4      \u001b[36m0.8738\u001b[0m      \u001b[32m0.8513\u001b[0m        \u001b[35m0.4469\u001b[0m  0.9473\n",
            "      5      \u001b[36m0.9599\u001b[0m      \u001b[32m0.9582\u001b[0m        \u001b[35m0.2044\u001b[0m  0.9158\n",
            "      6      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9892\u001b[0m        \u001b[35m0.1035\u001b[0m  0.9218\n",
            "      7      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0605\u001b[0m  0.9091\n",
            "      8      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0390\u001b[0m  0.8999\n",
            "      9      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0270\u001b[0m  0.9104\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0197\u001b[0m  0.9227\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4675\u001b[0m      \u001b[32m0.3585\u001b[0m        \u001b[35m1.3687\u001b[0m  0.9199\n",
            "      2      \u001b[36m0.5962\u001b[0m      \u001b[32m0.5093\u001b[0m        \u001b[35m1.1079\u001b[0m  0.9079\n",
            "      3      \u001b[36m0.7558\u001b[0m      \u001b[32m0.6853\u001b[0m        \u001b[35m0.8290\u001b[0m  0.9114\n",
            "      4      \u001b[36m0.8588\u001b[0m      \u001b[32m0.8315\u001b[0m        \u001b[35m0.4636\u001b[0m  0.9199\n",
            "      5      \u001b[36m0.9599\u001b[0m      \u001b[32m0.9583\u001b[0m        \u001b[35m0.2156\u001b[0m  0.9348\n",
            "      6      \u001b[36m0.9879\u001b[0m      \u001b[32m0.9877\u001b[0m        \u001b[35m0.1087\u001b[0m  0.9652\n",
            "      7      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0637\u001b[0m  1.0169\n",
            "      8      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0414\u001b[0m  0.9581\n",
            "      9      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0286\u001b[0m  0.9381\n",
            "     10      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0209\u001b[0m  0.9715\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4351\u001b[0m      \u001b[32m0.3980\u001b[0m        \u001b[35m1.3516\u001b[0m  0.9419\n",
            "      2      \u001b[36m0.5973\u001b[0m      \u001b[32m0.5107\u001b[0m        \u001b[35m1.1052\u001b[0m  0.9284\n",
            "      3      \u001b[36m0.7617\u001b[0m      \u001b[32m0.6927\u001b[0m        \u001b[35m0.8172\u001b[0m  0.9307\n",
            "      4      \u001b[36m0.8746\u001b[0m      \u001b[32m0.8561\u001b[0m        \u001b[35m0.4430\u001b[0m  0.9248\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5      \u001b[36m0.9720\u001b[0m      \u001b[32m0.9713\u001b[0m        \u001b[35m0.1968\u001b[0m  0.9210\n",
            "      6      \u001b[36m0.9923\u001b[0m      \u001b[32m0.9922\u001b[0m        \u001b[35m0.0981\u001b[0m  0.9102\n",
            "      7      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9944\u001b[0m        \u001b[35m0.0577\u001b[0m  0.9503\n",
            "      8      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0378\u001b[0m  0.9215\n",
            "      9      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0264\u001b[0m  0.9088\n",
            "     10      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0194\u001b[0m  0.9225\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4753\u001b[0m      \u001b[32m0.3869\u001b[0m        \u001b[35m1.3314\u001b[0m  1.3128\n",
            "      2      \u001b[36m0.6667\u001b[0m      \u001b[32m0.5965\u001b[0m        \u001b[35m1.0385\u001b[0m  1.2943\n",
            "      3      \u001b[36m0.8010\u001b[0m      \u001b[32m0.7481\u001b[0m        \u001b[35m0.6227\u001b[0m  1.2971\n",
            "      4      \u001b[36m0.9459\u001b[0m      \u001b[32m0.9431\u001b[0m        \u001b[35m0.2370\u001b[0m  1.2991\n",
            "      5      \u001b[36m0.9845\u001b[0m      \u001b[32m0.9843\u001b[0m        \u001b[35m0.0932\u001b[0m  1.2957\n",
            "      6      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0483\u001b[0m  1.3262\n",
            "      7      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0294\u001b[0m  1.3277\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0194\u001b[0m  1.3334\n",
            "      9      0.9993      0.9993        \u001b[35m0.0135\u001b[0m  1.2982\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0100\u001b[0m  1.3056\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4864\u001b[0m      \u001b[32m0.3501\u001b[0m        \u001b[35m1.3205\u001b[0m  1.4056\n",
            "      2      \u001b[36m0.6714\u001b[0m      \u001b[32m0.6008\u001b[0m        \u001b[35m1.0225\u001b[0m  1.3404\n",
            "      3      \u001b[36m0.8138\u001b[0m      \u001b[32m0.7641\u001b[0m        \u001b[35m0.6089\u001b[0m  1.3153\n",
            "      4      \u001b[36m0.9474\u001b[0m      \u001b[32m0.9446\u001b[0m        \u001b[35m0.2381\u001b[0m  1.2954\n",
            "      5      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9892\u001b[0m        \u001b[35m0.0950\u001b[0m  1.3260\n",
            "      6      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0491\u001b[0m  1.3054\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0300\u001b[0m  1.3123\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0199\u001b[0m  1.3084\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0141\u001b[0m  1.3338\n",
            "     10      0.9996      0.9996        \u001b[35m0.0105\u001b[0m  1.3083\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4871\u001b[0m      \u001b[32m0.3310\u001b[0m        \u001b[35m1.3153\u001b[0m  1.3655\n",
            "      2      \u001b[36m0.6670\u001b[0m      \u001b[32m0.5966\u001b[0m        \u001b[35m1.0220\u001b[0m  1.3303\n",
            "      3      \u001b[36m0.8098\u001b[0m      \u001b[32m0.7610\u001b[0m        \u001b[35m0.6048\u001b[0m  1.3204\n",
            "      4      \u001b[36m0.9448\u001b[0m      \u001b[32m0.9418\u001b[0m        \u001b[35m0.2354\u001b[0m  1.3187\n",
            "      5      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9885\u001b[0m        \u001b[35m0.0933\u001b[0m  1.3136\n",
            "      6      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0474\u001b[0m  1.3294\n",
            "      7      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0282\u001b[0m  1.3422\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0184\u001b[0m  1.3286\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0128\u001b[0m  1.3760\n",
            "     10      1.0000      1.0000        \u001b[35m0.0095\u001b[0m  1.3091\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4807\u001b[0m      \u001b[32m0.3256\u001b[0m        \u001b[35m1.3254\u001b[0m  1.3936\n",
            "      2      \u001b[36m0.6561\u001b[0m      \u001b[32m0.5847\u001b[0m        \u001b[35m1.0314\u001b[0m  1.3408\n",
            "      3      \u001b[36m0.8025\u001b[0m      \u001b[32m0.7487\u001b[0m        \u001b[35m0.6130\u001b[0m  1.3146\n",
            "      4      \u001b[36m0.9489\u001b[0m      \u001b[32m0.9463\u001b[0m        \u001b[35m0.2344\u001b[0m  1.3190\n",
            "      5      \u001b[36m0.9882\u001b[0m      \u001b[32m0.9881\u001b[0m        \u001b[35m0.0921\u001b[0m  1.3183\n",
            "      6      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0476\u001b[0m  1.3058\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0291\u001b[0m  1.3519\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0191\u001b[0m  1.3945\n",
            "      9      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0134\u001b[0m  1.3212\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0100\u001b[0m  1.3092\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4869\u001b[0m      \u001b[32m0.3379\u001b[0m        \u001b[35m1.3228\u001b[0m  1.3013\n",
            "      2      \u001b[36m0.6672\u001b[0m      \u001b[32m0.5971\u001b[0m        \u001b[35m1.0237\u001b[0m  1.3062\n",
            "      3      \u001b[36m0.7988\u001b[0m      \u001b[32m0.7426\u001b[0m        \u001b[35m0.6172\u001b[0m  1.3105\n",
            "      4      \u001b[36m0.9467\u001b[0m      \u001b[32m0.9437\u001b[0m        \u001b[35m0.2426\u001b[0m  1.3062\n",
            "      5      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9892\u001b[0m        \u001b[35m0.0945\u001b[0m  1.3034\n",
            "      6      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0478\u001b[0m  1.3051\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0288\u001b[0m  1.3097\n",
            "      8      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0189\u001b[0m  1.2972\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0133\u001b[0m  1.3029\n",
            "     10      0.9996      0.9996        \u001b[35m0.0098\u001b[0m  1.3042\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4757\u001b[0m      \u001b[32m0.4092\u001b[0m        \u001b[35m1.3052\u001b[0m  1.9520\n",
            "      2      \u001b[36m0.7215\u001b[0m      \u001b[32m0.6533\u001b[0m        \u001b[35m0.9168\u001b[0m  1.9634\n",
            "      3      \u001b[36m0.8867\u001b[0m      \u001b[32m0.8713\u001b[0m        \u001b[35m0.3900\u001b[0m  1.9745\n",
            "      4      \u001b[36m0.9801\u001b[0m      \u001b[32m0.9798\u001b[0m        \u001b[35m0.1099\u001b[0m  1.9626\n",
            "      5      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0445\u001b[0m  1.9602\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0241\u001b[0m  1.9591\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0147\u001b[0m  1.9585\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0097\u001b[0m  1.9584\n",
            "      9      0.9996      0.9996        \u001b[35m0.0069\u001b[0m  1.9582\n",
            "     10      0.9996      0.9996        \u001b[35m0.0052\u001b[0m  1.9631\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4801\u001b[0m      \u001b[32m0.3434\u001b[0m        \u001b[35m1.3047\u001b[0m  1.9669\n",
            "      2      \u001b[36m0.7071\u001b[0m      \u001b[32m0.6381\u001b[0m        \u001b[35m0.9188\u001b[0m  1.9555\n",
            "      3      \u001b[36m0.8834\u001b[0m      \u001b[32m0.8679\u001b[0m        \u001b[35m0.3954\u001b[0m  1.9501\n",
            "      4      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9828\u001b[0m        \u001b[35m0.1126\u001b[0m  1.9612\n",
            "      5      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9933\u001b[0m        \u001b[35m0.0453\u001b[0m  1.9431\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0249\u001b[0m  1.9554\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0155\u001b[0m  1.9545\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0104\u001b[0m  1.9716\n",
            "      9      0.9996      0.9996        \u001b[35m0.0075\u001b[0m  1.9551\n",
            "     10      0.9996      0.9996        \u001b[35m0.0056\u001b[0m  1.9506\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4709\u001b[0m      \u001b[32m0.3573\u001b[0m        \u001b[35m1.3092\u001b[0m  1.9572\n",
            "      2      \u001b[36m0.7134\u001b[0m      \u001b[32m0.6453\u001b[0m        \u001b[35m0.9225\u001b[0m  1.9507\n",
            "      3      \u001b[36m0.8797\u001b[0m      \u001b[32m0.8630\u001b[0m        \u001b[35m0.4017\u001b[0m  1.9594\n",
            "      4      \u001b[36m0.9812\u001b[0m      \u001b[32m0.9809\u001b[0m        \u001b[35m0.1152\u001b[0m  1.9516\n",
            "      5      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0442\u001b[0m  1.9511\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0232\u001b[0m  1.9539\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0139\u001b[0m  1.9537\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0092\u001b[0m  1.9618\n",
            "      9      1.0000      1.0000        \u001b[35m0.0066\u001b[0m  1.9573\n",
            "     10      1.0000      1.0000        \u001b[35m0.0049\u001b[0m  1.9993\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4789\u001b[0m      \u001b[32m0.3340\u001b[0m        \u001b[35m1.3044\u001b[0m  1.9675\n",
            "      2      \u001b[36m0.7183\u001b[0m      \u001b[32m0.6491\u001b[0m        \u001b[35m0.9219\u001b[0m  1.9703\n",
            "      3      \u001b[36m0.8727\u001b[0m      \u001b[32m0.8551\u001b[0m        \u001b[35m0.4055\u001b[0m  1.9732\n",
            "      4      \u001b[36m0.9816\u001b[0m      \u001b[32m0.9813\u001b[0m        \u001b[35m0.1146\u001b[0m  1.9686\n",
            "      5      \u001b[36m0.9949\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0457\u001b[0m  1.9661\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0249\u001b[0m  1.9765\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0152\u001b[0m  1.9542\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0100\u001b[0m  1.9552\n",
            "      9      0.9996      0.9996        \u001b[35m0.0072\u001b[0m  1.9601\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0054\u001b[0m  1.9559\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4693\u001b[0m      \u001b[32m0.3590\u001b[0m        \u001b[35m1.3034\u001b[0m  1.9533\n",
            "      2      \u001b[36m0.7083\u001b[0m      \u001b[32m0.6398\u001b[0m        \u001b[35m0.9213\u001b[0m  1.9667\n",
            "      3      \u001b[36m0.8834\u001b[0m      \u001b[32m0.8673\u001b[0m        \u001b[35m0.3975\u001b[0m  1.9730\n",
            "      4      \u001b[36m0.9849\u001b[0m      \u001b[32m0.9847\u001b[0m        \u001b[35m0.1109\u001b[0m  1.9765\n",
            "      5      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9944\u001b[0m        \u001b[35m0.0436\u001b[0m  1.9683\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0236\u001b[0m  1.9794\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0143\u001b[0m  1.9788\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0095\u001b[0m  1.9839\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0068\u001b[0m  2.0045\n",
            "     10      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  2.0225\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4025\u001b[0m      \u001b[32m0.3862\u001b[0m        \u001b[35m1.4114\u001b[0m  0.8001\n",
            "      2      \u001b[36m0.5096\u001b[0m      0.3631        \u001b[35m1.1561\u001b[0m  0.7177\n",
            "      3      \u001b[36m0.7001\u001b[0m      \u001b[32m0.6312\u001b[0m        \u001b[35m0.9893\u001b[0m  0.7339\n",
            "      4      \u001b[36m0.7855\u001b[0m      \u001b[32m0.7170\u001b[0m        \u001b[35m0.7146\u001b[0m  0.7200\n",
            "      5      \u001b[36m0.8837\u001b[0m      \u001b[32m0.8638\u001b[0m        \u001b[35m0.4371\u001b[0m  0.7160\n",
            "      6      \u001b[36m0.9632\u001b[0m      \u001b[32m0.9618\u001b[0m        \u001b[35m0.2453\u001b[0m  0.7778\n",
            "      7      \u001b[36m0.9838\u001b[0m      \u001b[32m0.9836\u001b[0m        \u001b[35m0.1426\u001b[0m  0.8049\n",
            "      8      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0908\u001b[0m  0.7518\n",
            "      9      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0622\u001b[0m  0.7221\n",
            "     10      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0448\u001b[0m  0.7222\n",
            "     11      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0336\u001b[0m  0.7234\n",
            "     12      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0261\u001b[0m  0.7259\n",
            "     13      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0208\u001b[0m  0.7180\n",
            "     14      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0170\u001b[0m  0.7135\n",
            "     15      0.9996      0.9996        \u001b[35m0.0141\u001b[0m  0.7066\n",
            "     16      0.9996      0.9996        \u001b[35m0.0118\u001b[0m  0.7136\n",
            "     17      0.9996      0.9996        \u001b[35m0.0101\u001b[0m  0.7288\n",
            "     18      0.9996      0.9996        \u001b[35m0.0087\u001b[0m  0.7453\n",
            "     19      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0076\u001b[0m  0.7287\n",
            "     20      1.0000      1.0000        \u001b[35m0.0066\u001b[0m  0.7140\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4330\u001b[0m      \u001b[32m0.3937\u001b[0m        \u001b[35m1.4107\u001b[0m  0.7255\n",
            "      2      \u001b[36m0.5287\u001b[0m      \u001b[32m0.3998\u001b[0m        \u001b[35m1.1463\u001b[0m  0.7203\n",
            "      3      \u001b[36m0.7152\u001b[0m      \u001b[32m0.6467\u001b[0m        \u001b[35m0.9642\u001b[0m  0.7191\n",
            "      4      \u001b[36m0.7881\u001b[0m      \u001b[32m0.7186\u001b[0m        \u001b[35m0.6958\u001b[0m  0.7774\n",
            "      5      \u001b[36m0.8823\u001b[0m      \u001b[32m0.8620\u001b[0m        \u001b[35m0.4307\u001b[0m  0.8188\n",
            "      6      \u001b[36m0.9547\u001b[0m      \u001b[32m0.9526\u001b[0m        \u001b[35m0.2468\u001b[0m  0.7747\n",
            "      7      \u001b[36m0.9842\u001b[0m      \u001b[32m0.9840\u001b[0m        \u001b[35m0.1462\u001b[0m  0.7267\n",
            "      8      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9907\u001b[0m        \u001b[35m0.0933\u001b[0m  0.7151\n",
            "      9      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9944\u001b[0m        \u001b[35m0.0640\u001b[0m  0.7314\n",
            "     10      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0464\u001b[0m  0.7211\n",
            "     11      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0350\u001b[0m  0.7265\n",
            "     12      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0273\u001b[0m  0.7163\n",
            "     13      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0219\u001b[0m  0.7157\n",
            "     14      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0179\u001b[0m  0.7631\n",
            "     15      0.9996      0.9996        \u001b[35m0.0148\u001b[0m  0.8174\n",
            "     16      0.9996      0.9996        \u001b[35m0.0125\u001b[0m  0.7712\n",
            "     17      0.9996      0.9996        \u001b[35m0.0107\u001b[0m  0.7306\n",
            "     18      0.9996      0.9996        \u001b[35m0.0092\u001b[0m  0.7242\n",
            "     19      0.9996      0.9996        \u001b[35m0.0080\u001b[0m  0.7236\n",
            "     20      0.9996      0.9996        \u001b[35m0.0071\u001b[0m  0.7283\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.3672\u001b[0m      \u001b[32m0.3317\u001b[0m        \u001b[35m1.4388\u001b[0m  0.7222\n",
            "      2      \u001b[36m0.5088\u001b[0m      \u001b[32m0.3625\u001b[0m        \u001b[35m1.1628\u001b[0m  0.7250\n",
            "      3      \u001b[36m0.6902\u001b[0m      \u001b[32m0.6208\u001b[0m        \u001b[35m0.9942\u001b[0m  0.7995\n",
            "      4      \u001b[36m0.7837\u001b[0m      \u001b[32m0.7175\u001b[0m        \u001b[35m0.7217\u001b[0m  0.7729\n",
            "      5      \u001b[36m0.8848\u001b[0m      \u001b[32m0.8672\u001b[0m        \u001b[35m0.4416\u001b[0m  0.7367\n",
            "      6      \u001b[36m0.9566\u001b[0m      \u001b[32m0.9546\u001b[0m        \u001b[35m0.2502\u001b[0m  0.7184\n",
            "      7      \u001b[36m0.9845\u001b[0m      \u001b[32m0.9843\u001b[0m        \u001b[35m0.1472\u001b[0m  0.7941\n",
            "      8      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0933\u001b[0m  0.7966\n",
            "      9      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0633\u001b[0m  0.7228\n",
            "     10      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0452\u001b[0m  0.7480\n",
            "     11      0.9989      0.9989        \u001b[35m0.0337\u001b[0m  0.7195\n",
            "     12      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0260\u001b[0m  0.7254\n",
            "     13      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0207\u001b[0m  0.7077\n",
            "     14      1.0000      1.0000        \u001b[35m0.0168\u001b[0m  0.7054\n",
            "     15      1.0000      1.0000        \u001b[35m0.0139\u001b[0m  0.7069\n",
            "     16      1.0000      1.0000        \u001b[35m0.0117\u001b[0m  0.7072\n",
            "     17      1.0000      1.0000        \u001b[35m0.0099\u001b[0m  0.7253\n",
            "     18      1.0000      1.0000        \u001b[35m0.0085\u001b[0m  0.7151\n",
            "     19      1.0000      1.0000        \u001b[35m0.0074\u001b[0m  0.7321\n",
            "     20      1.0000      1.0000        \u001b[35m0.0065\u001b[0m  0.7120\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4888\u001b[0m      \u001b[32m0.3236\u001b[0m        \u001b[35m1.3974\u001b[0m  0.7235\n",
            "      2      \u001b[36m0.5245\u001b[0m      \u001b[32m0.3923\u001b[0m        \u001b[35m1.1452\u001b[0m  0.7172\n",
            "      3      \u001b[36m0.6756\u001b[0m      \u001b[32m0.6057\u001b[0m        \u001b[35m0.9781\u001b[0m  0.7276\n",
            "      4      \u001b[36m0.7764\u001b[0m      \u001b[32m0.7113\u001b[0m        \u001b[35m0.7065\u001b[0m  0.7104\n",
            "      5      \u001b[36m0.8886\u001b[0m      \u001b[32m0.8753\u001b[0m        \u001b[35m0.4290\u001b[0m  0.7218\n",
            "      6      \u001b[36m0.9629\u001b[0m      \u001b[32m0.9617\u001b[0m        \u001b[35m0.2421\u001b[0m  0.7064\n",
            "      7      \u001b[36m0.9842\u001b[0m      \u001b[32m0.9840\u001b[0m        \u001b[35m0.1435\u001b[0m  0.7119\n",
            "      8      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9918\u001b[0m        \u001b[35m0.0922\u001b[0m  0.7241\n",
            "      9      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0632\u001b[0m  0.7190\n",
            "     10      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0456\u001b[0m  0.7337\n",
            "     11      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0343\u001b[0m  0.7163\n",
            "     12      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0267\u001b[0m  0.7255\n",
            "     13      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0214\u001b[0m  0.6995\n",
            "     14      0.9996      0.9996        \u001b[35m0.0174\u001b[0m  0.7146\n",
            "     15      0.9996      0.9996        \u001b[35m0.0145\u001b[0m  0.7279\n",
            "     16      0.9996      0.9996        \u001b[35m0.0122\u001b[0m  0.7156\n",
            "     17      0.9996      0.9996        \u001b[35m0.0104\u001b[0m  0.7247\n",
            "     18      0.9996      0.9996        \u001b[35m0.0090\u001b[0m  0.7234\n",
            "     19      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0078\u001b[0m  0.7296\n",
            "     20      1.0000      1.0000        \u001b[35m0.0069\u001b[0m  0.7077\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4406\u001b[0m      \u001b[32m0.3269\u001b[0m        \u001b[35m1.4069\u001b[0m  0.7316\n",
            "      2      \u001b[36m0.5057\u001b[0m      \u001b[32m0.3549\u001b[0m        \u001b[35m1.1624\u001b[0m  0.7987\n",
            "      3      \u001b[36m0.6576\u001b[0m      \u001b[32m0.5851\u001b[0m        \u001b[35m0.9953\u001b[0m  0.7882\n",
            "      4      \u001b[36m0.7665\u001b[0m      \u001b[32m0.6994\u001b[0m        \u001b[35m0.7221\u001b[0m  0.7267\n",
            "      5      \u001b[36m0.8702\u001b[0m      \u001b[32m0.8448\u001b[0m        \u001b[35m0.4505\u001b[0m  0.7231\n",
            "      6      \u001b[36m0.9537\u001b[0m      \u001b[32m0.9516\u001b[0m        \u001b[35m0.2605\u001b[0m  0.7277\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      7      \u001b[36m0.9849\u001b[0m      \u001b[32m0.9847\u001b[0m        \u001b[35m0.1533\u001b[0m  0.7235\n",
            "      8      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0968\u001b[0m  0.7141\n",
            "      9      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0656\u001b[0m  0.7276\n",
            "     10      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0471\u001b[0m  0.7246\n",
            "     11      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0353\u001b[0m  0.7184\n",
            "     12      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0274\u001b[0m  0.7180\n",
            "     13      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0219\u001b[0m  0.7353\n",
            "     14      0.9996      0.9996        \u001b[35m0.0178\u001b[0m  0.7195\n",
            "     15      0.9996      0.9996        \u001b[35m0.0148\u001b[0m  0.7199\n",
            "     16      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0124\u001b[0m  0.7257\n",
            "     17      1.0000      1.0000        \u001b[35m0.0106\u001b[0m  0.7179\n",
            "     18      1.0000      1.0000        \u001b[35m0.0091\u001b[0m  0.7097\n",
            "     19      1.0000      1.0000        \u001b[35m0.0080\u001b[0m  0.7098\n",
            "     20      1.0000      1.0000        \u001b[35m0.0070\u001b[0m  0.7227\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4882\u001b[0m      \u001b[32m0.3234\u001b[0m        \u001b[35m1.3737\u001b[0m  0.9291\n",
            "      2      \u001b[36m0.5806\u001b[0m      \u001b[32m0.4856\u001b[0m        \u001b[35m1.1051\u001b[0m  0.9264\n",
            "      3      \u001b[36m0.7564\u001b[0m      \u001b[32m0.6852\u001b[0m        \u001b[35m0.8185\u001b[0m  0.9148\n",
            "      4      \u001b[36m0.8694\u001b[0m      \u001b[32m0.8462\u001b[0m        \u001b[35m0.4494\u001b[0m  0.9206\n",
            "      5      \u001b[36m0.9673\u001b[0m      \u001b[32m0.9664\u001b[0m        \u001b[35m0.2025\u001b[0m  0.9198\n",
            "      6      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9866\u001b[0m        \u001b[35m0.1010\u001b[0m  0.9106\n",
            "      7      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0597\u001b[0m  0.9112\n",
            "      8      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0391\u001b[0m  0.9172\n",
            "      9      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0272\u001b[0m  0.9075\n",
            "     10      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0198\u001b[0m  0.9086\n",
            "     11      0.9993      0.9993        \u001b[35m0.0151\u001b[0m  0.9185\n",
            "     12      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0118\u001b[0m  0.9119\n",
            "     13      0.9996      0.9996        \u001b[35m0.0095\u001b[0m  0.9145\n",
            "     14      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0078\u001b[0m  0.9106\n",
            "     15      1.0000      1.0000        \u001b[35m0.0065\u001b[0m  0.9109\n",
            "     16      1.0000      1.0000        \u001b[35m0.0055\u001b[0m  0.9123\n",
            "     17      1.0000      1.0000        \u001b[35m0.0047\u001b[0m  0.9218\n",
            "     18      1.0000      1.0000        \u001b[35m0.0041\u001b[0m  0.9154\n",
            "     19      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  0.9156\n",
            "     20      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  0.9169\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4658\u001b[0m      \u001b[32m0.3759\u001b[0m        \u001b[35m1.3528\u001b[0m  0.9039\n",
            "      2      \u001b[36m0.5762\u001b[0m      \u001b[32m0.4788\u001b[0m        \u001b[35m1.1026\u001b[0m  0.9183\n",
            "      3      \u001b[36m0.7553\u001b[0m      \u001b[32m0.6854\u001b[0m        \u001b[35m0.8181\u001b[0m  0.9222\n",
            "      4      \u001b[36m0.8790\u001b[0m      \u001b[32m0.8601\u001b[0m        \u001b[35m0.4428\u001b[0m  0.9804\n",
            "      5      \u001b[36m0.9665\u001b[0m      \u001b[32m0.9654\u001b[0m        \u001b[35m0.1990\u001b[0m  0.9277\n",
            "      6      \u001b[36m0.9893\u001b[0m      \u001b[32m0.9892\u001b[0m        \u001b[35m0.1009\u001b[0m  0.9207\n",
            "      7      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0598\u001b[0m  0.9184\n",
            "      8      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0394\u001b[0m  0.9115\n",
            "      9      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0277\u001b[0m  0.9053\n",
            "     10      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0204\u001b[0m  0.9230\n",
            "     11      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0157\u001b[0m  0.9320\n",
            "     12      0.9996      0.9996        \u001b[35m0.0124\u001b[0m  0.9033\n",
            "     13      0.9996      0.9996        \u001b[35m0.0100\u001b[0m  0.9122\n",
            "     14      0.9996      0.9996        \u001b[35m0.0083\u001b[0m  0.9246\n",
            "     15      0.9996      0.9996        \u001b[35m0.0069\u001b[0m  0.9192\n",
            "     16      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0059\u001b[0m  0.9037\n",
            "     17      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  0.9057\n",
            "     18      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  0.9219\n",
            "     19      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  0.9165\n",
            "     20      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  0.9126\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4397\u001b[0m      \u001b[32m0.3528\u001b[0m        \u001b[35m1.3837\u001b[0m  0.9338\n",
            "      2      \u001b[36m0.5695\u001b[0m      \u001b[32m0.4697\u001b[0m        \u001b[35m1.1129\u001b[0m  0.9228\n",
            "      3      \u001b[36m0.7414\u001b[0m      \u001b[32m0.6727\u001b[0m        \u001b[35m0.8279\u001b[0m  0.9921\n",
            "      4      \u001b[36m0.8672\u001b[0m      \u001b[32m0.8448\u001b[0m        \u001b[35m0.4516\u001b[0m  1.0117\n",
            "      5      \u001b[36m0.9632\u001b[0m      \u001b[32m0.9619\u001b[0m        \u001b[35m0.2037\u001b[0m  0.9256\n",
            "      6      \u001b[36m0.9897\u001b[0m      \u001b[32m0.9896\u001b[0m        \u001b[35m0.1023\u001b[0m  0.9829\n",
            "      7      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0597\u001b[0m  1.0046\n",
            "      8      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0384\u001b[0m  1.0024\n",
            "      9      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0264\u001b[0m  0.9277\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0192\u001b[0m  0.9282\n",
            "     11      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0146\u001b[0m  0.9335\n",
            "     12      1.0000      1.0000        \u001b[35m0.0114\u001b[0m  0.9361\n",
            "     13      1.0000      1.0000        \u001b[35m0.0092\u001b[0m  0.9425\n",
            "     14      1.0000      1.0000        \u001b[35m0.0075\u001b[0m  1.0205\n",
            "     15      1.0000      1.0000        \u001b[35m0.0063\u001b[0m  0.9739\n",
            "     16      1.0000      1.0000        \u001b[35m0.0053\u001b[0m  0.9214\n",
            "     17      1.0000      1.0000        \u001b[35m0.0045\u001b[0m  1.0046\n",
            "     18      1.0000      1.0000        \u001b[35m0.0039\u001b[0m  0.9950\n",
            "     19      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  0.9481\n",
            "     20      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  0.9387\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4369\u001b[0m      \u001b[32m0.3801\u001b[0m        \u001b[35m1.3890\u001b[0m  0.9296\n",
            "      2      \u001b[36m0.5969\u001b[0m      \u001b[32m0.5099\u001b[0m        \u001b[35m1.1087\u001b[0m  0.9248\n",
            "      3      \u001b[36m0.7565\u001b[0m      \u001b[32m0.6864\u001b[0m        \u001b[35m0.8269\u001b[0m  0.9175\n",
            "      4      \u001b[36m0.8617\u001b[0m      \u001b[32m0.8360\u001b[0m        \u001b[35m0.4608\u001b[0m  0.9166\n",
            "      5      \u001b[36m0.9629\u001b[0m      \u001b[32m0.9617\u001b[0m        \u001b[35m0.2119\u001b[0m  0.9113\n",
            "      6      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9885\u001b[0m        \u001b[35m0.1062\u001b[0m  0.9236\n",
            "      7      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0622\u001b[0m  0.9218\n",
            "      8      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0405\u001b[0m  0.9276\n",
            "      9      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0281\u001b[0m  0.9310\n",
            "     10      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0206\u001b[0m  0.9343\n",
            "     11      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0157\u001b[0m  0.9313\n",
            "     12      0.9996      0.9996        \u001b[35m0.0124\u001b[0m  0.9255\n",
            "     13      0.9996      0.9996        \u001b[35m0.0100\u001b[0m  0.9321\n",
            "     14      0.9996      0.9996        \u001b[35m0.0082\u001b[0m  0.9308\n",
            "     15      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0069\u001b[0m  0.9317\n",
            "     16      1.0000      1.0000        \u001b[35m0.0059\u001b[0m  0.9398\n",
            "     17      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  0.9380\n",
            "     18      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  0.9351\n",
            "     19      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  0.9768\n",
            "     20      1.0000      1.0000        \u001b[35m0.0033\u001b[0m  0.9230\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4910\u001b[0m      \u001b[32m0.3234\u001b[0m        \u001b[35m1.3476\u001b[0m  0.9225\n",
            "      2      \u001b[36m0.5885\u001b[0m      \u001b[32m0.4977\u001b[0m        \u001b[35m1.1011\u001b[0m  0.9262\n",
            "      3      \u001b[36m0.7455\u001b[0m      \u001b[32m0.6755\u001b[0m        \u001b[35m0.8197\u001b[0m  0.9334\n",
            "      4      \u001b[36m0.8761\u001b[0m      \u001b[32m0.8561\u001b[0m        \u001b[35m0.4485\u001b[0m  0.9241\n",
            "      5      \u001b[36m0.9676\u001b[0m      \u001b[32m0.9666\u001b[0m        \u001b[35m0.2008\u001b[0m  0.9261\n",
            "      6      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9907\u001b[0m        \u001b[35m0.0999\u001b[0m  0.9280\n",
            "      7      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0586\u001b[0m  0.9123\n",
            "      8      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0383\u001b[0m  0.9086\n",
            "      9      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0266\u001b[0m  0.9260\n",
            "     10      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0195\u001b[0m  0.9189\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     11      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0149\u001b[0m  0.9313\n",
            "     12      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0117\u001b[0m  0.9281\n",
            "     13      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0095\u001b[0m  0.9178\n",
            "     14      1.0000      1.0000        \u001b[35m0.0078\u001b[0m  0.9079\n",
            "     15      1.0000      1.0000        \u001b[35m0.0065\u001b[0m  0.9158\n",
            "     16      1.0000      1.0000        \u001b[35m0.0055\u001b[0m  0.9273\n",
            "     17      1.0000      1.0000        \u001b[35m0.0047\u001b[0m  0.9167\n",
            "     18      1.0000      1.0000        \u001b[35m0.0041\u001b[0m  0.9156\n",
            "     19      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  0.9179\n",
            "     20      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  0.9218\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4687\u001b[0m      \u001b[32m0.4140\u001b[0m        \u001b[35m1.3186\u001b[0m  1.3143\n",
            "      2      \u001b[36m0.6762\u001b[0m      \u001b[32m0.6071\u001b[0m        \u001b[35m1.0333\u001b[0m  1.3117\n",
            "      3      \u001b[36m0.8039\u001b[0m      \u001b[32m0.7539\u001b[0m        \u001b[35m0.6202\u001b[0m  1.3064\n",
            "      4      \u001b[36m0.9470\u001b[0m      \u001b[32m0.9443\u001b[0m        \u001b[35m0.2367\u001b[0m  1.3151\n",
            "      5      \u001b[36m0.9857\u001b[0m      \u001b[32m0.9855\u001b[0m        \u001b[35m0.0933\u001b[0m  1.3170\n",
            "      6      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0485\u001b[0m  1.3084\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0294\u001b[0m  1.2997\n",
            "      8      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0193\u001b[0m  1.2954\n",
            "      9      0.9993      0.9993        \u001b[35m0.0135\u001b[0m  1.2934\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0099\u001b[0m  1.3073\n",
            "     11      0.9996      0.9996        \u001b[35m0.0076\u001b[0m  1.3049\n",
            "     12      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0060\u001b[0m  1.3199\n",
            "     13      1.0000      1.0000        \u001b[35m0.0049\u001b[0m  1.3060\n",
            "     14      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  1.3114\n",
            "     15      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  1.2995\n",
            "     16      1.0000      1.0000        \u001b[35m0.0028\u001b[0m  1.2916\n",
            "     17      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.3074\n",
            "     18      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.2893\n",
            "     19      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  1.3071\n",
            "     20      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.2970\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4853\u001b[0m      \u001b[32m0.3273\u001b[0m        \u001b[35m1.3241\u001b[0m  1.3008\n",
            "      2      \u001b[36m0.6663\u001b[0m      \u001b[32m0.5955\u001b[0m        \u001b[35m1.0287\u001b[0m  1.3027\n",
            "      3      \u001b[36m0.8087\u001b[0m      \u001b[32m0.7555\u001b[0m        \u001b[35m0.6185\u001b[0m  1.2879\n",
            "      4      \u001b[36m0.9437\u001b[0m      \u001b[32m0.9405\u001b[0m        \u001b[35m0.2427\u001b[0m  1.2936\n",
            "      5      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9866\u001b[0m        \u001b[35m0.0958\u001b[0m  1.3158\n",
            "      6      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0493\u001b[0m  1.3044\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0301\u001b[0m  1.3491\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0200\u001b[0m  1.4104\n",
            "      9      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0141\u001b[0m  1.3237\n",
            "     10      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0105\u001b[0m  1.3057\n",
            "     11      0.9996      0.9996        \u001b[35m0.0081\u001b[0m  1.3056\n",
            "     12      0.9996      0.9996        \u001b[35m0.0065\u001b[0m  1.3038\n",
            "     13      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0053\u001b[0m  1.2929\n",
            "     14      1.0000      1.0000        \u001b[35m0.0043\u001b[0m  1.2945\n",
            "     15      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  1.3021\n",
            "     16      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.2944\n",
            "     17      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  1.2896\n",
            "     18      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  1.3010\n",
            "     19      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  1.2927\n",
            "     20      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.2948\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4897\u001b[0m      \u001b[32m0.3270\u001b[0m        \u001b[35m1.3191\u001b[0m  1.3129\n",
            "      2      \u001b[36m0.6656\u001b[0m      \u001b[32m0.5953\u001b[0m        \u001b[35m1.0203\u001b[0m  1.2937\n",
            "      3      \u001b[36m0.8153\u001b[0m      \u001b[32m0.7698\u001b[0m        \u001b[35m0.5989\u001b[0m  1.3102\n",
            "      4      \u001b[36m0.9489\u001b[0m      \u001b[32m0.9458\u001b[0m        \u001b[35m0.2301\u001b[0m  1.2924\n",
            "      5      \u001b[36m0.9882\u001b[0m      \u001b[32m0.9881\u001b[0m        \u001b[35m0.0922\u001b[0m  1.3039\n",
            "      6      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0471\u001b[0m  1.2840\n",
            "      7      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0281\u001b[0m  1.3015\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0183\u001b[0m  1.2851\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0128\u001b[0m  1.2840\n",
            "     10      1.0000      1.0000        \u001b[35m0.0095\u001b[0m  1.2932\n",
            "     11      1.0000      1.0000        \u001b[35m0.0073\u001b[0m  1.3156\n",
            "     12      1.0000      1.0000        \u001b[35m0.0057\u001b[0m  1.3099\n",
            "     13      1.0000      1.0000        \u001b[35m0.0046\u001b[0m  1.3064\n",
            "     14      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  1.3063\n",
            "     15      1.0000      1.0000        \u001b[35m0.0032\u001b[0m  1.3023\n",
            "     16      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  1.2955\n",
            "     17      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.2973\n",
            "     18      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  1.2912\n",
            "     19      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.3079\n",
            "     20      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  1.3107\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4722\u001b[0m      \u001b[32m0.3245\u001b[0m        \u001b[35m1.3323\u001b[0m  1.2857\n",
            "      2      \u001b[36m0.6701\u001b[0m      \u001b[32m0.6002\u001b[0m        \u001b[35m1.0272\u001b[0m  1.2998\n",
            "      3      \u001b[36m0.8051\u001b[0m      \u001b[32m0.7501\u001b[0m        \u001b[35m0.6204\u001b[0m  1.2889\n",
            "      4      \u001b[36m0.9434\u001b[0m      \u001b[32m0.9399\u001b[0m        \u001b[35m0.2450\u001b[0m  1.3097\n",
            "      5      \u001b[36m0.9868\u001b[0m      \u001b[32m0.9866\u001b[0m        \u001b[35m0.0954\u001b[0m  1.2992\n",
            "      6      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0488\u001b[0m  1.2851\n",
            "      7      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0297\u001b[0m  1.2979\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0194\u001b[0m  1.3035\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0136\u001b[0m  1.3052\n",
            "     10      0.9996      0.9996        \u001b[35m0.0101\u001b[0m  1.3136\n",
            "     11      0.9996      0.9996        \u001b[35m0.0078\u001b[0m  1.2909\n",
            "     12      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0062\u001b[0m  1.2812\n",
            "     13      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  1.2976\n",
            "     14      1.0000      1.0000        \u001b[35m0.0042\u001b[0m  1.3063\n",
            "     15      1.0000      1.0000        \u001b[35m0.0035\u001b[0m  1.2801\n",
            "     16      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.2992\n",
            "     17      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  1.2991\n",
            "     18      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  1.3018\n",
            "     19      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  1.2837\n",
            "     20      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.3141\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4811\u001b[0m      \u001b[32m0.3410\u001b[0m        \u001b[35m1.3256\u001b[0m  1.3143\n",
            "      2      \u001b[36m0.6499\u001b[0m      \u001b[32m0.5767\u001b[0m        \u001b[35m1.0334\u001b[0m  1.3064\n",
            "      3      \u001b[36m0.7988\u001b[0m      \u001b[32m0.7449\u001b[0m        \u001b[35m0.6185\u001b[0m  1.3053\n",
            "      4      \u001b[36m0.9467\u001b[0m      \u001b[32m0.9438\u001b[0m        \u001b[35m0.2402\u001b[0m  1.3181\n",
            "      5      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9885\u001b[0m        \u001b[35m0.0947\u001b[0m  1.3234\n",
            "      6      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0484\u001b[0m  1.3441\n",
            "      7      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0293\u001b[0m  1.3721\n",
            "      8      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0192\u001b[0m  1.3244\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0135\u001b[0m  1.3177\n",
            "     10      0.9996      0.9996        \u001b[35m0.0100\u001b[0m  1.3096\n",
            "     11      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0077\u001b[0m  1.3073\n",
            "     12      1.0000      1.0000        \u001b[35m0.0061\u001b[0m  1.3037\n",
            "     13      1.0000      1.0000        \u001b[35m0.0049\u001b[0m  1.2990\n",
            "     14      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  1.3062\n",
            "     15      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  1.3028\n",
            "     16      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.3109\n",
            "     17      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  1.2927\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     18      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.2900\n",
            "     19      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  1.2977\n",
            "     20      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.2922\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4665\u001b[0m      \u001b[32m0.4134\u001b[0m        \u001b[35m1.3098\u001b[0m  2.0286\n",
            "      2      \u001b[36m0.7211\u001b[0m      \u001b[32m0.6532\u001b[0m        \u001b[35m0.9334\u001b[0m  1.9969\n",
            "      3      \u001b[36m0.8863\u001b[0m      \u001b[32m0.8711\u001b[0m        \u001b[35m0.4015\u001b[0m  1.9762\n",
            "      4      \u001b[36m0.9801\u001b[0m      \u001b[32m0.9798\u001b[0m        \u001b[35m0.1119\u001b[0m  1.9628\n",
            "      5      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0452\u001b[0m  1.9633\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0244\u001b[0m  1.9624\n",
            "      7      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0149\u001b[0m  1.9637\n",
            "      8      0.9993      0.9993        \u001b[35m0.0098\u001b[0m  1.9592\n",
            "      9      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0070\u001b[0m  1.9638\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0052\u001b[0m  1.9585\n",
            "     11      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  1.9538\n",
            "     12      1.0000      1.0000        \u001b[35m0.0032\u001b[0m  1.9598\n",
            "     13      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  1.9524\n",
            "     14      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  1.9696\n",
            "     15      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.9522\n",
            "     16      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.9716\n",
            "     17      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.9537\n",
            "     18      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.9805\n",
            "     19      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.9700\n",
            "     20      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.9564\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4890\u001b[0m      \u001b[32m0.3330\u001b[0m        \u001b[35m1.2994\u001b[0m  1.9890\n",
            "      2      \u001b[36m0.7009\u001b[0m      \u001b[32m0.6317\u001b[0m        \u001b[35m0.9275\u001b[0m  1.9775\n",
            "      3      \u001b[36m0.8797\u001b[0m      \u001b[32m0.8628\u001b[0m        \u001b[35m0.4113\u001b[0m  1.9659\n",
            "      4      \u001b[36m0.9816\u001b[0m      \u001b[32m0.9814\u001b[0m        \u001b[35m0.1175\u001b[0m  1.9611\n",
            "      5      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0463\u001b[0m  1.9556\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0252\u001b[0m  1.9616\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0156\u001b[0m  1.9772\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0105\u001b[0m  1.9811\n",
            "      9      0.9996      0.9996        \u001b[35m0.0075\u001b[0m  1.9795\n",
            "     10      0.9996      0.9996        \u001b[35m0.0057\u001b[0m  1.9644\n",
            "     11      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0044\u001b[0m  1.9649\n",
            "     12      1.0000      1.0000        \u001b[35m0.0035\u001b[0m  1.9620\n",
            "     13      1.0000      1.0000        \u001b[35m0.0029\u001b[0m  1.9765\n",
            "     14      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  1.9692\n",
            "     15      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  1.9698\n",
            "     16      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.9613\n",
            "     17      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.9687\n",
            "     18      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.9536\n",
            "     19      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  1.9600\n",
            "     20      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.9733\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4831\u001b[0m      \u001b[32m0.3449\u001b[0m        \u001b[35m1.2972\u001b[0m  1.9617\n",
            "      2      \u001b[36m0.7112\u001b[0m      \u001b[32m0.6430\u001b[0m        \u001b[35m0.9175\u001b[0m  1.9626\n",
            "      3      \u001b[36m0.8808\u001b[0m      \u001b[32m0.8638\u001b[0m        \u001b[35m0.3955\u001b[0m  1.9612\n",
            "      4      \u001b[36m0.9809\u001b[0m      \u001b[32m0.9805\u001b[0m        \u001b[35m0.1137\u001b[0m  1.9571\n",
            "      5      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0440\u001b[0m  1.9500\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0231\u001b[0m  1.9552\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0139\u001b[0m  1.9575\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0092\u001b[0m  1.9731\n",
            "      9      1.0000      1.0000        \u001b[35m0.0066\u001b[0m  1.9678\n",
            "     10      1.0000      1.0000        \u001b[35m0.0049\u001b[0m  1.9723\n",
            "     11      1.0000      1.0000        \u001b[35m0.0038\u001b[0m  1.9463\n",
            "     12      1.0000      1.0000        \u001b[35m0.0030\u001b[0m  1.9667\n",
            "     13      1.0000      1.0000        \u001b[35m0.0025\u001b[0m  1.9548\n",
            "     14      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.9541\n",
            "     15      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  1.9766\n",
            "     16      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.9658\n",
            "     17      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  1.9527\n",
            "     18      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  1.9627\n",
            "     19      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.9573\n",
            "     20      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.9575\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4873\u001b[0m      \u001b[32m0.3578\u001b[0m        \u001b[35m1.2926\u001b[0m  1.9432\n",
            "      2      \u001b[36m0.7201\u001b[0m      \u001b[32m0.6513\u001b[0m        \u001b[35m0.9179\u001b[0m  1.9597\n",
            "      3      \u001b[36m0.8739\u001b[0m      \u001b[32m0.8562\u001b[0m        \u001b[35m0.4074\u001b[0m  1.9798\n",
            "      4      \u001b[36m0.9823\u001b[0m      \u001b[32m0.9821\u001b[0m        \u001b[35m0.1156\u001b[0m  1.9461\n",
            "      5      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0458\u001b[0m  1.9526\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0248\u001b[0m  1.9721\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0151\u001b[0m  1.9588\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0100\u001b[0m  1.9528\n",
            "      9      0.9996      0.9996        \u001b[35m0.0072\u001b[0m  1.9697\n",
            "     10      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0054\u001b[0m  1.9495\n",
            "     11      1.0000      1.0000        \u001b[35m0.0042\u001b[0m  1.9647\n",
            "     12      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  1.9609\n",
            "     13      1.0000      1.0000        \u001b[35m0.0027\u001b[0m  1.9512\n",
            "     14      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  1.9535\n",
            "     15      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  2.0145\n",
            "     16      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  2.0279\n",
            "     17      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  2.0369\n",
            "     18      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  1.9571\n",
            "     19      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  1.9630\n",
            "     20      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  2.0146\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4921\u001b[0m      \u001b[32m0.3280\u001b[0m        \u001b[35m1.2946\u001b[0m  2.0703\n",
            "      2      \u001b[36m0.7102\u001b[0m      \u001b[32m0.6418\u001b[0m        \u001b[35m0.9161\u001b[0m  2.0362\n",
            "      3      \u001b[36m0.8823\u001b[0m      \u001b[32m0.8671\u001b[0m        \u001b[35m0.3970\u001b[0m  1.9615\n",
            "      4      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9827\u001b[0m        \u001b[35m0.1118\u001b[0m  1.9899\n",
            "      5      \u001b[36m0.9949\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0437\u001b[0m  1.9719\n",
            "      6      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0235\u001b[0m  1.9536\n",
            "      7      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0143\u001b[0m  1.9370\n",
            "      8      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0095\u001b[0m  1.9597\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0068\u001b[0m  1.9656\n",
            "     10      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  1.9622\n",
            "     11      1.0000      1.0000        \u001b[35m0.0040\u001b[0m  1.9509\n",
            "     12      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  1.9621\n",
            "     13      1.0000      1.0000        \u001b[35m0.0026\u001b[0m  1.9504\n",
            "     14      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  1.9617\n",
            "     15      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  1.9635\n",
            "     16      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  1.9672\n",
            "     17      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  2.0021\n",
            "     18      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  1.9759\n",
            "     19      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.9584\n",
            "     20      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.9663\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5029\u001b[0m      \u001b[32m0.4167\u001b[0m        \u001b[35m1.2196\u001b[0m  0.7883\n",
            "      2      \u001b[36m0.8815\u001b[0m      \u001b[32m0.8701\u001b[0m        \u001b[35m0.3609\u001b[0m  0.7929\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0188\u001b[0m  0.7276\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0025\u001b[0m  0.7272\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      5      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.7289\n",
            "      6      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7225\n",
            "      7      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7259\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7168\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7389\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7209\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4908\u001b[0m      \u001b[32m0.4140\u001b[0m        \u001b[35m1.2216\u001b[0m  0.7426\n",
            "      2      \u001b[36m0.8698\u001b[0m      \u001b[32m0.8569\u001b[0m        \u001b[35m0.3806\u001b[0m  0.7184\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0184\u001b[0m  0.7262\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0029\u001b[0m  0.7049\n",
            "      5      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.7194\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7158\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7211\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7704\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7270\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7220\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4823\u001b[0m      \u001b[32m0.4191\u001b[0m        \u001b[35m1.2315\u001b[0m  0.7428\n",
            "      2      \u001b[36m0.8639\u001b[0m      \u001b[32m0.8476\u001b[0m        \u001b[35m0.4006\u001b[0m  0.7252\n",
            "      3      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0235\u001b[0m  0.7088\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0028\u001b[0m  0.7114\n",
            "      5      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.7112\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7221\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7196\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7219\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7125\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7394\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4976\u001b[0m      \u001b[32m0.4127\u001b[0m        \u001b[35m1.2232\u001b[0m  0.7407\n",
            "      2      \u001b[36m0.8636\u001b[0m      \u001b[32m0.8485\u001b[0m        \u001b[35m0.3963\u001b[0m  0.7244\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0223\u001b[0m  0.7180\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0032\u001b[0m  0.7184\n",
            "      5      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.7205\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7329\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7247\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7352\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7172\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7174\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5064\u001b[0m      \u001b[32m0.4187\u001b[0m        \u001b[35m1.2154\u001b[0m  0.7170\n",
            "      2      \u001b[36m0.8628\u001b[0m      \u001b[32m0.8482\u001b[0m        \u001b[35m0.3999\u001b[0m  0.7116\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0162\u001b[0m  0.7005\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0027\u001b[0m  0.7217\n",
            "      5      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.7293\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7215\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7304\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7200\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7288\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7175\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4919\u001b[0m      \u001b[32m0.4270\u001b[0m        \u001b[35m1.2140\u001b[0m  0.9392\n",
            "      2      \u001b[36m0.9062\u001b[0m      \u001b[32m0.9006\u001b[0m        \u001b[35m0.2714\u001b[0m  0.9193\n",
            "      3      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0133\u001b[0m  0.9238\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0019\u001b[0m  0.9190\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.9044\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9074\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9186\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9311\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9209\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9202\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4971\u001b[0m      \u001b[32m0.4379\u001b[0m        \u001b[35m1.2238\u001b[0m  0.9303\n",
            "      2      \u001b[36m0.8977\u001b[0m      \u001b[32m0.8910\u001b[0m        \u001b[35m0.2974\u001b[0m  0.9156\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0127\u001b[0m  0.9125\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0020\u001b[0m  0.8910\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.9142\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.9186\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9150\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9246\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9228\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9291\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5033\u001b[0m      \u001b[32m0.4333\u001b[0m        \u001b[35m1.2185\u001b[0m  0.9080\n",
            "      2      \u001b[36m0.9007\u001b[0m      \u001b[32m0.8932\u001b[0m        \u001b[35m0.2815\u001b[0m  0.9203\n",
            "      3      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0119\u001b[0m  0.9225\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0016\u001b[0m  0.9205\n",
            "      5      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9090\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9102\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9157\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9159\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9050\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9307\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5002\u001b[0m      \u001b[32m0.4277\u001b[0m        \u001b[35m1.2183\u001b[0m  0.9256\n",
            "      2      \u001b[36m0.8941\u001b[0m      \u001b[32m0.8875\u001b[0m        \u001b[35m0.3058\u001b[0m  0.9224\n",
            "      3      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0110\u001b[0m  0.9214\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0018\u001b[0m  0.9139\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.9300\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.9291\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9786\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0116\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9499\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9391\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4998\u001b[0m      \u001b[32m0.4290\u001b[0m        \u001b[35m1.2154\u001b[0m  0.9321\n",
            "      2      \u001b[36m0.9058\u001b[0m      \u001b[32m0.9006\u001b[0m        \u001b[35m0.2715\u001b[0m  0.9209\n",
            "      3      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0079\u001b[0m  0.9279\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0012\u001b[0m  0.9327\n",
            "      5      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9403\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9387\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9310\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9319\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9381\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9379\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5011\u001b[0m      \u001b[32m0.4365\u001b[0m        \u001b[35m1.2111\u001b[0m  1.3157\n",
            "      2      \u001b[36m0.9264\u001b[0m      \u001b[32m0.9239\u001b[0m        \u001b[35m0.2217\u001b[0m  1.3567\n",
            "      3      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0119\u001b[0m  1.3665\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0013\u001b[0m  1.3346\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.3172\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2903\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2953\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3074\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3158\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3213\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5052\u001b[0m      \u001b[32m0.4443\u001b[0m        \u001b[35m1.2136\u001b[0m  1.3038\n",
            "      2      \u001b[36m0.9194\u001b[0m      \u001b[32m0.9159\u001b[0m        \u001b[35m0.2289\u001b[0m  1.2998\n",
            "      3      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9960\u001b[0m        \u001b[35m0.0167\u001b[0m  1.2982\n",
            "      4      0.9945      0.9945        0.0181  1.3939\n",
            "      5      0.9952      0.9952        \u001b[35m0.0158\u001b[0m  1.3283\n",
            "      6      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0046\u001b[0m  1.3120\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.3073\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2966\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3079\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2980\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5096\u001b[0m      \u001b[32m0.4380\u001b[0m        \u001b[35m1.2090\u001b[0m  1.3176\n",
            "      2      \u001b[36m0.9235\u001b[0m      \u001b[32m0.9199\u001b[0m        \u001b[35m0.2176\u001b[0m  1.3205\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0147\u001b[0m  1.3173\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0021\u001b[0m  1.3122\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.3065\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3019\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3129\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3144\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3183\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3103\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5039\u001b[0m      \u001b[32m0.4366\u001b[0m        \u001b[35m1.2180\u001b[0m  1.3120\n",
            "      2      \u001b[36m0.9073\u001b[0m      \u001b[32m0.9033\u001b[0m        \u001b[35m0.2582\u001b[0m  1.3122\n",
            "      3      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0141\u001b[0m  1.3215\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0018\u001b[0m  1.3126\n",
            "      5      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.2900\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.2928\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3108\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3053\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3072\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2882\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5009\u001b[0m      \u001b[32m0.4367\u001b[0m        \u001b[35m1.2123\u001b[0m  1.3088\n",
            "      2      \u001b[36m0.9191\u001b[0m      \u001b[32m0.9160\u001b[0m        \u001b[35m0.2327\u001b[0m  1.3082\n",
            "      3      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0191\u001b[0m  1.3203\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0022\u001b[0m  1.2953\n",
            "      5      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3100\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3145\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3215\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3021\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3002\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3117\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4971\u001b[0m      \u001b[32m0.4457\u001b[0m        \u001b[35m1.2149\u001b[0m  1.9763\n",
            "      2      \u001b[36m0.9316\u001b[0m      \u001b[32m0.9299\u001b[0m        \u001b[35m0.2031\u001b[0m  1.9546\n",
            "      3      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0127\u001b[0m  1.9651\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0026\u001b[0m  1.9724\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  2.0339\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9988\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9980\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9728\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9564\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9705\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5055\u001b[0m      \u001b[32m0.4477\u001b[0m        \u001b[35m1.2065\u001b[0m  1.9593\n",
            "      2      \u001b[36m0.9422\u001b[0m      \u001b[32m0.9411\u001b[0m        \u001b[35m0.1968\u001b[0m  1.9482\n",
            "      3      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0228\u001b[0m  1.9647\n",
            "      4      0.9923      0.9923        \u001b[35m0.0210\u001b[0m  1.9737\n",
            "      5      0.9890      0.9890        0.0337  1.9597\n",
            "      6      0.9860      0.9860        0.0423  1.9723\n",
            "      7      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        0.0222  1.9596\n",
            "      8      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0086\u001b[0m  1.9619\n",
            "      9      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  1.9595\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9579\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5048\u001b[0m      \u001b[32m0.4440\u001b[0m        \u001b[35m1.2016\u001b[0m  1.9827\n",
            "      2      \u001b[36m0.9474\u001b[0m      \u001b[32m0.9467\u001b[0m        \u001b[35m0.1768\u001b[0m  1.9728\n",
            "      3      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0188\u001b[0m  1.9704\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0056\u001b[0m  1.9546\n",
            "      5      0.9982      0.9982        \u001b[35m0.0040\u001b[0m  1.9598\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0008\u001b[0m  1.9573\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.9766\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9687\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9483\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9600\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5042\u001b[0m      \u001b[32m0.4489\u001b[0m        \u001b[35m1.2160\u001b[0m  1.9552\n",
            "      2      \u001b[36m0.9220\u001b[0m      \u001b[32m0.9207\u001b[0m        \u001b[35m0.2472\u001b[0m  1.9672\n",
            "      3      \u001b[36m0.9879\u001b[0m      \u001b[32m0.9879\u001b[0m        \u001b[35m0.0376\u001b[0m  1.9500\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0058\u001b[0m  1.9797\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  2.0320\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9891\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9747\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9726\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9626\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9829\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5072\u001b[0m      \u001b[32m0.4455\u001b[0m        \u001b[35m1.2056\u001b[0m  1.9701\n",
            "      2      \u001b[36m0.9327\u001b[0m      \u001b[32m0.9317\u001b[0m        \u001b[35m0.2168\u001b[0m  1.9936\n",
            "      3      \u001b[36m0.9890\u001b[0m      \u001b[32m0.9890\u001b[0m        \u001b[35m0.0354\u001b[0m  1.9934\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0064\u001b[0m  1.9762\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.9796\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9770\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9790\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9678\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.0145\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9845\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4820\u001b[0m      \u001b[32m0.4125\u001b[0m        \u001b[35m1.2291\u001b[0m  0.7925\n",
            "      2      \u001b[36m0.8606\u001b[0m      \u001b[32m0.8427\u001b[0m        \u001b[35m0.4095\u001b[0m  0.7548\n",
            "      3      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0272\u001b[0m  0.7871\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0037\u001b[0m  0.8000\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0016\u001b[0m  0.7643\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7918\n",
            "      7      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7946\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7351\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7246\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7415\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7171\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7414\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7315\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7354\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7166\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7356\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7209\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7185\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7061\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7396\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4875\u001b[0m      \u001b[32m0.4186\u001b[0m        \u001b[35m1.2274\u001b[0m  0.7212\n",
            "      2      \u001b[36m0.8771\u001b[0m      \u001b[32m0.8672\u001b[0m        \u001b[35m0.3713\u001b[0m  0.7189\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0178\u001b[0m  0.7189\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0029\u001b[0m  0.7389\n",
            "      5      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.7165\n",
            "      6      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7219\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7369\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7206\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7231\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7093\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7174\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7225\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7111\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7211\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7183\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7134\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7305\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7163\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7076\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7290\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4974\u001b[0m      \u001b[32m0.4148\u001b[0m        \u001b[35m1.2195\u001b[0m  0.7244\n",
            "      2      \u001b[36m0.8790\u001b[0m      \u001b[32m0.8664\u001b[0m        \u001b[35m0.3819\u001b[0m  0.7143\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0191\u001b[0m  0.7201\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0026\u001b[0m  0.7194\n",
            "      5      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.7117\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7064\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7164\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7125\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7175\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7229\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7110\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7180\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7222\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7109\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7154\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7085\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7104\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7206\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7211\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7185\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5013\u001b[0m      \u001b[32m0.4319\u001b[0m        \u001b[35m1.2224\u001b[0m  0.7262\n",
            "      2      \u001b[36m0.8672\u001b[0m      \u001b[32m0.8541\u001b[0m        \u001b[35m0.3898\u001b[0m  0.7168\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0175\u001b[0m  0.7383\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0029\u001b[0m  0.7149\n",
            "      5      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.7286\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.7176\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7211\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7054\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7114\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7143\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7159\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7120\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7275\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7128\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7321\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7276\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7305\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7299\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7245\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7184\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4950\u001b[0m      \u001b[32m0.4217\u001b[0m        \u001b[35m1.2180\u001b[0m  0.7071\n",
            "      2      \u001b[36m0.8812\u001b[0m      \u001b[32m0.8699\u001b[0m        \u001b[35m0.3650\u001b[0m  0.7252\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0153\u001b[0m  0.7259\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0024\u001b[0m  0.7292\n",
            "      5      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.7161\n",
            "      6      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7219\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7064\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7349\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7242\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7303\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7308\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7240\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7182\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7205\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7057\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7219\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7101\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7257\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7266\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7402\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4948\u001b[0m      \u001b[32m0.4313\u001b[0m        \u001b[35m1.2148\u001b[0m  0.9141\n",
            "      2      \u001b[36m0.9025\u001b[0m      \u001b[32m0.8955\u001b[0m        \u001b[35m0.2848\u001b[0m  0.9384\n",
            "      3      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9960\u001b[0m        \u001b[35m0.0167\u001b[0m  0.9210\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0016\u001b[0m  0.9254\n",
            "      5      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9272\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9746\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.0204\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9623\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9226\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9414\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0176\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9453\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9061\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9262\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0093\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9422\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0051\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9950\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9784\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0116\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4956\u001b[0m      \u001b[32m0.4342\u001b[0m        \u001b[35m1.2157\u001b[0m  0.9167\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      2      \u001b[36m0.9021\u001b[0m      \u001b[32m0.8952\u001b[0m        \u001b[35m0.2859\u001b[0m  0.9888\n",
            "      3      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0113\u001b[0m  0.9625\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0019\u001b[0m  1.0270\n",
            "      5      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.0115\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.9961\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9435\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9300\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9326\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9375\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9066\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9228\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0198\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9761\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9314\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9326\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9357\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9331\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9181\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  0.9343\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5033\u001b[0m      \u001b[32m0.4295\u001b[0m        \u001b[35m1.2174\u001b[0m  0.9270\n",
            "      2      \u001b[36m0.9084\u001b[0m      \u001b[32m0.9017\u001b[0m        \u001b[35m0.2757\u001b[0m  0.9226\n",
            "      3      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0124\u001b[0m  0.9351\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0014\u001b[0m  0.9362\n",
            "      5      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9111\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9109\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9312\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9181\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9222\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9138\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9293\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9179\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9244\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9690\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0093\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9583\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9950\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0051\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9869\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9296\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4972\u001b[0m      \u001b[32m0.4306\u001b[0m        \u001b[35m1.2175\u001b[0m  0.9179\n",
            "      2      \u001b[36m0.8915\u001b[0m      \u001b[32m0.8844\u001b[0m        \u001b[35m0.3142\u001b[0m  0.9230\n",
            "      3      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0114\u001b[0m  0.9358\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0022\u001b[0m  0.9178\n",
            "      5      0.9996      0.9996        \u001b[35m0.0011\u001b[0m  0.9289\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  0.9185\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9253\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9090\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9251\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9363\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9112\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9160\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9233\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9191\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9208\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9195\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9346\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9346\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9282\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9298\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4939\u001b[0m      \u001b[32m0.4238\u001b[0m        \u001b[35m1.2176\u001b[0m  0.9178\n",
            "      2      \u001b[36m0.9000\u001b[0m      \u001b[32m0.8937\u001b[0m        \u001b[35m0.2856\u001b[0m  0.9221\n",
            "      3      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0105\u001b[0m  0.9319\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0014\u001b[0m  0.9283\n",
            "      5      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9691\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9217\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9415\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9277\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9352\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9277\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0305\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9946\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9563\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0161\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9992\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9282\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9298\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9364\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9303\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9386\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4974\u001b[0m      \u001b[32m0.4406\u001b[0m        \u001b[35m1.2112\u001b[0m  1.3171\n",
            "      2      \u001b[36m0.9275\u001b[0m      \u001b[32m0.9254\u001b[0m        \u001b[35m0.2159\u001b[0m  1.2980\n",
            "      3      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0162\u001b[0m  1.4018\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0013\u001b[0m  1.3305\n",
            "      5      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3380\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3298\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3171\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3181\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3232\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.4050\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3229\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3141\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3159\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3197\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3240\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3262\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3119\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3075\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3850\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3733\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4989\u001b[0m      \u001b[32m0.4390\u001b[0m        \u001b[35m1.2153\u001b[0m  1.3112\n",
            "      2      \u001b[36m0.9235\u001b[0m      \u001b[32m0.9206\u001b[0m        \u001b[35m0.2164\u001b[0m  1.2866\n",
            "      3      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0184\u001b[0m  1.3056\n",
            "      4      0.9923      0.9923        0.0216  1.3011\n",
            "      5      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0177\u001b[0m  1.3049\n",
            "      6      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0031\u001b[0m  1.3308\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  1.3095\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3148\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3336\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3297\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3011\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2926\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2911\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3035\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3035\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3152\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3054\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3086\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3039\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3014\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5044\u001b[0m      \u001b[32m0.4423\u001b[0m        \u001b[35m1.2162\u001b[0m  1.3049\n",
            "      2      \u001b[36m0.9220\u001b[0m      \u001b[32m0.9181\u001b[0m        \u001b[35m0.2253\u001b[0m  1.3006\n",
            "      3      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0151\u001b[0m  1.2889\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0025\u001b[0m  1.3013\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.2923\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3094\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3049\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2843\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3018\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3073\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3028\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2815\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2948\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3025\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3089\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3016\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.2947\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3145\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.2899\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3039\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5050\u001b[0m      \u001b[32m0.4392\u001b[0m        \u001b[35m1.2197\u001b[0m  1.2760\n",
            "      2      \u001b[36m0.9125\u001b[0m      \u001b[32m0.9090\u001b[0m        \u001b[35m0.2531\u001b[0m  1.2961\n",
            "      3      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0115\u001b[0m  1.2925\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0015\u001b[0m  1.3044\n",
            "      5      0.9996      0.9996        0.0035  1.2871\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3185\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3068\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3006\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2869\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3037\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3057\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2976\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2855\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2932\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3018\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.2998\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3098\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3113\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.2927\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.2799\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5079\u001b[0m      \u001b[32m0.4357\u001b[0m        \u001b[35m1.2118\u001b[0m  1.3048\n",
            "      2      \u001b[36m0.9165\u001b[0m      \u001b[32m0.9128\u001b[0m        \u001b[35m0.2430\u001b[0m  1.2966\n",
            "      3      \u001b[36m0.9934\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0193\u001b[0m  1.2864\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0037\u001b[0m  1.2902\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.2853\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2988\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2911\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3018\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3016\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3065\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2888\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3018\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3036\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3073\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3136\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.2945\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3159\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.2889\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3006\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.3145\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4993\u001b[0m      \u001b[32m0.4470\u001b[0m        \u001b[35m1.2144\u001b[0m  1.9653\n",
            "      2      \u001b[36m0.9330\u001b[0m      \u001b[32m0.9313\u001b[0m        \u001b[35m0.1983\u001b[0m  1.9730\n",
            "      3      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0136\u001b[0m  1.9779\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0028\u001b[0m  1.9441\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0002\u001b[0m  1.9452\n",
            "      6      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9473\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9677\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9580\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9517\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9531\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9576\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9570\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9574\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9622\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9557\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9567\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9542\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9520\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9497\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9640\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5033\u001b[0m      \u001b[32m0.4432\u001b[0m        \u001b[35m1.2042\u001b[0m  2.0257\n",
            "      2      \u001b[36m0.9467\u001b[0m      \u001b[32m0.9458\u001b[0m        \u001b[35m0.1885\u001b[0m  1.9702\n",
            "      3      \u001b[36m0.9948\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0228\u001b[0m  1.9538\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0105\u001b[0m  1.9608\n",
            "      5      0.9963      \u001b[32m0.9963\u001b[0m        0.0107  1.9691\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0020\u001b[0m  1.9637\n",
            "      7      0.9996      0.9996        \u001b[35m0.0007\u001b[0m  1.9602\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.9872\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9876\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9706\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9984\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9632\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9608\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9812\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9538\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.0114\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9553\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9596\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9533\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9619\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5037\u001b[0m      \u001b[32m0.4382\u001b[0m        \u001b[35m1.2000\u001b[0m  1.9590\n",
            "      2      \u001b[36m0.9452\u001b[0m      \u001b[32m0.9442\u001b[0m        \u001b[35m0.1828\u001b[0m  1.9598\n",
            "      3      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0164\u001b[0m  1.9855\n",
            "      4      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0071\u001b[0m  1.9554\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0018\u001b[0m  1.9687\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0001\u001b[0m  1.9475\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9616\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9722\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9638\n",
            "     10      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9686\n",
            "     11      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9649\n",
            "     12      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9616\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9623\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.0297\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9598\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9772\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9991\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.0043\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.0167\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9553\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5116\u001b[0m      \u001b[32m0.4531\u001b[0m        \u001b[35m1.2156\u001b[0m  2.0072\n",
            "      2      \u001b[36m0.9172\u001b[0m      \u001b[32m0.9157\u001b[0m        \u001b[35m0.2506\u001b[0m  1.9543\n",
            "      3      \u001b[36m0.9864\u001b[0m      \u001b[32m0.9864\u001b[0m        \u001b[35m0.0396\u001b[0m  1.9555\n",
            "      4      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0066\u001b[0m  1.9570\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.9751\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9860\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9738\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9505\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9538\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9712\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.0257\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.0042\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9613\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9602\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9454\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9711\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9683\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9605\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9710\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9559\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5068\u001b[0m      \u001b[32m0.4486\u001b[0m        \u001b[35m1.2059\u001b[0m  2.0320\n",
            "      2      \u001b[36m0.9275\u001b[0m      \u001b[32m0.9263\u001b[0m        \u001b[35m0.2244\u001b[0m  1.9774\n",
            "      3      \u001b[36m0.9860\u001b[0m      \u001b[32m0.9860\u001b[0m        \u001b[35m0.0467\u001b[0m  1.9633\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0058\u001b[0m  1.9836\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.9880\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9762\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9652\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9668\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9839\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9500\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9674\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9630\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9539\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9565\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9680\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9615\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9662\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9646\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9951\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9760\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4831\u001b[0m      \u001b[32m0.4042\u001b[0m        \u001b[35m1.2237\u001b[0m  0.7158\n",
            "      2      \u001b[36m0.8469\u001b[0m      \u001b[32m0.8399\u001b[0m        \u001b[35m0.4326\u001b[0m  0.7390\n",
            "      3      \u001b[36m0.9706\u001b[0m      \u001b[32m0.9704\u001b[0m        \u001b[35m0.0952\u001b[0m  0.7277\n",
            "      4      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0150\u001b[0m  0.7257\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0015\u001b[0m  0.7067\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7088\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7235\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7106\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7072\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7171\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4753\u001b[0m      \u001b[32m0.4259\u001b[0m        \u001b[35m1.2343\u001b[0m  0.7140\n",
            "      2      \u001b[36m0.8425\u001b[0m      \u001b[32m0.8323\u001b[0m        \u001b[35m0.4736\u001b[0m  0.7429\n",
            "      3      \u001b[36m0.9577\u001b[0m      \u001b[32m0.9570\u001b[0m        \u001b[35m0.1235\u001b[0m  0.7256\n",
            "      4      \u001b[36m0.9930\u001b[0m      \u001b[32m0.9930\u001b[0m        \u001b[35m0.0224\u001b[0m  0.7117\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0037\u001b[0m  0.7150\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  0.7081\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7178\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7167\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7199\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7300\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4731\u001b[0m      \u001b[32m0.4089\u001b[0m        \u001b[35m1.2519\u001b[0m  0.7104\n",
            "      2      \u001b[36m0.7667\u001b[0m      \u001b[32m0.7567\u001b[0m        \u001b[35m0.6160\u001b[0m  0.7202\n",
            "      3      \u001b[36m0.9669\u001b[0m      \u001b[32m0.9667\u001b[0m        \u001b[35m0.1130\u001b[0m  0.7158\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0207\u001b[0m  0.7111\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0040\u001b[0m  0.7301\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0013\u001b[0m  0.7110\n",
            "      7      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7237\n",
            "      8      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7130\n",
            "      9      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7098\n",
            "     10      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7221\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4921\u001b[0m      \u001b[32m0.4331\u001b[0m        \u001b[35m1.2267\u001b[0m  0.7168\n",
            "      2      \u001b[36m0.8533\u001b[0m      \u001b[32m0.8446\u001b[0m        \u001b[35m0.4339\u001b[0m  0.7102\n",
            "      3      \u001b[36m0.9776\u001b[0m      \u001b[32m0.9774\u001b[0m        \u001b[35m0.0828\u001b[0m  0.7231\n",
            "      4      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0149\u001b[0m  0.7100\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0020\u001b[0m  0.7052\n",
            "      6      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.7219\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7046\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7190\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7256\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7088\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4627\u001b[0m      \u001b[32m0.3845\u001b[0m        \u001b[35m1.2533\u001b[0m  0.6982\n",
            "      2      \u001b[36m0.7804\u001b[0m      \u001b[32m0.7657\u001b[0m        \u001b[35m0.5846\u001b[0m  0.7182\n",
            "      3      \u001b[36m0.9640\u001b[0m      \u001b[32m0.9638\u001b[0m        \u001b[35m0.1175\u001b[0m  0.7135\n",
            "      4      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0230\u001b[0m  0.7206\n",
            "      5      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0065\u001b[0m  0.7128\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0024\u001b[0m  0.7140\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  0.7037\n",
            "      8      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7107\n",
            "      9      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7193\n",
            "     10      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7043\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4882\u001b[0m      \u001b[32m0.4296\u001b[0m        \u001b[35m1.2506\u001b[0m  0.9187\n",
            "      2      \u001b[36m0.8381\u001b[0m      \u001b[32m0.8252\u001b[0m        \u001b[35m0.4916\u001b[0m  0.9281\n",
            "      3      \u001b[36m0.9757\u001b[0m      \u001b[32m0.9754\u001b[0m        \u001b[35m0.0772\u001b[0m  0.9345\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      4      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0163\u001b[0m  0.9263\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0017\u001b[0m  0.9254\n",
            "      6      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9094\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9171\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9227\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9248\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9107\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4937\u001b[0m      \u001b[32m0.4381\u001b[0m        \u001b[35m1.2621\u001b[0m  0.9292\n",
            "      2      \u001b[36m0.8466\u001b[0m      \u001b[32m0.8391\u001b[0m        \u001b[35m0.4371\u001b[0m  0.9334\n",
            "      3      \u001b[36m0.9860\u001b[0m      \u001b[32m0.9860\u001b[0m        \u001b[35m0.0484\u001b[0m  0.9316\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0042\u001b[0m  0.9312\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  0.9192\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9736\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0256\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9534\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9290\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9435\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4665\u001b[0m      \u001b[32m0.3939\u001b[0m        \u001b[35m1.2677\u001b[0m  0.9148\n",
            "      2      \u001b[36m0.8344\u001b[0m      \u001b[32m0.8269\u001b[0m        \u001b[35m0.4784\u001b[0m  0.9283\n",
            "      3      \u001b[36m0.9776\u001b[0m      \u001b[32m0.9775\u001b[0m        \u001b[35m0.0730\u001b[0m  0.9456\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0094\u001b[0m  0.9337\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0026\u001b[0m  0.9302\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.9251\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9202\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9093\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9248\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9241\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4858\u001b[0m      \u001b[32m0.4315\u001b[0m        \u001b[35m1.2816\u001b[0m  0.9196\n",
            "      2      \u001b[36m0.8316\u001b[0m      \u001b[32m0.8194\u001b[0m        \u001b[35m0.5117\u001b[0m  0.9325\n",
            "      3      \u001b[36m0.9761\u001b[0m      \u001b[32m0.9759\u001b[0m        \u001b[35m0.0778\u001b[0m  0.9332\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0072\u001b[0m  0.9191\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0010\u001b[0m  0.9399\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.9345\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9321\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9313\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9251\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9317\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4737\u001b[0m      \u001b[32m0.4138\u001b[0m        \u001b[35m1.2714\u001b[0m  0.9265\n",
            "      2      \u001b[36m0.8202\u001b[0m      \u001b[32m0.8081\u001b[0m        \u001b[35m0.5076\u001b[0m  0.9415\n",
            "      3      \u001b[36m0.9750\u001b[0m      \u001b[32m0.9749\u001b[0m        \u001b[35m0.0729\u001b[0m  0.9289\n",
            "      4      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0196\u001b[0m  0.9254\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0021\u001b[0m  0.9169\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  0.9108\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9157\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9148\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9315\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9233\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4849\u001b[0m      \u001b[32m0.4260\u001b[0m        \u001b[35m1.3773\u001b[0m  1.3146\n",
            "      2      \u001b[36m0.8289\u001b[0m      \u001b[32m0.8183\u001b[0m        \u001b[35m0.4859\u001b[0m  1.3145\n",
            "      3      \u001b[36m0.9831\u001b[0m      \u001b[32m0.9830\u001b[0m        \u001b[35m0.0592\u001b[0m  1.3130\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0072\u001b[0m  1.3181\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0011\u001b[0m  1.3077\n",
            "      6      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  1.3369\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3957\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3505\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3148\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.2965\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4327\u001b[0m      \u001b[32m0.3777\u001b[0m        \u001b[35m1.4995\u001b[0m  1.4016\n",
            "      2      \u001b[36m0.7119\u001b[0m      \u001b[32m0.6997\u001b[0m        \u001b[35m0.7738\u001b[0m  1.3419\n",
            "      3      \u001b[36m0.9415\u001b[0m      \u001b[32m0.9411\u001b[0m        \u001b[35m0.1723\u001b[0m  1.3106\n",
            "      4      \u001b[36m0.9923\u001b[0m      \u001b[32m0.9923\u001b[0m        \u001b[35m0.0265\u001b[0m  1.3232\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0033\u001b[0m  1.3361\n",
            "      6      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.3010\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3079\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3225\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3186\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3179\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4658\u001b[0m      \u001b[32m0.4008\u001b[0m        \u001b[35m1.3773\u001b[0m  1.3455\n",
            "      2      \u001b[36m0.8006\u001b[0m      \u001b[32m0.7897\u001b[0m        \u001b[35m0.5796\u001b[0m  1.3935\n",
            "      3      \u001b[36m0.9625\u001b[0m      \u001b[32m0.9623\u001b[0m        \u001b[35m0.1118\u001b[0m  1.3168\n",
            "      4      \u001b[36m0.9919\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0299\u001b[0m  1.3174\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0015\u001b[0m  1.3347\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3231\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3218\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.4094\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.4053\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3667\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4531\u001b[0m      \u001b[32m0.3918\u001b[0m        \u001b[35m1.4150\u001b[0m  1.3791\n",
            "      2      \u001b[36m0.7753\u001b[0m      \u001b[32m0.7628\u001b[0m        \u001b[35m0.6490\u001b[0m  1.3312\n",
            "      3      \u001b[36m0.9603\u001b[0m      \u001b[32m0.9598\u001b[0m        \u001b[35m0.1132\u001b[0m  1.3219\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0136\u001b[0m  1.3193\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0019\u001b[0m  1.3923\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.3510\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3102\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3530\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3804\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.4079\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4564\u001b[0m      \u001b[32m0.3983\u001b[0m        \u001b[35m1.4317\u001b[0m  1.3478\n",
            "      2      \u001b[36m0.7962\u001b[0m      \u001b[32m0.7788\u001b[0m        \u001b[35m0.5697\u001b[0m  1.3908\n",
            "      3      \u001b[36m0.9651\u001b[0m      \u001b[32m0.9649\u001b[0m        \u001b[35m0.0999\u001b[0m  1.3264\n",
            "      4      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0110\u001b[0m  1.3022\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  1.3122\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3094\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3176\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3126\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3289\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3655\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4842\u001b[0m      \u001b[32m0.4268\u001b[0m        \u001b[35m1.7046\u001b[0m  1.9726\n",
            "      2      \u001b[36m0.8389\u001b[0m      \u001b[32m0.8227\u001b[0m        \u001b[35m0.5461\u001b[0m  1.9555\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      3      \u001b[36m0.9702\u001b[0m      \u001b[32m0.9698\u001b[0m        \u001b[35m0.0853\u001b[0m  1.9645\n",
            "      4      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0121\u001b[0m  1.9549\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0021\u001b[0m  1.9717\n",
            "      6      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  1.9580\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.9720\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.9754\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9456\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9583\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4415\u001b[0m      \u001b[32m0.3935\u001b[0m        \u001b[35m1.7901\u001b[0m  1.9731\n",
            "      2      \u001b[36m0.7774\u001b[0m      \u001b[32m0.7624\u001b[0m        \u001b[35m0.6406\u001b[0m  1.9659\n",
            "      3      \u001b[36m0.9750\u001b[0m      \u001b[32m0.9749\u001b[0m        \u001b[35m0.0822\u001b[0m  1.9646\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0119\u001b[0m  1.9997\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0043\u001b[0m  1.9787\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0010\u001b[0m  1.9559\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.9716\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9578\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9785\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9661\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4529\u001b[0m      \u001b[32m0.3917\u001b[0m        \u001b[35m1.7109\u001b[0m  1.9893\n",
            "      2      \u001b[36m0.7734\u001b[0m      \u001b[32m0.7525\u001b[0m        \u001b[35m0.6429\u001b[0m  1.9743\n",
            "      3      \u001b[36m0.9581\u001b[0m      \u001b[32m0.9575\u001b[0m        \u001b[35m0.1146\u001b[0m  2.0053\n",
            "      4      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0187\u001b[0m  1.9760\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0031\u001b[0m  1.9740\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  1.9588\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.9641\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.9756\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9696\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9724\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4454\u001b[0m      \u001b[32m0.4014\u001b[0m        \u001b[35m1.7222\u001b[0m  1.9543\n",
            "      2      \u001b[36m0.7444\u001b[0m      \u001b[32m0.7291\u001b[0m        \u001b[35m0.7645\u001b[0m  2.0392\n",
            "      3      \u001b[36m0.9555\u001b[0m      \u001b[32m0.9550\u001b[0m        \u001b[35m0.1402\u001b[0m  1.9721\n",
            "      4      \u001b[36m0.9945\u001b[0m      \u001b[32m0.9945\u001b[0m        \u001b[35m0.0160\u001b[0m  1.9841\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0020\u001b[0m  1.9918\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.9652\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.9677\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.9614\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9725\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.0282\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4594\u001b[0m      \u001b[32m0.3998\u001b[0m        \u001b[35m1.7793\u001b[0m  1.9732\n",
            "      2      \u001b[36m0.7771\u001b[0m      \u001b[32m0.7607\u001b[0m        \u001b[35m0.6248\u001b[0m  2.0311\n",
            "      3      \u001b[36m0.9640\u001b[0m      \u001b[32m0.9637\u001b[0m        \u001b[35m0.1090\u001b[0m  2.0396\n",
            "      4      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9960\u001b[0m        \u001b[35m0.0143\u001b[0m  2.0254\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0027\u001b[0m  1.9785\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  1.9743\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.9582\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  2.0002\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9803\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9930\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5052\u001b[0m      \u001b[32m0.4293\u001b[0m        \u001b[35m1.2169\u001b[0m  0.7116\n",
            "      2      \u001b[36m0.8536\u001b[0m      \u001b[32m0.8455\u001b[0m        \u001b[35m0.4198\u001b[0m  0.7259\n",
            "      3      \u001b[36m0.9827\u001b[0m      \u001b[32m0.9827\u001b[0m        \u001b[35m0.0577\u001b[0m  0.7444\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0061\u001b[0m  0.7339\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0012\u001b[0m  0.7164\n",
            "      6      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7341\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7428\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.8074\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7875\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7275\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7137\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7447\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7190\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7276\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7304\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7913\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.8062\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7480\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7316\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7208\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4768\u001b[0m      \u001b[32m0.4234\u001b[0m        \u001b[35m1.2420\u001b[0m  0.7203\n",
            "      2      \u001b[36m0.8606\u001b[0m      \u001b[32m0.8532\u001b[0m        \u001b[35m0.4068\u001b[0m  0.7165\n",
            "      3      \u001b[36m0.9845\u001b[0m      \u001b[32m0.9845\u001b[0m        \u001b[35m0.0545\u001b[0m  0.7420\n",
            "      4      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9959\u001b[0m        \u001b[35m0.0143\u001b[0m  0.7169\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0016\u001b[0m  0.7226\n",
            "      6      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.7140\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7147\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7123\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7174\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7208\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7315\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7132\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7085\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7319\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7114\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7217\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7117\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7260\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7179\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7166\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4805\u001b[0m      \u001b[32m0.4132\u001b[0m        \u001b[35m1.2094\u001b[0m  0.6989\n",
            "      2      \u001b[36m0.8815\u001b[0m      \u001b[32m0.8766\u001b[0m        \u001b[35m0.3500\u001b[0m  0.7304\n",
            "      3      \u001b[36m0.9857\u001b[0m      \u001b[32m0.9857\u001b[0m        \u001b[35m0.0427\u001b[0m  0.7128\n",
            "      4      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0062\u001b[0m  0.7136\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0009\u001b[0m  0.7184\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7129\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.6991\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7585\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.8149\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7807\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7303\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7194\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7274\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7225\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7326\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7177\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7273\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7149\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7405\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7620\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4873\u001b[0m      \u001b[32m0.4344\u001b[0m        \u001b[35m1.2336\u001b[0m  0.7255\n",
            "      2      \u001b[36m0.8396\u001b[0m      \u001b[32m0.8270\u001b[0m        \u001b[35m0.4732\u001b[0m  0.7263\n",
            "      3      \u001b[36m0.9757\u001b[0m      \u001b[32m0.9755\u001b[0m        \u001b[35m0.0806\u001b[0m  0.7263\n",
            "      4      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0121\u001b[0m  0.7128\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0023\u001b[0m  0.7126\n",
            "      6      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7233\n",
            "      7      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7147\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7221\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7214\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7449\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7106\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7167\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7120\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7025\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7255\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7211\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7221\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7167\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7344\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.8059\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4847\u001b[0m      \u001b[32m0.4269\u001b[0m        \u001b[35m1.2246\u001b[0m  0.7815\n",
            "      2      \u001b[36m0.8573\u001b[0m      \u001b[32m0.8488\u001b[0m        \u001b[35m0.4314\u001b[0m  0.7302\n",
            "      3      \u001b[36m0.9750\u001b[0m      \u001b[32m0.9747\u001b[0m        \u001b[35m0.0780\u001b[0m  0.7271\n",
            "      4      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0149\u001b[0m  0.7246\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0018\u001b[0m  0.7377\n",
            "      6      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.7212\n",
            "      7      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.7265\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.7242\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.7331\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7140\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7226\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.7084\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7136\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7167\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7437\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7196\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.7466\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7284\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7234\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.7152\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4930\u001b[0m      \u001b[32m0.4301\u001b[0m        \u001b[35m1.2515\u001b[0m  0.9187\n",
            "      2      \u001b[36m0.8348\u001b[0m      \u001b[32m0.8274\u001b[0m        \u001b[35m0.4715\u001b[0m  0.9177\n",
            "      3      \u001b[36m0.9765\u001b[0m      \u001b[32m0.9764\u001b[0m        \u001b[35m0.0643\u001b[0m  0.9029\n",
            "      4      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0046\u001b[0m  0.9124\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  0.9175\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9221\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9349\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9277\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9226\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9210\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9278\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9343\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9879\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0064\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9361\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9379\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9417\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9328\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9254\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9360\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4684\u001b[0m      \u001b[32m0.4082\u001b[0m        \u001b[35m1.3210\u001b[0m  0.9267\n",
            "      2      \u001b[36m0.7557\u001b[0m      \u001b[32m0.7350\u001b[0m        \u001b[35m0.6597\u001b[0m  0.9230\n",
            "      3      \u001b[36m0.9625\u001b[0m      \u001b[32m0.9623\u001b[0m        \u001b[35m0.1260\u001b[0m  0.9217\n",
            "      4      \u001b[36m0.9908\u001b[0m      \u001b[32m0.9908\u001b[0m        \u001b[35m0.0277\u001b[0m  0.9227\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0048\u001b[0m  0.9266\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0016\u001b[0m  0.9634\n",
            "      7      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  1.0160\n",
            "      8      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.9523\n",
            "      9      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9247\n",
            "     10      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.9227\n",
            "     11      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9270\n",
            "     12      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9245\n",
            "     13      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9309\n",
            "     14      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9392\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9374\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9212\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9283\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9132\n",
            "     19      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9069\n",
            "     20      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9115\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4717\u001b[0m      \u001b[32m0.4046\u001b[0m        \u001b[35m1.2923\u001b[0m  0.9261\n",
            "      2      \u001b[36m0.7848\u001b[0m      \u001b[32m0.7714\u001b[0m        \u001b[35m0.5673\u001b[0m  0.9137\n",
            "      3      \u001b[36m0.9783\u001b[0m      \u001b[32m0.9782\u001b[0m        \u001b[35m0.0736\u001b[0m  0.9173\n",
            "      4      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0098\u001b[0m  0.9340\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0013\u001b[0m  0.9331\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.9335\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9301\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9289\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9253\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9181\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9167\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9167\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9118\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9234\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9116\n",
            "     16      1.0000      1.0000        0.0001  0.9156\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9229\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9176\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9203\n",
            "     20      1.0000      1.0000        0.0001  0.9218\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4755\u001b[0m      \u001b[32m0.4165\u001b[0m        \u001b[35m1.2817\u001b[0m  0.9142\n",
            "      2      \u001b[36m0.8334\u001b[0m      \u001b[32m0.8235\u001b[0m        \u001b[35m0.4684\u001b[0m  0.9225\n",
            "      3      \u001b[36m0.9794\u001b[0m      \u001b[32m0.9792\u001b[0m        \u001b[35m0.0738\u001b[0m  0.9330\n",
            "      4      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9941\u001b[0m        \u001b[35m0.0182\u001b[0m  0.9205\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0041\u001b[0m  0.9225\n",
            "      6      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0015\u001b[0m  0.9106\n",
            "      7      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0006\u001b[0m  0.9095\n",
            "      8      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  0.9156\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9203\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9215\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9359\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0165\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9227\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9222\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9066\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9057\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9077\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9057\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9075\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9172\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4777\u001b[0m      \u001b[32m0.4202\u001b[0m        \u001b[35m1.2743\u001b[0m  0.9122\n",
            "      2      \u001b[36m0.8135\u001b[0m      \u001b[32m0.8016\u001b[0m        \u001b[35m0.5075\u001b[0m  0.9105\n",
            "      3      \u001b[36m0.9720\u001b[0m      \u001b[32m0.9720\u001b[0m        \u001b[35m0.0812\u001b[0m  0.9120\n",
            "      4      \u001b[36m0.9967\u001b[0m      \u001b[32m0.9967\u001b[0m        \u001b[35m0.0123\u001b[0m  0.9189\n",
            "      5      \u001b[36m0.9993\u001b[0m      \u001b[32m0.9993\u001b[0m        \u001b[35m0.0021\u001b[0m  0.9742\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0008\u001b[0m  0.9994\n",
            "      7      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.9291\n",
            "      8      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  0.9911\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9600\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.0306\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9991\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  0.9345\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9520\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.0149\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9734\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9252\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9278\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9099\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9129\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  0.9179\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4860\u001b[0m      \u001b[32m0.4252\u001b[0m        \u001b[35m1.4301\u001b[0m  1.3541\n",
            "      2      \u001b[36m0.8168\u001b[0m      \u001b[32m0.8040\u001b[0m        \u001b[35m0.5426\u001b[0m  1.3685\n",
            "      3      \u001b[36m0.9753\u001b[0m      \u001b[32m0.9752\u001b[0m        \u001b[35m0.0796\u001b[0m  1.3137\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0133\u001b[0m  1.3208\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.3405\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3036\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2973\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2934\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2950\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2974\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2885\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3049\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3012\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3184\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2976\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2903\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3301\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3302\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3767\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3775\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4650\u001b[0m      \u001b[32m0.4070\u001b[0m        \u001b[35m1.3879\u001b[0m  1.3049\n",
            "      2      \u001b[36m0.8212\u001b[0m      \u001b[32m0.8114\u001b[0m        \u001b[35m0.5305\u001b[0m  1.3170\n",
            "      3      \u001b[36m0.9753\u001b[0m      \u001b[32m0.9752\u001b[0m        \u001b[35m0.0834\u001b[0m  1.3140\n",
            "      4      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0122\u001b[0m  1.3503\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0031\u001b[0m  1.3933\n",
            "      6      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  1.3200\n",
            "      7      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  1.3049\n",
            "      8      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3120\n",
            "      9      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3040\n",
            "     10      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3991\n",
            "     11      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.3507\n",
            "     12      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3208\n",
            "     13      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3251\n",
            "     14      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2958\n",
            "     15      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3148\n",
            "     16      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3259\n",
            "     17      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3930\n",
            "     18      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3495\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3233\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3268\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4492\u001b[0m      \u001b[32m0.3919\u001b[0m        \u001b[35m1.4473\u001b[0m  0.7814\n",
            "      2      \u001b[36m0.7951\u001b[0m      \u001b[32m0.7822\u001b[0m        \u001b[35m0.5625\u001b[0m  1.3168\n",
            "      3      \u001b[36m0.9761\u001b[0m      \u001b[32m0.9760\u001b[0m        \u001b[35m0.0776\u001b[0m  1.3153\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0109\u001b[0m  1.3144\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0014\u001b[0m  1.3201\n",
            "      6      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  1.3222\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3120\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3882\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3340\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3363\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2993\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3084\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3005\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3113\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2938\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3105\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3063\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2980\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3034\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3017\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4542\u001b[0m      \u001b[32m0.4046\u001b[0m        \u001b[35m1.4532\u001b[0m  1.3224\n",
            "      2      \u001b[36m0.7889\u001b[0m      \u001b[32m0.7747\u001b[0m        \u001b[35m0.5889\u001b[0m  1.3174\n",
            "      3      \u001b[36m0.9618\u001b[0m      \u001b[32m0.9616\u001b[0m        \u001b[35m0.1061\u001b[0m  1.2954\n",
            "      4      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0185\u001b[0m  1.3275\n",
            "      5      \u001b[36m0.9989\u001b[0m      \u001b[32m0.9989\u001b[0m        \u001b[35m0.0108\u001b[0m  1.3156\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0005\u001b[0m  1.3106\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.2892\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3066\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.2969\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3064\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3743\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3950\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3247\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3297\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3187\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3188\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.4210\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3634\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3344\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3229\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4568\u001b[0m      \u001b[32m0.4018\u001b[0m        \u001b[35m1.4238\u001b[0m  1.3244\n",
            "      2      \u001b[36m0.8257\u001b[0m      \u001b[32m0.8138\u001b[0m        \u001b[35m0.4879\u001b[0m  1.3831\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      3      \u001b[36m0.9783\u001b[0m      \u001b[32m0.9783\u001b[0m        \u001b[35m0.0755\u001b[0m  1.3214\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0145\u001b[0m  1.3162\n",
            "      5      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        0.0215  1.3097\n",
            "      6      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0007\u001b[0m  1.2875\n",
            "      7      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.3145\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3138\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.3134\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3035\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3019\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3150\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3042\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2994\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3121\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2984\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3063\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3005\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.3057\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.2888\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4695\u001b[0m      \u001b[32m0.4016\u001b[0m        \u001b[35m1.7222\u001b[0m  1.9466\n",
            "      2      \u001b[36m0.8043\u001b[0m      \u001b[32m0.7864\u001b[0m        \u001b[35m0.6320\u001b[0m  1.9731\n",
            "      3      \u001b[36m0.9603\u001b[0m      \u001b[32m0.9596\u001b[0m        \u001b[35m0.1112\u001b[0m  1.9661\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0158\u001b[0m  1.9457\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0014\u001b[0m  1.9550\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0003\u001b[0m  1.9505\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9630\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9410\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9730\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9580\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9503\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9650\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9605\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9614\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9636\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9560\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9614\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9881\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.0172\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9907\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4448\u001b[0m      \u001b[32m0.4006\u001b[0m        \u001b[35m1.7442\u001b[0m  1.9886\n",
            "      2      \u001b[36m0.7178\u001b[0m      \u001b[32m0.6975\u001b[0m        \u001b[35m0.7437\u001b[0m  1.9764\n",
            "      3      \u001b[36m0.9529\u001b[0m      \u001b[32m0.9524\u001b[0m        \u001b[35m0.1383\u001b[0m  1.9974\n",
            "      4      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0189\u001b[0m  1.9545\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0016\u001b[0m  1.9588\n",
            "      6      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  2.0276\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.9956\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9764\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9570\n",
            "     10      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9580\n",
            "     11      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9677\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9766\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9689\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9517\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9731\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9636\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9738\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9855\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9634\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9586\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4566\u001b[0m      \u001b[32m0.4019\u001b[0m        \u001b[35m1.6674\u001b[0m  1.9708\n",
            "      2      \u001b[36m0.7965\u001b[0m      \u001b[32m0.7856\u001b[0m        \u001b[35m0.6163\u001b[0m  1.9758\n",
            "      3      \u001b[36m0.9673\u001b[0m      \u001b[32m0.9671\u001b[0m        \u001b[35m0.0973\u001b[0m  1.9463\n",
            "      4      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0087\u001b[0m  1.9540\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0006\u001b[0m  1.9543\n",
            "      6      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9584\n",
            "      7      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9529\n",
            "      8      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9939\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.0086\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  2.0021\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9639\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9529\n",
            "     13      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9790\n",
            "     14      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9766\n",
            "     15      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9579\n",
            "     16      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9814\n",
            "     17      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  2.0035\n",
            "     18      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9788\n",
            "     19      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9994\n",
            "     20      1.0000      1.0000        \u001b[35m0.0000\u001b[0m  1.9574\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4535\u001b[0m      \u001b[32m0.4001\u001b[0m        \u001b[35m1.6514\u001b[0m  1.9570\n",
            "      2      \u001b[36m0.7882\u001b[0m      \u001b[32m0.7667\u001b[0m        \u001b[35m0.6240\u001b[0m  1.9617\n",
            "      3      \u001b[36m0.9680\u001b[0m      \u001b[32m0.9676\u001b[0m        \u001b[35m0.0970\u001b[0m  1.9706\n",
            "      4      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0111\u001b[0m  1.9598\n",
            "      5      \u001b[36m0.9996\u001b[0m      \u001b[32m0.9996\u001b[0m        \u001b[35m0.0015\u001b[0m  1.9458\n",
            "      6      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0004\u001b[0m  1.9539\n",
            "      7      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.9735\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9746\n",
            "      9      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9621\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9523\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9569\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9539\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9727\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9538\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9587\n",
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9376\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9638\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9494\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9759\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9683\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4561\u001b[0m      \u001b[32m0.4112\u001b[0m        \u001b[35m1.6091\u001b[0m  1.9576\n",
            "      2      \u001b[36m0.7900\u001b[0m      \u001b[32m0.7773\u001b[0m        \u001b[35m0.6410\u001b[0m  1.9695\n",
            "      3      \u001b[36m0.9691\u001b[0m      \u001b[32m0.9687\u001b[0m        \u001b[35m0.0906\u001b[0m  1.9739\n",
            "      4      \u001b[36m0.9978\u001b[0m      \u001b[32m0.9978\u001b[0m        \u001b[35m0.0068\u001b[0m  1.9566\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0007\u001b[0m  1.9603\n",
            "      6      1.0000      1.0000        \u001b[35m0.0003\u001b[0m  1.9608\n",
            "      7      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9729\n",
            "      8      1.0000      1.0000        \u001b[35m0.0002\u001b[0m  1.9596\n",
            "      9      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9798\n",
            "     10      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9545\n",
            "     11      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9574\n",
            "     12      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9551\n",
            "     13      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9598\n",
            "     14      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9503\n",
            "     15      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     16      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9524\n",
            "     17      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9641\n",
            "     18      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9645\n",
            "     19      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9493\n",
            "     20      1.0000      1.0000        \u001b[35m0.0001\u001b[0m  1.9626\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=LSTMModel(\n",
              "    (lstm): LSTM(17200, 32, batch_first=True)\n",
              "    (fc): Linear(in_features=32, out_features=5, bias=True)\n",
              "  ),\n",
              "),\n",
              "             param_grid={'batch_size': [16, 32, 64], 'lr': [0.001, 0.01, 0.1],\n",
              "                         'max_epochs': [10, 20],\n",
              "                         'module__hidden_dim': [64, 128, 256, 512]},\n",
              "             refit=False, scoring='accuracy')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this hyperparameter search possibly has too many parameters: took 3+ hours to run\n",
        "params = {\n",
        "    'max_epochs': [10, 20],\n",
        "    'batch_size':[16, 32, 64],\n",
        "    'lr': [0.001, 0.01, 0.1],\n",
        "    'module__hidden_dim': [64, 128, 256, 512],\n",
        "}\n",
        "gs = GridSearchCV(classifier, params, refit=False, cv=5, scoring='accuracy')\n",
        "\n",
        "gs.fit(train_features, train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHRuRHSQniwA",
        "outputId": "9e68fe89-a5d0-4ce7-f8fd-2be8c359f7eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "gs.best_score_  0.5514991769903836 \n",
            "gs.best_params_ {'batch_size': 64, 'lr': 0.001, 'max_epochs': 10, 'module__hidden_dim': 64}\n"
          ]
        }
      ],
      "source": [
        "print('\\ngs.best_score_ ', gs.best_score_, '\\ngs.best_params_', gs.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-5fbU0MniwA",
        "outputId": "2748690d-1cb9-4a80-c58a-ea259c21f75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4432\u001b[0m      \u001b[32m0.3292\u001b[0m        \u001b[35m1.3922\u001b[0m  0.4585\n",
            "      2      \u001b[36m0.5209\u001b[0m      \u001b[32m0.3853\u001b[0m        \u001b[35m1.1499\u001b[0m  0.3689\n",
            "      3      \u001b[36m0.7034\u001b[0m      \u001b[32m0.6346\u001b[0m        \u001b[35m0.9480\u001b[0m  0.3569\n",
            "      4      \u001b[36m0.8046\u001b[0m      \u001b[32m0.7499\u001b[0m        \u001b[35m0.6231\u001b[0m  0.3539\n",
            "      5      \u001b[36m0.9241\u001b[0m      \u001b[32m0.9179\u001b[0m        \u001b[35m0.3364\u001b[0m  0.3643\n",
            "      6      \u001b[36m0.9756\u001b[0m      \u001b[32m0.9750\u001b[0m        \u001b[35m0.1766\u001b[0m  0.3585\n",
            "      7      \u001b[36m0.9915\u001b[0m      \u001b[32m0.9914\u001b[0m        \u001b[35m0.1016\u001b[0m  0.3568\n",
            "      8      \u001b[36m0.9956\u001b[0m      \u001b[32m0.9956\u001b[0m        \u001b[35m0.0648\u001b[0m  0.3575\n",
            "      9      \u001b[36m0.9979\u001b[0m      \u001b[32m0.9979\u001b[0m        \u001b[35m0.0446\u001b[0m  0.3580\n",
            "     10      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0324\u001b[0m  0.3648\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=LSTMModel(\n",
              "    (lstm): LSTM(17200, 64, batch_first=True)\n",
              "    (fc): Linear(in_features=64, out_features=5, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# refit with optimal parameters\n",
        "\n",
        "classifier = NeuralNetClassifier(module=LSTMModel,\n",
        "                                 module__hidden_dim = 64,\n",
        "                                 batch_size=64,\n",
        "                                 max_epochs= 10,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.Adam,\n",
        "                                 lr=0.001,\n",
        "                                 train_split=None,\n",
        "                                 callbacks=callbacks,\n",
        "                                 verbose=1,\n",
        "                                 device=device)\n",
        "\n",
        "classifier.fit(train_features, train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gni7yfWniwB",
        "outputId": "f24ab1f7-f32f-4c17-8fde-fa9a776af9a9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " expl:impers       0.40      0.09      0.15        44\n",
            "   expl:pass       0.51      0.49      0.50       287\n",
            "     expl:pv       0.60      0.77      0.67       417\n",
            "        iobj       0.50      0.03      0.05        37\n",
            "         obj       0.30      0.11      0.16        65\n",
            "\n",
            "    accuracy                           0.56       850\n",
            "   macro avg       0.46      0.30      0.31       850\n",
            "weighted avg       0.53      0.56      0.52       850\n",
            "\n"
          ]
        }
      ],
      "source": [
        "targets = label_encoder.classes_\n",
        "\n",
        "y_pred_test = classifier.predict(test_features)\n",
        "print(classification_report(test_labels, y_pred_test, target_names=targets, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97pKKm7CniwB"
      },
      "source": [
        "***model performance mismatch problem***: the model is overfitting on the train data and thus performs much worse on the test data \n",
        "(https://machinelearningmastery.com/the-model-performance-mismatch-problem/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4-QbfdbniwC"
      },
      "source": [
        "## 5) Active Learner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_features.detach().cpu().numpy()\n",
        "train_labels = train_labels.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "PZ0pdms-0x2j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "k1IZezMJniwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f496c1be-6cc4-4744-e056-6c794b5a306e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4553\u001b[0m      \u001b[32m0.3717\u001b[0m        \u001b[35m1.3793\u001b[0m  0.3617\n",
            "      2      \u001b[36m0.5303\u001b[0m      \u001b[32m0.4029\u001b[0m        \u001b[35m1.1417\u001b[0m  0.3659\n",
            "      3      \u001b[36m0.7266\u001b[0m      \u001b[32m0.6576\u001b[0m        \u001b[35m0.9294\u001b[0m  0.3552\n",
            "      4      \u001b[36m0.8117\u001b[0m      \u001b[32m0.7592\u001b[0m        \u001b[35m0.5988\u001b[0m  0.3612\n",
            "      5      \u001b[36m0.9282\u001b[0m      \u001b[32m0.9229\u001b[0m        \u001b[35m0.3173\u001b[0m  0.3558\n",
            "      6      \u001b[36m0.9753\u001b[0m      \u001b[32m0.9747\u001b[0m        \u001b[35m0.1653\u001b[0m  0.3563\n",
            "      7      \u001b[36m0.9906\u001b[0m      \u001b[32m0.9905\u001b[0m        \u001b[35m0.0956\u001b[0m  0.3545\n",
            "      8      \u001b[36m0.9944\u001b[0m      \u001b[32m0.9944\u001b[0m        \u001b[35m0.0614\u001b[0m  0.3716\n",
            "      9      \u001b[36m0.9976\u001b[0m      \u001b[32m0.9976\u001b[0m        \u001b[35m0.0425\u001b[0m  0.3586\n",
            "     10      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0310\u001b[0m  0.3631\n"
          ]
        }
      ],
      "source": [
        "# no training arguments because classifier is already fitted\n",
        "learner = ActiveLearner(estimator=classifier,\n",
        "                        query_strategy=uncertainty_sampling,\n",
        "                        X_training=train_features,\n",
        "                        y_training=train_labels,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HxXXw2cRniwD"
      },
      "outputs": [],
      "source": [
        "number_of_loops = 10\n",
        "n_instances = 20 \n",
        "accuracies = [learner.score(test_features, test_labels)] # append first accuracy without learning\n",
        "pool_sent_list= list() # store annotated sentences and the labels\n",
        "pool_label_list= list()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqLLFEWZniwD"
      },
      "source": [
        "### Loop\n",
        "- stops after 20 iterations\n",
        "- prompt sentence\n",
        "\n",
        "Problem: if annotation is 'None' (e.g in the case a sentence is discarded) the loop breaks. We have to discard certain sentences because when creating the underlying corpus\n",
        "phrases that do not contain 'se' like 'aunque a tu mac no le pase nada' were not discarded because there is no suited programmatical way to differentiate btw. 'pase' and 'siéntese'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKGcIoETniwD",
        "outputId": "23ce84d8-7b38-416f-fec8-aa9fd1d5c39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "loop: 1\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('iobj', 0.24), ('expl:pv', 0.21), ('expl:impers', 0.2), ('obj', 0.18), ('expl:pass', 0.17)]\n",
            "\n",
            "En definitiva , los compradores ( y presumiblemente consumidores ) de vino se llevaban a casa más alimentos saludables que los que compraban cerveza .\n",
            "iobj\n",
            "\n",
            "loop: 1\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('obj', 0.25), ('expl:pv', 0.24), ('expl:impers', 0.21), ('expl:pass', 0.17), ('iobj', 0.13)]\n",
            "\n",
            "Una respuesta a Bebedores de vino se alimentan mejor que los consumidores de cerveza Que interesante estudio .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.24), ('expl:impers', 0.22), ('expl:pv', 0.2), ('iobj', 0.19), ('obj', 0.15)]\n",
            "\n",
            "Freud sabía con antelación que , si Valéry no podía reconocer a Nietzsche , es porque Nietzsche se parecía demasiado a Freud .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.25), ('obj', 0.18), ('expl:impers', 0.16), ('iobj', 0.13)]\n",
            "\n",
            "En este momento no se permiten comentarios , pero puedes enviar un trackback desde tu propio sitio .\n",
            "expl:pass\n",
            "\n",
            "loop: 1\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('iobj', 0.26), ('expl:pv', 0.2), ('obj', 0.18), ('expl:pass', 0.1)]\n",
            "\n",
            "La sociología positivista de la ciencia no se inquieta a sí misma con semejantes disputas , porque nunca examina el contexto social de el contenido de una disciplina .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('obj', 0.25), ('expl:impers', 0.22), ('expl:pv', 0.22), ('iobj', 0.17), ('expl:pass', 0.14)]\n",
            "\n",
            "Alrededor de el 90 % de la producción de trigo de Oregón se exporta , principalmente a países asiáticos .\n",
            "expl:pass\n",
            "\n",
            "loop: 1\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.26), ('obj', 0.25), ('expl:impers', 0.15), ('iobj', 0.07)]\n",
            "\n",
            "Cristo Jesús , que se entregó en rescate por todos .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.24), ('obj', 0.24), ('expl:pass', 0.23), ('expl:pv', 0.22), ('iobj', 0.08)]\n",
            "\n",
            "Respecto a su vacancia , dijo que se dio en circunstancias extrañas y si seguiría como regidor no hubiera podido manejar su estudio con esas situaciones municipales .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.25), ('expl:pass', 0.21), ('obj', 0.17), ('iobj', 0.11)]\n",
            "\n",
            "La única solución es tomar medidas para desmantelar completamente las estructuras paramilitares , económica y políticamente , afirmó Schwarz , sería un sinsentido que la Unión Europea financiase a criminales que mantienen poder ilegal y riquezas robadas , añadió .\n",
            "None\n",
            "\n",
            "loop: 1\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('iobj', 0.24), ('expl:pass', 0.21), ('expl:impers', 0.2), ('obj', 0.19), ('expl:pv', 0.16)]\n",
            "\n",
            "Las técnicas que haya sido testigo de la base de la tecnología futura AO que Maurice contribuyo a sistematizar .\n",
            "None\n",
            "\n",
            "loop: 1\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.24), ('obj', 0.23), ('expl:impers', 0.17), ('iobj', 0.09)]\n",
            "\n",
            "' Érase una vez en Anatolia ' , contemplando que es gerundio Conseguir un premio en un festival no asegura nunca el favor de el público .\n",
            "None\n",
            "\n",
            "loop: 1\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.25), ('obj', 0.24), ('expl:impers', 0.23), ('expl:pass', 0.23), ('iobj', 0.05)]\n",
            "\n",
            "Hace poco cayó en mis manos un libro de teológos gay que prueban que la homosexualidad es aceptada por dios y que incluso Jesucristo se levanta junto a un jóven desnudo en el huerto de Getsemaní .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('expl:impers', 0.23), ('expl:pass', 0.2), ('obj', 0.17), ('iobj', 0.13)]\n",
            "\n",
            "Urano en fase de sexta , Saturno en cuadratura con él mismo .\n",
            "None\n",
            "\n",
            "loop: 1\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.25), ('iobj', 0.24), ('expl:pv', 0.2), ('obj', 0.16), ('expl:pass', 0.15)]\n",
            "\n",
            "Maite Ayestaran apuesta por hacer de la crisis una oportunidad y conseguir que San Sebastián se posicione en esos nichos de el surf en los que la propia crisis nos deje entrar .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.26), ('obj', 0.21), ('expl:impers', 0.16), ('iobj', 0.11)]\n",
            "\n",
            "El TRATO PERSONAL se enfoca en nuestra gente , nuestro servicio y nuestro producto .\n",
            "expl:pass\n",
            "\n",
            "loop: 1\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:impers', 0.24), ('iobj', 0.24), ('expl:pass', 0.22), ('obj', 0.04)]\n",
            "\n",
            "Uno aprende mucho más sobre sí mismo observándo se que a través de libros , o de un psicólogo , o de un hombre de letras o profesor , erudito , ingenioso y complicado .\n",
            "expl:pv\n",
            "\n",
            "loop: 1\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('iobj', 0.22), ('expl:impers', 0.2), ('expl:pass', 0.2), ('obj', 0.12)]\n",
            "\n",
            "( El Sr. Monstrenco ) El Cahiers Du Cinema de Serie Z sin ningún titubeo lo consideramos el mejor blog de cultura popular hecho nunca , y quizá que se haga nunca .\n",
            "expl:impers\n",
            "\n",
            "loop: 1\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:impers', 0.21), ('iobj', 0.21), ('obj', 0.16), ('expl:pass', 0.15)]\n",
            "\n",
            "Pregunta a la familia en qué aspectos queman que mejorase la persona .\n",
            "None\n",
            "\n",
            "loop: 1\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('iobj', 0.25), ('expl:pv', 0.21), ('expl:pass', 0.19), ('obj', 0.08)]\n",
            "\n",
            "Hace mucho tiempo en una galaxia muy lejana , cuando aún no había encontrado un tipo de letra que me gustase para este blog , veía en muchas páginas web fuentes que me gustaban mucho , pero no había manera de saber su nombre .\n",
            "None\n",
            "\n",
            "loop: 1\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.25), ('expl:impers', 0.19), ('obj', 0.16), ('iobj', 0.12)]\n",
            "\n",
            "Segunda expedición : A el arruinar sin querer la bufanda de seda de mamá , Anabella se propone buscar una solución .\n",
            "expl:pv\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4229\u001b[0m      \u001b[32m0.3642\u001b[0m        \u001b[35m1.4016\u001b[0m  0.3690\n",
            "      2      \u001b[36m0.5308\u001b[0m      \u001b[32m0.4044\u001b[0m        \u001b[35m1.1407\u001b[0m  0.3528\n",
            "      3      \u001b[36m0.7110\u001b[0m      \u001b[32m0.6428\u001b[0m        \u001b[35m0.9361\u001b[0m  0.3575\n",
            "      4      \u001b[36m0.8133\u001b[0m      \u001b[32m0.7637\u001b[0m        \u001b[35m0.6115\u001b[0m  0.3516\n",
            "      5      \u001b[36m0.9203\u001b[0m      \u001b[32m0.9137\u001b[0m        \u001b[35m0.3279\u001b[0m  0.3630\n",
            "      6      \u001b[36m0.9771\u001b[0m      \u001b[32m0.9766\u001b[0m        \u001b[35m0.1722\u001b[0m  0.3609\n",
            "      7      \u001b[36m0.9889\u001b[0m      \u001b[32m0.9888\u001b[0m        \u001b[35m0.0993\u001b[0m  0.3540\n",
            "      8      \u001b[36m0.9950\u001b[0m      \u001b[32m0.9950\u001b[0m        \u001b[35m0.0636\u001b[0m  0.3554\n",
            "      9      \u001b[36m0.9977\u001b[0m      \u001b[32m0.9976\u001b[0m        \u001b[35m0.0439\u001b[0m  0.3576\n",
            "     10      \u001b[36m0.9982\u001b[0m      \u001b[32m0.9982\u001b[0m        \u001b[35m0.0319\u001b[0m  0.3684\n",
            "\n",
            "loop: 2\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.24), ('iobj', 0.24), ('expl:pv', 0.22), ('obj', 0.16), ('expl:pass', 0.14)]\n",
            "\n",
            "Los nervios se inflaman .\n",
            "expl:pv\n",
            "\n",
            "loop: 2\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('obj', 0.24), ('expl:pass', 0.22), ('expl:pv', 0.21), ('iobj', 0.18), ('expl:impers', 0.15)]\n",
            "\n",
            "domingo , julio 14 , 2013 Nadie cree nada al menos que primero piense que es creíble .\n",
            "None\n",
            "\n",
            "loop: 2\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.25), ('expl:pass', 0.25), ('expl:pv', 0.21), ('obj', 0.15), ('iobj', 0.14)]\n",
            "\n",
            "Si la base es 10 , será divisible por 9 .\n",
            "None\n",
            "\n",
            "loop: 2\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.26), ('iobj', 0.22), ('obj', 0.2), ('expl:pass', 0.18), ('expl:pv', 0.14)]\n",
            "\n",
            "Los trabajadores / as de la alimentación se arriesgan a la exposición a el diacetil en forma de vapores , gotas o polvo durante el proceso de fabricación .\n",
            "expl:pv\n",
            "\n",
            "loop: 2\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('iobj', 0.24), ('expl:pv', 0.21), ('expl:impers', 0.2), ('expl:pass', 0.18), ('obj', 0.18)]\n",
            "\n",
            "Encuestas hechas a un año de la elección tienen muchísimo mayor margen para equivocar se , y , por lo tanto , buscar sustituir un proceso formal de elecciones por una encuesta le hace un flaco favor a la democracia .\n",
            "expl:pv\n",
            "\n",
            "loop: 2\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.26), ('expl:impers', 0.21), ('iobj', 0.16), ('obj', 0.12)]\n",
            "\n",
            "Y cuando se práctica , claro .\n",
            "expl:pass\n",
            "\n",
            "loop: 2\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.26), ('iobj', 0.26), ('obj', 0.24), ('expl:pass', 0.13), ('expl:pv', 0.11)]\n",
            "\n",
            "Pareto ( que es el apellido de quien postuló esta ley ) descubrió con experimentos que esta ley aplica a montones de situaciones en la vida real , y que si bien en muchas ocasiones puede que no sea un 20 % o un 80 % exacto ( podría ser 23 % y 79 % ) que por lo regular esos valores se encuentran a el rededor de 20 y 80 .\n",
            "expl:pv\n",
            "\n",
            "loop: 2\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:impers', 0.23), ('expl:pv', 0.21), ('iobj', 0.18), ('obj', 0.13)]\n",
            "\n",
            "Cabe incluso preguntar se si todavía podemos hablar de « Estado en el caso de Francia .\n",
            "expl:pv\n",
            "\n",
            "loop: 2\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('iobj', 0.22), ('expl:pass', 0.18), ('obj', 0.17), ('expl:impers', 0.16)]\n",
            "\n",
            "En definitiva , lo que se puede decir es que el acuerdo es para salvar a los acreedores .\n",
            "expl:impers\n",
            "\n",
            "loop: 2\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.23), ('expl:impers', 0.22), ('expl:pv', 0.19), ('iobj', 0.18), ('obj', 0.17)]\n",
            "\n",
            "Colossus C on el comienzo de la Segunda Guerra Mundial , en 1939 , el Gobierno británico reclutó en Bletchley Park ( cerca de Londres ) a sus mejores científicos para que descifraran los mensajes de los alemanes , entre ellos estaba Alan Turing , uno de los mayores impulsores de el proyecto , que se encargó , entre otras cosas , de las funciones lógicas de la máquina .\n",
            "expl:pv\n",
            "\n",
            "loop: 2\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.25), ('expl:impers', 0.2), ('iobj', 0.17), ('obj', 0.13)]\n",
            "\n",
            "El salario medio de los obreros de base era de 5 córdobas por 8 horas de labor o sea 63 centavos dólar por hora .\n",
            "None\n",
            "\n",
            "loop: 2\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.25), ('iobj', 0.25), ('expl:pass', 0.2), ('obj', 0.16), ('expl:impers', 0.13)]\n",
            "\n",
            "Conclusiones Todo ser humano posee una dignidad intrínseca e inviolable , que no es susceptible de gradaciones , y que es universal e independiente de la situación de edad , salud o autonomía que se posea .\n",
            "expl:impers\n",
            "\n",
            "loop: 2\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('iobj', 0.23), ('expl:impers', 0.22), ('obj', 0.17), ('expl:pass', 0.12)]\n",
            "\n",
            "En Francia y Bulgaria se\n",
            "None\n",
            "\n",
            "loop: 2\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.23), ('expl:impers', 0.22), ('obj', 0.16), ('iobj', 0.12)]\n",
            "\n",
            "La paella ha sido y es , para los más exigentes un alimento más divino que humano , tienta , deleita , reconforta , y su ancestral receta se inscribe dentro de los más puros cánones de la acreditada dieta valenciana o mediterránea , nadie puede alcanzar eminencia de buen sibarita , si antes no ha experimentado el placer de saborear la paella con cuchara de madera .\n",
            "expl:pv\n",
            "\n",
            "loop: 2\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.27), ('obj', 0.18), ('expl:impers', 0.14), ('iobj', 0.14)]\n",
            "\n",
            "Jesse le dijo que necesitaban ayuda , y Suu los aceptó .\n",
            "None\n",
            "\n",
            "loop: 2\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('obj', 0.24), ('expl:pv', 0.19), ('expl:pass', 0.17), ('iobj', 0.14)]\n",
            "\n",
            "- ¿ Por qué utilizó la frase él es ella para definir a Massa ?\n",
            "None\n",
            "\n",
            "loop: 2\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('obj', 0.26), ('expl:pv', 0.25), ('expl:impers', 0.16), ('iobj', 0.06)]\n",
            "\n",
            "Que hagan su mochila para ir a el cole cuando ya son más mayores , estos son pequeños ejemplos que ayudan a los niños y niñas a se más autónomos e independientes .\n",
            "None\n",
            "\n",
            "loop: 2\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('iobj', 0.26), ('expl:impers', 0.23), ('expl:pv', 0.22), ('obj', 0.02)]\n",
            "\n",
            "En la Ámsterdam que alguna vez era tolerante , ahora a los gays se los castiga corporalmente de parte de los Musulmanes exclusivamente .\n",
            "expl:impers\n",
            "\n",
            "loop: 2\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('obj', 0.27), ('iobj', 0.26), ('expl:pass', 0.19), ('expl:impers', 0.17), ('expl:pv', 0.12)]\n",
            "\n",
            "Mucho se ha escrito sobre la batalla de Pichincha , casi siempre entre la exaltación y la hipérbole .\n",
            "expl:pass\n",
            "\n",
            "loop: 2\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.26), ('expl:impers', 0.18), ('iobj', 0.18), ('obj', 0.11)]\n",
            "\n",
            "LA IGLESIA GENERAL La Iglesia de Dios se compone de todas las personas espi­ritualmente regeneradas , cuyos nombres están escritos en el cielo .\n",
            "expl:pv\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4012\u001b[0m      \u001b[32m0.3706\u001b[0m        \u001b[35m1.4161\u001b[0m  0.3529\n",
            "      2      \u001b[36m0.5661\u001b[0m      \u001b[32m0.4665\u001b[0m        \u001b[35m1.1376\u001b[0m  0.3604\n",
            "      3      \u001b[36m0.7358\u001b[0m      \u001b[32m0.6659\u001b[0m        \u001b[35m0.9101\u001b[0m  0.3585\n",
            "      4      \u001b[36m0.8175\u001b[0m      \u001b[32m0.7624\u001b[0m        \u001b[35m0.5960\u001b[0m  0.3525\n",
            "      5      \u001b[36m0.9165\u001b[0m      \u001b[32m0.9072\u001b[0m        \u001b[35m0.3359\u001b[0m  0.3599\n",
            "      6      \u001b[36m0.9740\u001b[0m      \u001b[32m0.9734\u001b[0m        \u001b[35m0.1830\u001b[0m  0.3637\n",
            "      7      \u001b[36m0.9898\u001b[0m      \u001b[32m0.9897\u001b[0m        \u001b[35m0.1064\u001b[0m  0.3598\n",
            "      8      \u001b[36m0.9939\u001b[0m      \u001b[32m0.9938\u001b[0m        \u001b[35m0.0680\u001b[0m  0.3573\n",
            "      9      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0467\u001b[0m  0.3674\n",
            "     10      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0338\u001b[0m  0.3603\n",
            "\n",
            "loop: 3\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('obj', 0.2), ('expl:pv', 0.19), ('iobj', 0.19), ('expl:pass', 0.15)]\n",
            "\n",
            "[ iii ] La idea antiintuicionista y antifundacionalista básica común a Derrida y a estos autores es que el conocimiento es cuestión de declarar oraciones , y que no se puede convalidar una declaración enfrentándo la a un objeto ( por ejemplo , una mesa , el concepto « mesidad o la idea platónica de mesa ) , sino únicamente declarando otras oraciones .\n",
            "expl:impers\n",
            "\n",
            "loop: 3\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('obj', 0.26), ('expl:pass', 0.23), ('iobj', 0.21), ('expl:impers', 0.17), ('expl:pv', 0.13)]\n",
            "\n",
            "La iglesia se llena para un concierto , una película , o algo extravagante .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.25), ('expl:impers', 0.24), ('obj', 0.23), ('expl:pass', 0.22), ('iobj', 0.06)]\n",
            "\n",
            "( silencio incómodo ) - Bueno Antonio , y cuando dices que se juega el Madrid-Barça de fútbol .\n",
            "expl:pass\n",
            "\n",
            "loop: 3\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.25), ('obj', 0.22), ('expl:impers', 0.14), ('iobj', 0.12)]\n",
            "\n",
            "Ellos le solucionaron el problema buscando vía Internet , clientes que se interesaran en sus productos .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.25), ('expl:pass', 0.21), ('expl:pv', 0.21), ('iobj', 0.2), ('obj', 0.12)]\n",
            "\n",
            "Hoy me avisaron que en 5 tiendas importantes de Miami ya entregaron con la version 1.1.1 y con los iPhone que tenian todavia en stock con la vieja 1.0.2 automaticamente se los cambiaron por la mercaderia nueva .\n",
            "iobj\n",
            "\n",
            "loop: 3\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.25), ('expl:pass', 0.21), ('expl:pv', 0.21), ('iobj', 0.2), ('obj', 0.12)]\n",
            "\n",
            "- Predisposición a compartir : Tradicionalmente las empresas mostraban recelo a compartir sus ideas , pero se han dado cuenta que estas medidas dificultan su crecimiento .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('expl:pass', 0.23), ('obj', 0.2), ('expl:impers', 0.17), ('iobj', 0.14)]\n",
            "\n",
            "1 m 2 en la copia escaneada , con el 5 escaneó tan mal que ni siquiera se parece a un dígito .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('expl:impers', 0.24), ('expl:pv', 0.24), ('iobj', 0.17), ('obj', 0.1)]\n",
            "\n",
            "El Rectorado de la Universidad de Sevilla se ha convertido en el cuartel ético de estos jóvenes románticos que saben que esta crisis está siendo el subterfugio a través de el cual la derecha está instalando su modelo excluyente de sociedad .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('expl:impers', 0.24), ('expl:pv', 0.24), ('iobj', 0.17), ('obj', 0.1)]\n",
            "\n",
            "11 Respuestas por Que el mundo se entere [ .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.24), ('expl:pv', 0.23), ('expl:pass', 0.19), ('iobj', 0.18), ('obj', 0.16)]\n",
            "\n",
            "Tundis estuvo participando de un encuentro con jubilados de nuestra ciudad junto a el precandidato a concejal de el Frente Renovador , Facundo López , donde se hizo entrega , además , de una donación para la Asociación Cooperadora del Hospital Municipal Dr. Emilio Ferreyra .\n",
            "expl:pass\n",
            "\n",
            "loop: 3\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('iobj', 0.24), ('obj', 0.22), ('expl:pv', 0.19), ('expl:impers', 0.09)]\n",
            "\n",
            "El 20 de mayo de 1902 , a el cesar la Intervención , se habían construido unos 500 metros .\n",
            "expl:pass\n",
            "\n",
            "loop: 3\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('obj', 0.23), ('expl:pv', 0.22), ('expl:impers', 0.16), ('iobj', 0.13)]\n",
            "\n",
            "Por ejemplo , en la parte de la izquierda del todo nos encontramos con todos los elementos que tienen los electrones externos en los orbitales s ( menos el helio , que es especial y no se encuentra ahí ) .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.26), ('expl:impers', 0.23), ('obj', 0.16), ('iobj', 0.1)]\n",
            "\n",
            "Pero lo más lindo es que la libertad , el viento en la cara , el silencio y esa magnífica soledad de correr no se ha perdido .\n",
            "expl:impers\n",
            "\n",
            "loop: 3\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.25), ('expl:impers', 0.22), ('iobj', 0.16), ('obj', 0.1)]\n",
            "\n",
            "Leí tu relato , me encantó y se lo reenvié a una hermana que también corre .\n",
            "iobj\n",
            "\n",
            "loop: 3\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('expl:pass', 0.25), ('expl:impers', 0.2), ('iobj', 0.16), ('obj', 0.13)]\n",
            "\n",
            "{ 20 } A medida que el ejército diezmaba sus bases de apoyo , la guerrilla se vio obligada a enterrar las armas y las municiones por falta de combatientes que las usaran .\n",
            "expl:pv\n",
            "\n",
            "loop: 3\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.26), ('expl:pass', 0.21), ('obj', 0.17), ('iobj', 0.1)]\n",
            "\n",
            "Masgüel , pienso que los que opináis así lo hacéis bien por este motivo : Que no os hayáis enterado de que la noticia en que se responsabilizaba a el Papa de el escándalo es falsa ( una de las grandes meteduras de pata de el periodismo moderno ) , y de que este escándalo de abusos sexuales es un caso de libro de pánico moral y agitprop .\n",
            "expl:pass\n",
            "\n",
            "loop: 3\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('obj', 0.27), ('expl:impers', 0.21), ('iobj', 0.17), ('expl:pass', 0.09)]\n",
            "\n",
            "El libro de James M. Barrie demuestra el poder de imaginación de quien lo escribió y también deja claro por qué , cien años después , aún se trata de una lectura recomendable .\n",
            "expl:impers\n",
            "\n",
            "loop: 3\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.27), ('expl:impers', 0.23), ('obj', 0.13), ('iobj', 0.11)]\n",
            "\n",
            "Cuando encuentras una escuela de el Cuarto Camino dirigida por una persona que ha roto las cadenas de el sueño y que ha alcanzado un nivel de consciencia más elevado , se te enseña a alcanzar el potencial completo de tus posibilidades de evolución humana .\n",
            "expl:impers\n",
            "\n",
            "loop: 3\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.26), ('iobj', 0.25), ('expl:impers', 0.14), ('obj', 0.08)]\n",
            "\n",
            "Los logros de la mujer en la sociedad se han visto reflejados con tal fortuna en las leyes que incluso ya hay reglamentos especiales para madres embarazadas o que estén lactando .\n",
            "expl:pass\n",
            "\n",
            "loop: 3\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('iobj', 0.24), ('expl:pv', 0.23), ('expl:impers', 0.17), ('obj', 0.09)]\n",
            "\n",
            "PGR deberá informar de todos los delitos que se le imputan a El Chapo CIUDAD DE MÉXICO , 14 de agosto .\n",
            "expl:impers\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4151\u001b[0m      \u001b[32m0.3980\u001b[0m        \u001b[35m1.4032\u001b[0m  0.3637\n",
            "      2      \u001b[36m0.5257\u001b[0m      0.3935        \u001b[35m1.1520\u001b[0m  0.3516\n",
            "      3      \u001b[36m0.6952\u001b[0m      \u001b[32m0.6264\u001b[0m        \u001b[35m0.9423\u001b[0m  0.3514\n",
            "      4      \u001b[36m0.8090\u001b[0m      \u001b[32m0.7594\u001b[0m        \u001b[35m0.6212\u001b[0m  0.3585\n",
            "      5      \u001b[36m0.9225\u001b[0m      \u001b[32m0.9157\u001b[0m        \u001b[35m0.3430\u001b[0m  0.3586\n",
            "      6      \u001b[36m0.9742\u001b[0m      \u001b[32m0.9734\u001b[0m        \u001b[35m0.1861\u001b[0m  0.3623\n",
            "      7      \u001b[36m0.9896\u001b[0m      \u001b[32m0.9894\u001b[0m        \u001b[35m0.1092\u001b[0m  0.3528\n",
            "      8      \u001b[36m0.9942\u001b[0m      \u001b[32m0.9942\u001b[0m        \u001b[35m0.0701\u001b[0m  0.3554\n",
            "      9      \u001b[36m0.9974\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0483\u001b[0m  0.3530\n",
            "     10      \u001b[36m0.9985\u001b[0m      \u001b[32m0.9985\u001b[0m        \u001b[35m0.0350\u001b[0m  0.3575\n",
            "\n",
            "loop: 4\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.25), ('expl:pass', 0.25), ('iobj', 0.23), ('expl:pv', 0.15), ('obj', 0.11)]\n",
            "\n",
            "( Vea el relato de el doctor Yáñez a El Mercurio de el 13 de agosto 2001 : Me fueron a decir que estaba mal , ' parece que se va a desmayar ' .\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('obj', 0.24), ('expl:impers', 0.23), ('expl:pv', 0.23), ('expl:pass', 0.18), ('iobj', 0.12)]\n",
            "\n",
            "Las nebulosas de emisión y de reflexión suelen verse juntas .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('iobj', 0.25), ('expl:impers', 0.23), ('obj', 0.22), ('expl:pass', 0.19), ('expl:pv', 0.11)]\n",
            "\n",
            "En otras palabras , combatía a la gente en la que se convirtieron su hija y su nieto .\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.25), ('expl:pv', 0.23), ('obj', 0.21), ('expl:pass', 0.17), ('iobj', 0.13)]\n",
            "\n",
            "Y también están los vendedores ambulantes a los que la pobreza ha obligado a aliar se con quienes el presidente de Nicautor califica de personas sin escrúpulos .\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('expl:pass', 0.25), ('expl:impers', 0.19), ('iobj', 0.17), ('obj', 0.13)]\n",
            "\n",
            "Y les tenemos las habitaciones de nuestros hijos parecidas a una tienda de juguetes , pareciera que allí Papa Noel o los Reyes Magos hubieran dejado olvidado allí millones de juguetes , sin embargo nuestros hijos se aburren con facilidad y no saben a qué jugar !\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('iobj', 0.26), ('expl:pv', 0.23), ('expl:pass', 0.21), ('obj', 0.16), ('expl:impers', 0.14)]\n",
            "\n",
            "Pero no se puede llamar sagrada la propiedad de grandes latifundios mal explotados ; peor aún si fueron mal adquiridos .\n",
            "expl:impers\n",
            "\n",
            "loop: 4\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('expl:impers', 0.21), ('iobj', 0.21), ('expl:pass', 0.19), ('obj', 0.13)]\n",
            "\n",
            "A partir de la investigación de distintas culturas , se puede decir que el pensamiento mágico es inherente a la naturaleza humana .\n",
            "expl:impers\n",
            "\n",
            "loop: 4\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('expl:impers', 0.23), ('obj', 0.23), ('expl:pass', 0.21), ('iobj', 0.06)]\n",
            "\n",
            "Mire , y espero que con esto dé por terminado el tema , porque yo discuto para llegar a alguna parte , no encuentro ningún placer en peloteos , y si usted tiene problemas de fe y herejías , creo que se ha equivocado completamente de lugar .\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.26), ('expl:impers', 0.25), ('expl:pass', 0.18), ('obj', 0.18), ('iobj', 0.13)]\n",
            "\n",
            "Pero además , cree que Rajoy no tiene ni el liderazgo , ni la autoridad política , ni la legitimación social para gobernar en las circunstancias que se han producido después de el escándalo Bárcenas .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.26), ('obj', 0.23), ('iobj', 0.21), ('expl:pass', 0.15), ('expl:pv', 0.15)]\n",
            "\n",
            "Se debe tener conocimiento previo de todos los riesgos asociados a la negociación de divisas y , en caso de que se tenga alguna duda , buscar la ayuda de un asesor financiero independiente .\n",
            "expl:impers\n",
            "\n",
            "loop: 4\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('obj', 0.23), ('expl:pv', 0.21), ('expl:impers', 0.15), ('iobj', 0.15)]\n",
            "\n",
            "II Durante los últimos catorce años , nuestras exportaciones no petroleras se han reducido tanto en términos absolutos como relativos .\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.26), ('expl:impers', 0.24), ('iobj', 0.18), ('obj', 0.07)]\n",
            "\n",
            "Hay quien apunta que el plato tiene su origen en la cocina árabe y que se utilizó cus-cus en su elaboración , siendo sustituido más tarde por el arroz .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('iobj', 0.26), ('expl:impers', 0.22), ('expl:pass', 0.2), ('obj', 0.18), ('expl:pv', 0.14)]\n",
            "\n",
            "Una tercera opción era divorciar se en el exterior , lo que después debía ser validado en Malta .\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:impers', 0.25), ('expl:pv', 0.25), ('iobj', 0.18), ('obj', 0.05)]\n",
            "\n",
            "Esas patentes se desarrollaron incluso con la guerra de las corrientes contra Edison , el cual defendía la corriente continua , en curso .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('iobj', 0.27), ('obj', 0.22), ('expl:pass', 0.21), ('expl:pv', 0.19), ('expl:impers', 0.11)]\n",
            "\n",
            "Con antibióticos adecuados la regresión de la fiebre y la detención de el avance de la placa inflamada y dolorosa sobre la piel se produce en 1 a 3 días .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pass', 0.25), ('expl:pv', 0.21), ('obj', 0.2), ('iobj', 0.07)]\n",
            "\n",
            "A el asumir la teoría neoclásica de el productor y el libre mercado entonces la intervención de el Estado se descarta ya que su intervención provocaría imponer impuestos a el ahorro empresarial lo que limita la posibilidad de inversión .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('obj', 0.26), ('expl:pass', 0.25), ('iobj', 0.14), ('expl:impers', 0.09)]\n",
            "\n",
            "Después se verterá a la paella con el caldo y de esta manera proporcionará el específico sabor de baquetes ( caracoles ) de montaña .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.25), ('expl:impers', 0.2), ('obj', 0.16), ('iobj', 0.12)]\n",
            "\n",
            "En vez de eso , se hacen adeptos a encontrar formas creativas de resolver problemas o usar la fuerza bruta para seguir su camino y perseverar .\n",
            "expl:pv\n",
            "\n",
            "loop: 4\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.26), ('iobj', 0.23), ('expl:impers', 0.19), ('obj', 0.04)]\n",
            "\n",
            "Vuelvo e insisto a la población venezolana , está sin novedad el Complejo Refinador Paraguaná , explicó Stella Lugo , gobernadora de el estado Falcón , a el confirmar que hubo un pequeño incendio en la refinería de Amuay , Complejo Refinador Paraguaná ( CRP ) , pero que ya fue controlado e informó que los heroicos bomberos apagaron el incendio y que inmediatamente se formó un comité de evaluación para determinar las causas de el incidente .\n",
            "expl:pass\n",
            "\n",
            "loop: 4\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('iobj', 0.28), ('expl:pv', 0.24), ('expl:impers', 0.22), ('expl:pass', 0.2), ('obj', 0.06)]\n",
            "\n",
            "Si es que no se puede ser buena .\n",
            "expl:impers\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4084\u001b[0m      \u001b[32m0.3728\u001b[0m        \u001b[35m1.3861\u001b[0m  0.3818\n",
            "      2      \u001b[36m0.5512\u001b[0m      \u001b[32m0.4432\u001b[0m        \u001b[35m1.1427\u001b[0m  0.3632\n",
            "      3      \u001b[36m0.7264\u001b[0m      \u001b[32m0.6566\u001b[0m        \u001b[35m0.9282\u001b[0m  0.3584\n",
            "      4      \u001b[36m0.8115\u001b[0m      \u001b[32m0.7591\u001b[0m        \u001b[35m0.6072\u001b[0m  0.3691\n",
            "      5      \u001b[36m0.9247\u001b[0m      \u001b[32m0.9183\u001b[0m        \u001b[35m0.3334\u001b[0m  0.3569\n",
            "      6      \u001b[36m0.9734\u001b[0m      \u001b[32m0.9727\u001b[0m        \u001b[35m0.1803\u001b[0m  0.3569\n",
            "      7      \u001b[36m0.9896\u001b[0m      \u001b[32m0.9895\u001b[0m        \u001b[35m0.1064\u001b[0m  0.3654\n",
            "      8      \u001b[36m0.9942\u001b[0m      \u001b[32m0.9942\u001b[0m        \u001b[35m0.0689\u001b[0m  0.3721\n",
            "      9      \u001b[36m0.9968\u001b[0m      \u001b[32m0.9968\u001b[0m        \u001b[35m0.0480\u001b[0m  0.3641\n",
            "     10      \u001b[36m0.9980\u001b[0m      \u001b[32m0.9980\u001b[0m        \u001b[35m0.0351\u001b[0m  0.3631\n",
            "\n",
            "loop: 5\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.23), ('expl:pass', 0.22), ('expl:pv', 0.22), ('obj', 0.17), ('iobj', 0.16)]\n",
            "\n",
            "O dicho de otro modo , ¿ Qué hace que en lugar de decir la materia es eterna se diga dios es eterno , por ejemplo ?\n",
            "expl:impers\n",
            "\n",
            "loop: 5\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('iobj', 0.25), ('expl:pv', 0.23), ('expl:impers', 0.19), ('obj', 0.07)]\n",
            "\n",
            "Supongo que en las tribus de cazadores recolectores se debe mantener un equilibrio interno entre competitividad por un lado y cooperación y altruismo por otro , para mantener tanto a los individuos sanos , vigorosos y hábiles , como a la tribu cohesionada y fuerte frente otras competidoras .\n",
            "expl:impers\n",
            "\n",
            "loop: 5\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.24), ('obj', 0.22), ('expl:pv', 0.19), ('expl:pass', 0.18), ('iobj', 0.17)]\n",
            "\n",
            "Sin duda que esas sombras que impedían ver la luminosa apuesta que guarda la lírica de Sena , quedan ahora disipadas , con este volumen intenso y extenso , donde se descubre la voz de un autor de variada temática - lo civil , lo político , lo erótico , lo material , lo amoroso .\n",
            "expl:pass\n",
            "\n",
            "loop: 5\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.24), ('expl:pass', 0.22), ('iobj', 0.21), ('obj', 0.21), ('expl:impers', 0.11)]\n",
            "\n",
            "Este número se ve verde o azul según el ángulo de observación .\n",
            "expl:impers\n",
            "\n",
            "loop: 5\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.24), ('expl:impers', 0.23), ('iobj', 0.2), ('expl:pass', 0.17), ('obj', 0.17)]\n",
            "\n",
            "Donostia debe entrar en los nichos de el surf en los que la crisis le deje Maite Ayestaran , de Fomento San Sebastián , apuesta por hacer de el contexto económico actual una oportunidad El sector está de moda y se considera estratégico para una ciudad de servicios como San Sebastián .\n",
            "expl:pass\n",
            "\n",
            "loop: 5\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('iobj', 0.25), ('expl:pv', 0.23), ('expl:impers', 0.19), ('obj', 0.07)]\n",
            "\n",
            "De este modo los que mejor puntúan en el juego ( los mejor adaptados ) son los que más se reproducen ( éxito reproductor ) y pasan su comportamiento ( sus genes ) a la siguiente generación .\n",
            "expl:pv\n",
            "\n",
            "loop: 5\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('obj', 0.21), ('iobj', 0.18), ('expl:pass', 0.17), ('expl:impers', 0.16)]\n",
            "\n",
            "En homenaje a el valor demostrado es que se recuerda esta fecha como el día de la madre boliviana , conmemoración que fue confirmada a través de la Ley del Día de la Madre , el 8 de Mayo de 1927 , durante el gobierno de Hernando Siles .\n",
            "expl:pass\n",
            "\n",
            "loop: 5\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('obj', 0.26), ('expl:pv', 0.23), ('expl:impers', 0.14), ('iobj', 0.11)]\n",
            "\n",
            "No queremos estar fuera de la ley , sino presionar para que haya leyes justas y así se pueda vivir con conciencia tranquila dentro de la ley .\n",
            "expl:impers\n",
            "\n",
            "loop: 5\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('expl:impers', 0.27), ('obj', 0.27), ('expl:pass', 0.11), ('iobj', 0.08)]\n",
            "\n",
            "En cambio , en vez de hablar en términos de debería o tengo que , sería mejor utilizar la frase me gustaría .\n",
            "None\n",
            "\n",
            "loop: 5\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.25), ('iobj', 0.23), ('obj', 0.13), ('expl:pass', 0.12)]\n",
            "\n",
            "Sólo que se hace de una manera algo distinta .\n",
            "expl:impers\n",
            "\n",
            "loop: 5\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:impers', 0.23), ('expl:pv', 0.23), ('obj', 0.21), ('iobj', 0.06)]\n",
            "\n",
            "Se aprecia como una sucesión de segmentos plateados ; a el trasluz aparece una banda oscura y continua en la que puede leer se la leyenda BCRA » , con el número que corresponde a el valor de el billete .\n",
            "expl:impers\n",
            "\n",
            "loop: 5\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('iobj', 0.26), ('obj', 0.2), ('expl:impers', 0.19), ('expl:pv', 0.07)]\n",
            "\n",
            "En 1979 , se une a su padre como líder de el CUC .\n",
            "expl:pv\n",
            "\n",
            "loop: 5\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:impers', 0.22), ('iobj', 0.22), ('expl:pass', 0.16), ('obj', 0.13)]\n",
            "\n",
            "5 ) Manejo de Lista , Segmentación , Testing & Bevaviour Tracking : toda actividad e interacción de marketing realizada por tu consumidor termina en una base de datos de la herramienta de marketing .\n",
            "None\n",
            "\n",
            "loop: 5\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.28), ('expl:pv', 0.26), ('iobj', 0.19), ('obj', 0.16), ('expl:pass', 0.12)]\n",
            "\n",
            "Cuando se producen cambios de temperatura , es elemental que también cambien de vestuario .\n",
            "expl:pv\n",
            "\n",
            "loop: 5\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('iobj', 0.24), ('expl:pv', 0.21), ('expl:impers', 0.19), ('obj', 0.09)]\n",
            "\n",
            "Su número ha caído un 3,1 % con respecto a 2009 , como describe el director general de un banco privado suizo : Algunas , por ejemplo la de Ram Bhavnani , se fusionaron , mientras que otros inversores han optado por vehículos más eficientes , como las SIF [ fondos de inversión especializados , por sus siglas en inglés ] luxemburguesas .\n",
            "expl:pass\n",
            "\n",
            "loop: 5\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('iobj', 0.27), ('expl:pass', 0.26), ('obj', 0.17), ('expl:pv', 0.16), ('expl:impers', 0.14)]\n",
            "\n",
            "Especial significación tuvo la celebración de la X Sesión de la Comisión Intergubernamental con la Federación de Rusia y la V Sesión del Comité Empresarial Cuba-Rusia , en cuyo contexto se suscribió un nuevo plan de acción para el período 2012013 que resume los fructíferos intercambios entre empresarios y autoridades de ambos países .\n",
            "expl:pass\n",
            "\n",
            "loop: 5\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:impers', 0.27), ('expl:pv', 0.25), ('iobj', 0.15), ('obj', 0.06)]\n",
            "\n",
            "Pero el Lincoln de Spielberg no es lo que se suele referir a una película biográfica , dado que solo contempla su más glorioso momento .\n",
            "expl:impers\n",
            "\n",
            "loop: 5\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.28), ('obj', 0.26), ('iobj', 0.22), ('expl:pv', 0.18), ('expl:pass', 0.07)]\n",
            "\n",
            "El entrenador asturiano ya se lo comunicó a el futbolista venezolano pero todavía no ha logrado encontrar equipo .\n",
            "iobj\n",
            "\n",
            "loop: 5\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:pv', 0.26), ('obj', 0.17), ('expl:impers', 0.15), ('iobj', 0.14)]\n",
            "\n",
            "Cada vez que ellos venían con su ofrenda tenían que acordar se de donde dios los había sacado .\n",
            "expl:pv\n",
            "\n",
            "loop: 5\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('expl:pass', 0.27), ('obj', 0.23), ('expl:impers', 0.14), ('iobj', 0.07)]\n",
            "\n",
            "Con el tiempo , conforme la empresa familiar crece , sobre todo teniendo en cuenta la complejidad de el entorno se deben adquirir habilidades en finanzas , contabilidad , marketing , etc .\n",
            "expl:pass\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4889\u001b[0m      \u001b[32m0.3295\u001b[0m        \u001b[35m1.3655\u001b[0m  0.3679\n",
            "      2      \u001b[36m0.5300\u001b[0m      \u001b[32m0.4043\u001b[0m        \u001b[35m1.1464\u001b[0m  0.3640\n",
            "      3      \u001b[36m0.7086\u001b[0m      \u001b[32m0.6397\u001b[0m        \u001b[35m0.9367\u001b[0m  0.3608\n",
            "      4      \u001b[36m0.8079\u001b[0m      \u001b[32m0.7550\u001b[0m        \u001b[35m0.6130\u001b[0m  0.3650\n",
            "      5      \u001b[36m0.9228\u001b[0m      \u001b[32m0.9171\u001b[0m        \u001b[35m0.3341\u001b[0m  0.3589\n",
            "      6      \u001b[36m0.9750\u001b[0m      \u001b[32m0.9745\u001b[0m        \u001b[35m0.1778\u001b[0m  0.3584\n",
            "      7      \u001b[36m0.9914\u001b[0m      \u001b[32m0.9913\u001b[0m        \u001b[35m0.1037\u001b[0m  0.3655\n",
            "      8      \u001b[36m0.9957\u001b[0m      \u001b[32m0.9957\u001b[0m        \u001b[35m0.0668\u001b[0m  0.3546\n",
            "      9      \u001b[36m0.9968\u001b[0m      \u001b[32m0.9968\u001b[0m        \u001b[35m0.0465\u001b[0m  0.3592\n",
            "     10      \u001b[36m0.9980\u001b[0m      \u001b[32m0.9980\u001b[0m        \u001b[35m0.0341\u001b[0m  0.3659\n",
            "\n",
            "loop: 6\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('obj', 0.28), ('expl:pv', 0.27), ('expl:impers', 0.1), ('iobj', 0.06)]\n",
            "\n",
            "Como sea , gracias a Dios me acaban de confirmar que conseguí un empleo , se trata de un proyecto de 6 semanas , pero como están las cosas es mejor que nada .\n",
            "expl:impers\n",
            "\n",
            "loop: 6\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.27), ('iobj', 0.18), ('expl:pass', 0.17), ('obj', 0.11)]\n",
            "\n",
            "No se si los ' neutros ' tienen un plan .\n",
            "None\n",
            "\n",
            "loop: 6\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.27), ('iobj', 0.18), ('expl:pass', 0.17), ('obj', 0.11)]\n",
            "\n",
            "OPERACION Se debita : Por las partidas deudoras cuando se originan .\n",
            "None\n",
            "\n",
            "loop: 6\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.27), ('expl:impers', 0.26), ('iobj', 0.16), ('obj', 0.03)]\n",
            "\n",
            "La casa Prada fue creada en 1913 y pronto se hizo conocida por sus artículos de cuero de excelente calidad .\n",
            "expl:pv\n",
            "\n",
            "loop: 6\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('obj', 0.27), ('expl:pass', 0.26), ('expl:impers', 0.23), ('expl:pv', 0.12), ('iobj', 0.12)]\n",
            "\n",
            "Desde hace alrededor de 25 años que se comenzó a poblar la zona , han padecido varias inundaciones , que nos hablan de lo cierto de el dicho que dice que las aguas tienen memoria .\n",
            "expl:impers\n",
            "\n",
            "loop: 6\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.24), ('expl:pv', 0.24), ('iobj', 0.24), ('expl:impers', 0.2), ('obj', 0.08)]\n",
            "\n",
            "Puede estudiar se tanto desde el punto de vista antropológico , sociológico , económico o incluso moral .\n",
            "expl:pass\n",
            "\n",
            "loop: 6\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.28), ('iobj', 0.25), ('expl:pv', 0.24), ('expl:pass', 0.17), ('obj', 0.06)]\n",
            "\n",
            "Actitudes que me cargan , por lo que digo se porta pésimo : gritar , mentir , GOLPEAR , decir garabatos , responder mal ( asi pesado o de mala gana ) , manipular y ser egoista .\n",
            "expl:pv\n",
            "\n",
            "loop: 6\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('expl:pv', 0.28), ('expl:pass', 0.24), ('obj', 0.11), ('iobj', 0.09)]\n",
            "\n",
            "También asegúre se de que la cabeza de su pene y el prepucio no entren en contacto con la orina después de orinar .\n",
            "expl:pv\n",
            "\n",
            "loop: 6\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:pv', 0.25), ('obj', 0.18), ('expl:impers', 0.17), ('iobj', 0.11)]\n",
            "\n",
            "Esta descripción se apega más a el perfil de un ?\n",
            "expl:pv\n",
            "\n",
            "loop: 6\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:pv', 0.28), ('expl:impers', 0.22), ('obj', 0.14), ('iobj', 0.08)]\n",
            "\n",
            ", las actividades deportivas y recreativas , se trabaja muy fuerte en la parte psico pedagógica , con el propósito de lograr la autovaloración de cada uno de los niños .\n",
            "expl:impers\n",
            "\n",
            "loop: 6\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.24), ('expl:impers', 0.23), ('expl:pv', 0.2), ('iobj', 0.17), ('obj', 0.15)]\n",
            "\n",
            "y luego de decir que si , me puse a pensar .\n",
            "None\n",
            "\n",
            "loop: 6\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('iobj', 0.29), ('expl:impers', 0.25), ('expl:pass', 0.24), ('expl:pv', 0.21), ('obj', 0.02)]\n",
            "\n",
            "Los servicios de Competencia de Bruselas , encabezados por el español Joaquín Almunia , iniciaron su investigación hace cuatro años , a raíz de una denuncia .\n",
            "None\n",
            "\n",
            "loop: 6\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('expl:pv', 0.25), ('iobj', 0.24), ('obj', 0.15), ('expl:impers', 0.11)]\n",
            "\n",
            "[ E ] ntre 1976 y 1983 en Argentina se perpetraron una serie de actos , enmarcados en un plan común con fines delictivos , consistentes en exterminio , ejecuciones extrajudiciales , desapariciones forzosas , torturas , persecución basada en motivos ideas políticos y sindicales , y detenciones ilegales o arbitrarias ' . '\n",
            "expl:pass\n",
            "\n",
            "loop: 6\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.26), ('expl:pass', 0.26), ('expl:pv', 0.24), ('obj', 0.17), ('iobj', 0.07)]\n",
            "\n",
            "Leitao a Bairrada El plato conocido como Leitao a Bairrada es un lechón , un cochinillo asado que se prepara en una región llamada Bairrada .\n",
            "expl:pass\n",
            "\n",
            "loop: 6\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.27), ('expl:pass', 0.22), ('iobj', 0.18), ('obj', 0.06)]\n",
            "\n",
            "Nunca permita que alguien que no es comprometido a enseñar la Palabra de Dios se pare en el pulpito .\n",
            "expl:pv\n",
            "\n",
            "loop: 6\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.26), ('expl:pass', 0.26), ('expl:pv', 0.24), ('obj', 0.17), ('iobj', 0.07)]\n",
            "\n",
            "A dosis mayores se observan conductas de desinhibición y pérdida de control .\n",
            "expl:pass\n",
            "\n",
            "loop: 6\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:impers', 0.23), ('expl:pv', 0.21), ('obj', 0.17), ('iobj', 0.12)]\n",
            "\n",
            "( 3 ) Una precisión que vale la pena hacer : en los RAE figuran dos títulos de un mismo trabajo realizado por M. Luisa Talavera ( 1994 ) , en México , en el contexto de su Maestría en Educación ; uno de ellos tiene un título bastante sugerente para nuestro propósito : Cómo se inician los maestros en su profesión .\n",
            "expl:pv\n",
            "\n",
            "loop: 6\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('obj', 0.26), ('expl:pv', 0.24), ('expl:impers', 0.21), ('expl:pass', 0.21), ('iobj', 0.09)]\n",
            "\n",
            "Posteriormente lavar se con jabón y abundante agua .\n",
            "expl:pv\n",
            "\n",
            "loop: 6\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.29), ('expl:impers', 0.24), ('expl:pv', 0.24), ('iobj', 0.15), ('obj', 0.08)]\n",
            "\n",
            "La mayor aceptación que está teniendo la deuda pública española se debe , en parte , a la compra que están haciendo los inversores extranjeros : durante el primer trimestre de este año aumentaron su posición en bonos y obligaciones en aproximadamente 15.000 millones de euros .\n",
            "expl:pass\n",
            "\n",
            "loop: 6\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.27), ('iobj', 0.18), ('obj', 0.14), ('expl:impers', 0.12)]\n",
            "\n",
            "Soy una persona que nunca está conforme , una persona que se aburre muy rápido y mucho , entonces siempre me falta algo , soy una persona muy incompleta pero ahora sí estoy feliz .\n",
            "expl:pv\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.3804\u001b[0m      \u001b[32m0.3598\u001b[0m        \u001b[35m1.4045\u001b[0m  0.3764\n",
            "      2      \u001b[36m0.5410\u001b[0m      \u001b[32m0.4282\u001b[0m        \u001b[35m1.1519\u001b[0m  0.3732\n",
            "      3      \u001b[36m0.7151\u001b[0m      \u001b[32m0.6457\u001b[0m        \u001b[35m0.9397\u001b[0m  0.3732\n",
            "      4      \u001b[36m0.8094\u001b[0m      \u001b[32m0.7591\u001b[0m        \u001b[35m0.6313\u001b[0m  0.3682\n",
            "      5      \u001b[36m0.9143\u001b[0m      \u001b[32m0.9056\u001b[0m        \u001b[35m0.3626\u001b[0m  0.3697\n",
            "      6      \u001b[36m0.9728\u001b[0m      \u001b[32m0.9721\u001b[0m        \u001b[35m0.2006\u001b[0m  0.3696\n",
            "      7      \u001b[36m0.9886\u001b[0m      \u001b[32m0.9884\u001b[0m        \u001b[35m0.1185\u001b[0m  0.3596\n",
            "      8      \u001b[36m0.9937\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0765\u001b[0m  0.3637\n",
            "      9      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0531\u001b[0m  0.3639\n",
            "     10      \u001b[36m0.9971\u001b[0m      \u001b[32m0.9971\u001b[0m        \u001b[35m0.0388\u001b[0m  0.3619\n",
            "\n",
            "loop: 7\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('iobj', 0.24), ('expl:pass', 0.21), ('expl:impers', 0.2), ('expl:pv', 0.19), ('obj', 0.16)]\n",
            "\n",
            "Algunas veces el silencio de el vasto universo se cierne sobre nosotros envolviéndo nos .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('obj', 0.23), ('expl:impers', 0.21), ('expl:pv', 0.2), ('expl:pass', 0.18), ('iobj', 0.18)]\n",
            "\n",
            "Me acuerdo que había un viejo dirigente de el salitre que no se había perdido ninguna represión .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('iobj', 0.24), ('expl:pass', 0.21), ('expl:impers', 0.2), ('expl:pv', 0.19), ('obj', 0.16)]\n",
            "\n",
            "Nunca se dieron por perdidos incluso en los peores momentos .\n",
            "expl:pass\n",
            "\n",
            "loop: 7\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('expl:pv', 0.24), ('iobj', 0.2), ('obj', 0.2), ('expl:impers', 0.12)]\n",
            "\n",
            "Así como en Animales Sueltos conviven Coco Silly , Nicole Neumann y una mesa por donde pasan Gabriel Mariotto , Daniel Scioli o la calva osamenta de Tomás Bulat explicándo le a la señora qué es un fondo buitre , por el programa de Del Moro puede pasar , por caso , la vicejefa de gobierno de la Ciudad de Buenos Aires , María Eugenia Vidal , a someter se a preguntas tras las inundaciones .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.26), ('expl:pass', 0.26), ('expl:pv', 0.22), ('obj', 0.19), ('iobj', 0.06)]\n",
            "\n",
            "Durante la entrega de las unidades , el secretario de salud se refirió a la Norma Oficial Mexicana 041 ( NOM- 041 ) , que actualmente está en revisión , luego de recibir las observaciones de organizaciones civiles y personas interesadas en el tema .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.27), ('expl:impers', 0.19), ('obj', 0.15), ('iobj', 0.12)]\n",
            "\n",
            "Los mentores como camaradas educacionales : en este enfoque los mentores también auxilian a los profesores debutantes en sus problemas inmediatos , pero se forjan respecto a ellos fines profesionales a más largo plazo , tales como ayudar les a descubrir el pensamiento de el alumno y a desarrollar sólidas razones para fundamentar su actuar .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.25), ('obj', 0.2), ('expl:impers', 0.16), ('iobj', 0.14)]\n",
            "\n",
            "Moraleja , si tienes un arranque de artista pintes donde pintes no lo tires a la basura , en un futuro podría convertir se en una obra de arte .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.25), ('expl:impers', 0.24), ('obj', 0.24), ('expl:pass', 0.16), ('iobj', 0.11)]\n",
            "\n",
            "Nadie podía escapar de ella , ya que allí el Río de la Plata se vuelve bravo , intolerante y anchísimo y el Uruguay desagua con tanta fuerza que es imposible cruzar lo a nado .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.23), ('expl:impers', 0.19), ('obj', 0.18), ('iobj', 0.13)]\n",
            "\n",
            "Diríja se a la agencia donde realizó la apertura de el CDT en la fecha de vencimiento pactada .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('iobj', 0.27), ('expl:pv', 0.2), ('obj', 0.15), ('expl:impers', 0.11)]\n",
            "\n",
            "Murió de nuevo y ya se están aprender a hacer lo que quiero con premura .\n",
            "None\n",
            "\n",
            "loop: 7\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.26), ('expl:pass', 0.21), ('iobj', 0.21), ('obj', 0.04)]\n",
            "\n",
            "Hace poco me mudé fuera de mi país y vivo sola en un lugar nuevo sin amigos ni familiares cerca y todas las emociones que enfrento se agigantan sin poder contar con nadie con quien hablar para dejar escapar las poco a poco .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.26), ('iobj', 0.26), ('obj', 0.11), ('expl:impers', 0.1)]\n",
            "\n",
            "Supongo que se me pasará cuando acabe los exámenes .\n",
            "obj\n",
            "\n",
            "loop: 7\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('iobj', 0.26), ('obj', 0.25), ('expl:impers', 0.14), ('expl:pass', 0.08)]\n",
            "\n",
            "# O # N # P x # Para enviar el SMS anónimo , a la vez te notifique el mensaje enviado y a la vez retrase la recepción de el mensaje .\n",
            "None\n",
            "\n",
            "loop: 7\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('obj', 0.28), ('iobj', 0.25), ('expl:pass', 0.24), ('expl:impers', 0.13), ('expl:pv', 0.11)]\n",
            "\n",
            "Creo que se está volviendo más importante que nunca , asegura el profesor de seguridad e inteligencia en la Universidad Aeronáutica de Embry-Riddle ( Arizona , EE UU ) .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('obj', 0.27), ('iobj', 0.22), ('expl:pass', 0.17), ('expl:impers', 0.07)]\n",
            "\n",
            "Dani , yo no tengo la misma sensación que tú ; a mí no me parece que la blogosfera científica amateur se está desinflando últimamente .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.24), ('expl:impers', 0.21), ('iobj', 0.2), ('obj', 0.07)]\n",
            "\n",
            "Yo creo que la vida de un blog tiene un ciclo : el descubrimiento , la ilusión , el deslumbramiento cuando los lectores se cuentan por cientos o miles y , la depresión .\n",
            "expl:pass\n",
            "\n",
            "loop: 7\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('iobj', 0.23), ('expl:pass', 0.22), ('obj', 0.22), ('expl:impers', 0.04)]\n",
            "\n",
            "La oprimí contra mi corazón con inquietud y amor ; por eso se ha marchitado la flor .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:pv', 0.24), ('expl:impers', 0.21), ('iobj', 0.19), ('obj', 0.09)]\n",
            "\n",
            "saber como se llama , si tiene familia , como poder ayudar los efectivamente , ya que una moneda sólo parcha el día y no soluciona el fondo .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('obj', 0.28), ('expl:impers', 0.24), ('expl:pv', 0.21), ('expl:pass', 0.19), ('iobj', 0.08)]\n",
            "\n",
            "La orgullosa Jericó , cuyos muros se desplomaron con el sonar de las trompetas de los hebreos , era entonces un pobre caserío .\n",
            "expl:pv\n",
            "\n",
            "loop: 7\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('obj', 0.28), ('expl:impers', 0.17), ('iobj', 0.16), ('expl:pass', 0.11)]\n",
            "\n",
            "Las ballenas se pasan nadando todo el día , solo comen pescado y solo beben agua .\n",
            "expl:pv\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4234\u001b[0m      \u001b[32m0.4038\u001b[0m        \u001b[35m1.3919\u001b[0m  0.3914\n",
            "      2      \u001b[36m0.5564\u001b[0m      \u001b[32m0.4488\u001b[0m        \u001b[35m1.1423\u001b[0m  0.3714\n",
            "      3      \u001b[36m0.7154\u001b[0m      \u001b[32m0.6460\u001b[0m        \u001b[35m0.9200\u001b[0m  0.3686\n",
            "      4      \u001b[36m0.8018\u001b[0m      \u001b[32m0.7477\u001b[0m        \u001b[35m0.6054\u001b[0m  0.3640\n",
            "      5      \u001b[36m0.9201\u001b[0m      \u001b[32m0.9137\u001b[0m        \u001b[35m0.3397\u001b[0m  0.3677\n",
            "      6      \u001b[36m0.9699\u001b[0m      \u001b[32m0.9690\u001b[0m        \u001b[35m0.1887\u001b[0m  0.3667\n",
            "      7      \u001b[36m0.9875\u001b[0m      \u001b[32m0.9873\u001b[0m        \u001b[35m0.1134\u001b[0m  0.3694\n",
            "      8      \u001b[36m0.9929\u001b[0m      \u001b[32m0.9928\u001b[0m        \u001b[35m0.0744\u001b[0m  0.3617\n",
            "      9      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9960\u001b[0m        \u001b[35m0.0524\u001b[0m  0.3657\n",
            "     10      \u001b[36m0.9966\u001b[0m      \u001b[32m0.9966\u001b[0m        \u001b[35m0.0387\u001b[0m  0.3736\n",
            "\n",
            "loop: 8\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.23), ('expl:impers', 0.22), ('expl:pv', 0.19), ('iobj', 0.18), ('obj', 0.18)]\n",
            "\n",
            "Sin embargo para muchos se trato de una complicación , sobre todo a la hora de encontrar la ubicación de las nuevas funciones .\n",
            "expl:impers\n",
            "\n",
            "loop: 8\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('obj', 0.29), ('expl:pass', 0.19), ('iobj', 0.17), ('expl:impers', 0.06)]\n",
            "\n",
            "el video nos muestra como trabajar por competencias , as competencias tienen la función de desarrollar habilidades , todos los seres humanos tenemos ya funciones determinadas desde antes de nacer La competencia crea a un estudiante autónomo , capaz de autorealizar se en su vida .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('expl:pv', 0.26), ('obj', 0.18), ('expl:impers', 0.15), ('iobj', 0.15)]\n",
            "\n",
            "Las canciones tienen la fuerza precisa para valer se por sí mismas sin depender las unas de las otras , logrando que el conjunto ( valga la redundancia ) sirva de obra maestra para futuras formaciones que están por llegar .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('obj', 0.28), ('expl:impers', 0.23), ('expl:pv', 0.2), ('iobj', 0.17), ('expl:pass', 0.12)]\n",
            "\n",
            "Los gobernadores que más se le acercan son el kirchnerista Scioli y la única mandataria provincial de ARI , Fabiana Ríos , que ganan 12.000 pesos de bolsillo .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('obj', 0.23), ('expl:impers', 0.19), ('iobj', 0.18), ('expl:pass', 0.11)]\n",
            "\n",
            "En esta ocasión es muy diferente ( a lo sucedido en el Campeonato Mundial Sub7 de Perú ) es Chivas y jugar una Final con Chivas en el torneo que sea , no se da todos los días , afirma con su serenidad característica Edgar Mejía Viruete .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('obj', 0.28), ('iobj', 0.23), ('expl:pass', 0.2), ('expl:pv', 0.2), ('expl:impers', 0.09)]\n",
            "\n",
            "[ 5 ] La Confederación lanzó la primera ola de ataque , y los Jedi y sus fuerzas clones se vieron obligadas a retroceder .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:impers', 0.28), ('expl:pass', 0.26), ('iobj', 0.09), ('obj', 0.08)]\n",
            "\n",
            "El posterior suicidio de el joven se ha atríbuido a el hecho de la forzada separación .\n",
            "expl:pass\n",
            "\n",
            "loop: 8\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('iobj', 0.24), ('expl:pv', 0.23), ('expl:impers', 0.21), ('obj', 0.08)]\n",
            "\n",
            "Como podemos observar en el video la diferencia de educación actual y la educación tradicional ha tenido cambios pero esos cambios se deben aplicar en la escuela primaria y la secundaria .\n",
            "expl:pass\n",
            "\n",
            "loop: 8\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.26), ('expl:pass', 0.25), ('iobj', 0.12), ('obj', 0.11)]\n",
            "\n",
            "Consultado sobre la recepción de denuncias por intento de coimas por parte de los inspectores , Legarreta confirmó que durante 2013 se han recibido denuncias aunque dijo no recordar el número exacto de las mismas .\n",
            "expl:pass\n",
            "\n",
            "loop: 8\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.29), ('expl:pv', 0.28), ('expl:impers', 0.26), ('iobj', 0.15), ('obj', 0.03)]\n",
            "\n",
            "La orientación es el ángulo con el que el cuerpo está dirigido a los demás ( uno puede poner se frente a frente , en ángulo recto , o de espaldas ) .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('obj', 0.28), ('expl:pass', 0.22), ('expl:impers', 0.11), ('iobj', 0.1)]\n",
            "\n",
            "En las visitas puerta a puerta que realizan los profesionales de Policía adscritos a el Gaula y debidamente uniformados , entregarán calcomanías alusivas a la campaña y los números de celular para comunicación directa , entre los que se encuentra el 314-714-6502 y 31288-3141 .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.29), ('expl:pv', 0.24), ('iobj', 0.21), ('expl:impers', 0.18), ('obj', 0.08)]\n",
            "\n",
            "Sí , todo el tiempo , muchísimo , pero sufrí , me parece , porque siempre fui la que se puso los pantalones en todas las relaciones que tuve y además porque tengo una idea muy idealista de el amor .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('expl:impers', 0.24), ('expl:pass', 0.24), ('obj', 0.23), ('iobj', 0.0)]\n",
            "\n",
            "FXstreet.es declina cualquier responsabilidad legal por cualquier pérdida o perjuicio incluyendo , a título enunciativo y no limitativo , pérdidas o beneficios que puedan derivar se directa o indirectamente de el uso de esta información o de la confianza depositada en ella .\n",
            "expl:pass\n",
            "\n",
            "loop: 8\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('obj', 0.27), ('expl:pass', 0.24), ('iobj', 0.12), ('expl:impers', 0.09)]\n",
            "\n",
            "a y gracias a Charlie que parece que fue el que lo puso en faceboock lo de que estaba en el corte ingles , yo no se exactamente en pagina de el faceboock de monster high lo vi porque hay muchas así que si dice que es de él .\n",
            "None\n",
            "\n",
            "loop: 8\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.26), ('iobj', 0.26), ('obj', 0.26), ('expl:impers', 0.13), ('expl:pv', 0.1)]\n",
            "\n",
            "La estimulación eléctrica de esta zona produce movimientos similares a los de el área motora primaria pero se necesita estimulación más intensa para producir el mismo grado de movimiento .\n",
            "expl:pass\n",
            "\n",
            "loop: 8\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('expl:pass', 0.27), ('iobj', 0.24), ('obj', 0.18), ('expl:impers', 0.02)]\n",
            "\n",
            "El francés , uno de los tres primeros candidatos para sustituir a Mark Webber en Red Bull , se ha caído de la lista y desde Faenza y Milton Keynes han afirmado que seguramente continuará una temporada más en el equipo italiano .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('obj', 0.25), ('expl:impers', 0.23), ('expl:pass', 0.14), ('iobj', 0.12)]\n",
            "\n",
            "Me es difícil estar sentado porque se me acalambra la pierna derecha , _seguro no estiré bien_ , y el uso de un short inadecuado me produjo una paspadura en el interior de los muslos .\n",
            "obj\n",
            "\n",
            "loop: 8\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('expl:pv', 0.27), ('iobj', 0.18), ('obj', 0.16), ('expl:impers', 0.12)]\n",
            "\n",
            "En los últimos años , la bacteria ha viajado por diferentes países de Europa e incluso la cepa ha mutado haciéndo se resistente a los antibióticos .\n",
            "expl:pv\n",
            "\n",
            "loop: 8\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.28), ('iobj', 0.18), ('obj', 0.14), ('expl:impers', 0.11)]\n",
            "\n",
            "martes , 22 de noviembre de 2011 Está establecido que el 93 % de los municipios de el país , no cuentan con una ley que respalde , la plena delimitación de su jurisdicción El tema de los límites enfrenta a pueblos , a departamentos y municipios en las ciudades como es el caso de los contenciosos que hace años se discute entre La Paz y las alcaldías de Palca , Mecapaca , Achocalla y Coroico .\n",
            "expl:pass\n",
            "\n",
            "loop: 8\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.3), ('iobj', 0.25), ('expl:pass', 0.21), ('obj', 0.14), ('expl:impers', 0.1)]\n",
            "\n",
            "Se hace insostenible el nivel de egocentrismo de la fase anterior .\n",
            "expl:pv\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4624\u001b[0m      \u001b[32m0.3252\u001b[0m        \u001b[35m1.3779\u001b[0m  0.3740\n",
            "      2      \u001b[36m0.5438\u001b[0m      \u001b[32m0.4280\u001b[0m        \u001b[35m1.1396\u001b[0m  0.3646\n",
            "      3      \u001b[36m0.7079\u001b[0m      \u001b[32m0.6374\u001b[0m        \u001b[35m0.9266\u001b[0m  0.3691\n",
            "      4      \u001b[36m0.8080\u001b[0m      \u001b[32m0.7522\u001b[0m        \u001b[35m0.6145\u001b[0m  0.3622\n",
            "      5      \u001b[36m0.9163\u001b[0m      \u001b[32m0.9084\u001b[0m        \u001b[35m0.3437\u001b[0m  0.3591\n",
            "      6      \u001b[36m0.9717\u001b[0m      \u001b[32m0.9709\u001b[0m        \u001b[35m0.1869\u001b[0m  0.3670\n",
            "      7      \u001b[36m0.9870\u001b[0m      \u001b[32m0.9868\u001b[0m        \u001b[35m0.1110\u001b[0m  0.3655\n",
            "      8      \u001b[36m0.9926\u001b[0m      \u001b[32m0.9926\u001b[0m        \u001b[35m0.0728\u001b[0m  0.3633\n",
            "      9      \u001b[36m0.9960\u001b[0m      \u001b[32m0.9960\u001b[0m        \u001b[35m0.0511\u001b[0m  0.3622\n",
            "     10      \u001b[36m0.9963\u001b[0m      \u001b[32m0.9963\u001b[0m        \u001b[35m0.0377\u001b[0m  0.3647\n",
            "\n",
            "loop: 9\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('obj', 0.26), ('expl:impers', 0.2), ('iobj', 0.17), ('expl:pass', 0.1)]\n",
            "\n",
            "En el hotel de concentración de la selección guatemalteca tuvimos la oportunidad de conversar con Gary Stempel , quien conoce bien el fútbol panameño , y aseguró que ve como favorito a el equipo canalero para llevar se el boleto directo .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.29), ('expl:impers', 0.26), ('expl:pv', 0.25), ('obj', 0.12), ('iobj', 0.08)]\n",
            "\n",
            "El dolor en el pecho despues de comer se debe usualmente a reflujo gastrointestinal .\n",
            "expl:pass\n",
            "\n",
            "loop: 9\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('expl:pass', 0.29), ('expl:pv', 0.18), ('iobj', 0.13), ('obj', 0.12)]\n",
            "\n",
            "La convocatoria es a parar se frente a las Catedrales de dichas ciudades , impidiendo el paso de quienes busquen la profanación de los Templos , mientras dure el intento de dañar y profanar cada Catedral .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.27), ('obj', 0.26), ('expl:impers', 0.23), ('iobj', 0.18), ('expl:pv', 0.05)]\n",
            "\n",
            "A las 17:30 entraba por la puerta pensando en cómo la gente no se daba la vuelta en el mismo parking , si es que los coches estaban parados con los maridos a el volante , mientras las mujeres hacían la compra ( un tópico , pero cierto ) .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.28), ('expl:pass', 0.22), ('obj', 0.22), ('expl:pv', 0.21), ('iobj', 0.06)]\n",
            "\n",
            "En 1776 , Fray Íñigo Abbad y Lasierra en su descripción de los pueblos de la isla , se menciona como la nueva ciudad de San Carlos de Aguadilla .\n",
            "expl:pass\n",
            "\n",
            "loop: 9\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('obj', 0.27), ('expl:pass', 0.22), ('expl:impers', 0.15), ('iobj', 0.07)]\n",
            "\n",
            "Ante estas decisiones , Viviana y otros abogados de derechos humanos han solicitado se abra juicio político a tres jueces de esta Cámara por otorgar libertades y excarcelaciones a responsables de crímenes contra la humanidad .\n",
            "expl:pass\n",
            "\n",
            "loop: 9\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:impers', 0.24), ('expl:pv', 0.23), ('iobj', 0.22), ('obj', 0.03)]\n",
            "\n",
            "Es extraño que los empresarios tributen como mileuristas , o que el Banco de España se entere siempre el último de el agujero de las entidades que vigila o que el Gobierno crea hoy que beneficia a España no privatizar las Loterías cuando el martes pensaba lo contrario .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:impers', 0.25), ('iobj', 0.23), ('expl:pv', 0.2), ('obj', 0.04)]\n",
            "\n",
            "Inscríbase a un gimnasio .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.25), ('expl:pv', 0.25), ('iobj', 0.2), ('expl:impers', 0.17), ('obj', 0.12)]\n",
            "\n",
            "La última partida de 30 barcazas se despachó con documentos falsificados ( proveídos por firmas vinculadas a el mismo grupo con sede en Bahamas ) , según lo reconocieron en un juicio abreviado .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('iobj', 0.29), ('expl:impers', 0.28), ('expl:pv', 0.25), ('expl:pass', 0.15), ('obj', 0.03)]\n",
            "\n",
            "Pero hace tiempo que el campesino se está despertando .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('iobj', 0.25), ('expl:pv', 0.21), ('expl:impers', 0.13), ('obj', 0.13)]\n",
            "\n",
            "cuando nadie los mira , se animan y trotan un poquito .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.24), ('iobj', 0.22), ('obj', 0.21), ('expl:impers', 0.19), ('expl:pass', 0.14)]\n",
            "\n",
            "24 de febrero de 2012 Y aconteció que mientras la multitud se agolpaba sobre El para oír la palabra de Dios , estando Jesús junto a el lago de Genesaret , vio dos barcas que estaban a la orilla de el lago , pero los pescadores habían bajado de ellas y lavaban las redes .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:pv', 0.26), ('obj', 0.25), ('expl:impers', 0.15), ('iobj', 0.06)]\n",
            "\n",
            "Las competencias tienen la función de desarrollar habilidades , todos los seres humanos tenemos ya funciones determinadas desde antes de nacer La competencia crea a un estudiante autónomo Las habilidades se enseñan por medio de los procedimientos .\n",
            "expl:pass\n",
            "\n",
            "loop: 9\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('obj', 0.23), ('expl:impers', 0.22), ('expl:pass', 0.18), ('iobj', 0.1)]\n",
            "\n",
            "La Pasantía Curricular Supervisada de la Itaipu Binacional tienen como objetivo colaborar en la formación y capacitación de Recursos Humanos que se integraran a la mano de obra productiva de el país , mediante la promoción de actividades de integración y formación general , respecto a la Itaipu y las prácticas fundamentales de la especialidad .\n",
            "expl:pass\n",
            "\n",
            "loop: 9\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:pv', 0.27), ('iobj', 0.17), ('expl:impers', 0.16), ('obj', 0.12)]\n",
            "\n",
            "La vigilancia , lícita o ilícita , se ha incrementado en proporción directa a la mejora de la tecnología , reducción de costos y capacidad de procesamiento que permite manejar volúmenes inmensos de información ; además de las prácticas ' tradicionales ' de interceptación y captación de llamadas telefónicas o apertura de la correspondencia , hoy es posible , monitorear el Internet y seguir millones de transacciones económicas .\n",
            "expl:pass\n",
            "\n",
            "loop: 9\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('obj', 0.28), ('expl:pass', 0.23), ('expl:pv', 0.15), ('iobj', 0.05)]\n",
            "\n",
            "Por su parte , Imbernón ( 1994 ) , incluyendo también la situación española , agrega que , a la fecha , existía amplia bibliografía sobre la problemática de el profesorado novel y de su proceso de socialización profesional , constituyéndo se la investigación al respecto como uno de los temas más trabajados en el campo de la formación de el profesorado .\n",
            "expl:pass\n",
            "\n",
            "loop: 9\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.26), ('expl:impers', 0.21), ('iobj', 0.12), ('obj', 0.12)]\n",
            "\n",
            "Que se centraran en conseguir ventas .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.28), ('expl:impers', 0.16), ('iobj', 0.16), ('obj', 0.1)]\n",
            "\n",
            "que luchen por la gloria , que pongamos huevo y corazon y que asi las cosas se darán .\n",
            "expl:pv\n",
            "\n",
            "loop: 9\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('expl:pv', 0.24), ('expl:pass', 0.17), ('obj', 0.17), ('iobj', 0.12)]\n",
            "\n",
            "lunes , 12 de agosto de 2013 UN SALARIO DE ESCANDALO Dice un sabio y castizo refran , que se coge mas pronto a un mentiroso que a un cojo .\n",
            "expl:impers\n",
            "\n",
            "loop: 9\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.27), ('iobj', 0.21), ('expl:impers', 0.14), ('obj', 0.09)]\n",
            "\n",
            "La política y los programas políticos se toman demasiado en serio a sí mismos .\n",
            "expl:pv\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4429\u001b[0m      \u001b[32m0.3990\u001b[0m        \u001b[35m1.3730\u001b[0m  0.3801\n",
            "      2      \u001b[36m0.5377\u001b[0m      \u001b[32m0.4215\u001b[0m        \u001b[35m1.1471\u001b[0m  0.3769\n",
            "      3      \u001b[36m0.7109\u001b[0m      \u001b[32m0.6419\u001b[0m        \u001b[35m0.9366\u001b[0m  0.3783\n",
            "      4      \u001b[36m0.8133\u001b[0m      \u001b[32m0.7638\u001b[0m        \u001b[35m0.6138\u001b[0m  0.3722\n",
            "      5      \u001b[36m0.9199\u001b[0m      \u001b[32m0.9127\u001b[0m        \u001b[35m0.3450\u001b[0m  0.3866\n",
            "      6      \u001b[36m0.9691\u001b[0m      \u001b[32m0.9681\u001b[0m        \u001b[35m0.1943\u001b[0m  0.3723\n",
            "      7      \u001b[36m0.9873\u001b[0m      \u001b[32m0.9872\u001b[0m        \u001b[35m0.1176\u001b[0m  0.3776\n",
            "      8      \u001b[36m0.9935\u001b[0m      \u001b[32m0.9935\u001b[0m        \u001b[35m0.0774\u001b[0m  0.3735\n",
            "      9      \u001b[36m0.9958\u001b[0m      \u001b[32m0.9958\u001b[0m        \u001b[35m0.0544\u001b[0m  0.3758\n",
            "     10      \u001b[36m0.9966\u001b[0m      \u001b[32m0.9966\u001b[0m        \u001b[35m0.0401\u001b[0m  0.3776\n",
            "\n",
            "loop: 10\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.29), ('expl:pv', 0.28), ('iobj', 0.19), ('obj', 0.17), ('expl:impers', 0.07)]\n",
            "\n",
            "Hasta el momento los funcionario capitalinos no se han pronunciado sobre el asunto .\n",
            "expl:pv\n",
            "\n",
            "loop: 10\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('expl:pass', 0.27), ('obj', 0.2), ('iobj', 0.14), ('expl:impers', 0.11)]\n",
            "\n",
            "Y lo más probable es que se lo van a decir a ella .\n",
            "iobj\n",
            "\n",
            "loop: 10\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.22), ('iobj', 0.22), ('expl:impers', 0.18), ('obj', 0.09)]\n",
            "\n",
            "Entonces , que el pueblo vote y después se verá cuál es el resultado electoral .\n",
            "expl:impers\n",
            "\n",
            "loop: 10\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.27), ('expl:pv', 0.26), ('iobj', 0.24), ('expl:pass', 0.14), ('obj', 0.09)]\n",
            "\n",
            "También puede referir se a una sobrevaloración erótica de una parte de el cuerpo humano , como cabellos , el pie , etcétera .\n",
            "expl:pv\n",
            "\n",
            "loop: 10\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl:pass', 0.28), ('expl:impers', 0.27), ('iobj', 0.22), ('expl:pv', 0.15), ('obj', 0.08)]\n",
            "\n",
            "No obstante , hasta 2009 sólo se había cubierto el 7.5 por ciento de las mujeres asintomáticas de entre 40 y 69 años , edad establecida en la Norma Oficial Mexicana ( NOM- 041 ) para la prevención , diagnóstico , tratamiento , control y vigilancia epidemiológica de el cáncer de mama .\n",
            "expl:pass\n",
            "\n",
            "loop: 10\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('expl:pass', 0.26), ('expl:impers', 0.25), ('obj', 0.13), ('iobj', 0.08)]\n",
            "\n",
            "A fin de disponer de un contraste polémicamente útil entre « concepto y « metáfora se tendría que suponer que los conceptos tienen necesariamente un significado literal , y luego concebir este significado como un significado sólo posible en virtud de mostración ( mostrar un objeto sensible o inteligible a la consciencia , evocar lo que el concepto significa para la mente v nombrar lo ) .\n",
            "expl:impers\n",
            "\n",
            "loop: 10\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.27), ('expl:pass', 0.26), ('iobj', 0.23), ('obj', 0.14), ('expl:impers', 0.1)]\n",
            "\n",
            "Y cuando se trata de querer a una familia grande o pequeña , bueno , ella tiene una respuesta muy simple .\n",
            "expl:impers\n",
            "\n",
            "loop: 10\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.28), ('obj', 0.28), ('expl:pass', 0.2), ('expl:impers', 0.19), ('iobj', 0.06)]\n",
            "\n",
            "Hoy se da la situación en Catalunya que el tipo de música que hacemos con Mishima ha llegado a un cierto punto de madurez o de etapa clásica .\n",
            "expl:pv\n",
            "\n",
            "loop: 10\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('obj', 0.29), ('expl:pv', 0.22), ('iobj', 0.19), ('expl:pass', 0.17), ('expl:impers', 0.13)]\n",
            "\n",
            "Está disponible para la Evolution 1 y para la Evolution 2 cuando se libere una nueva beta de esta plataforma .\n",
            "expl:pass\n",
            "\n",
            "loop: 10\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('obj', 0.29), ('expl:pass', 0.27), ('expl:impers', 0.25), ('iobj', 0.1), ('expl:pv', 0.09)]\n",
            "\n",
            "Mañana mi marido se lo llevará dándo les las gracias por todo el cariño que les dan a mis hijos .\n",
            "iobj\n",
            "\n",
            "loop: 10\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('expl:pv', 0.29), ('expl:pass', 0.25), ('iobj', 0.12), ('obj', 0.05)]\n",
            "\n",
            "Sucede que la primera surgía a el calor de reuniones con amigos , cuando se habla con excitación y pasión de algo que a uno lo moviliza .\n",
            "expl:impers\n",
            "\n",
            "loop: 10\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('obj', 0.29), ('expl:pass', 0.17), ('iobj', 0.16), ('expl:pv', 0.09)]\n",
            "\n",
            "Hay mucho que se aprecia sobre este canal a través de Centroamérica y aquí están algunas cosas que todos deben saber sobre él .\n",
            "expl:pass\n",
            "\n",
            "loop: 10\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('expl:pv', 0.26), ('obj', 0.23), ('expl:pass', 0.2), ('iobj', 0.03)]\n",
            "\n",
            "Así fue , entonces , que luego de numerosas reuniones se llegó a un acuerdo para coordinar de la manera más amable las distintas estrategias comerciales .\n",
            "expl:impers\n",
            "\n",
            "loop: 10\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.24), ('iobj', 0.17), ('expl:impers', 0.16), ('obj', 0.13)]\n",
            "\n",
            "Además es una cuestión mucho mayor que no cabe aproximar se a ella en un blog sobre telenovelas .\n",
            "expl:pv\n",
            "\n",
            "loop: 10\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('obj', 0.28), ('expl:pass', 0.18), ('expl:impers', 0.13), ('iobj', 0.11)]\n",
            "\n",
            "Esto resta fuerza a la hipótesis , aunque a mi mismo se me podrían ocurrir algunos aunque podría ser que .\n",
            "obj\n",
            "\n",
            "loop: 10\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('iobj', 0.25), ('expl:pv', 0.24), ('expl:pass', 0.19), ('obj', 0.02)]\n",
            "\n",
            "Algunas de las características de seguridad deben activar se manualmente y las que funcionan por defecto requieren una doble comprobación .\n",
            "expl:pass\n",
            "\n",
            "loop: 10\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl:impers', 0.29), ('expl:pv', 0.29), ('expl:pass', 0.24), ('iobj', 0.17), ('obj', 0.01)]\n",
            "\n",
            "1 y 2 268 - Son los principales cursos de acción que se eligen e instrumentan para alcanzar uno a más objetivos a .\n",
            "expl:pass\n",
            "\n",
            "loop: 10\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('obj', 0.29), ('expl:pv', 0.27), ('expl:pass', 0.25), ('expl:impers', 0.11), ('iobj', 0.09)]\n",
            "\n",
            "Recordemos que había un rey que se llamaba Nabucodonosor , que escuchó el consejo de Daniel y prosperó .\n",
            "expl:pv\n",
            "\n",
            "loop: 10\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.29), ('expl:pass', 0.25), ('obj', 0.25), ('expl:impers', 0.16), ('iobj', 0.04)]\n",
            "\n",
            "Utiliza mil excusas para no salir a saludar y cuando no le queda más remedio que hacer lo , tiembla como un flan actúa torpemente y se queda parado en un rincón sin abrir la boca .\n",
            "expl:pv\n",
            "\n",
            "loop: 10\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl:pv', 0.3), ('expl:impers', 0.27), ('expl:pass', 0.26), ('obj', 0.15), ('iobj', 0.02)]\n",
            "\n",
            "De este modo los que mejor puntúan en el juego ( los mejor adaptados ) son los que más se reproducen ( éxito reproductor ) y pasan su comportamiento ( sus genes ) a la siguiente generación .\n",
            "expl:pv\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4407\u001b[0m      \u001b[32m0.3298\u001b[0m        \u001b[35m1.3895\u001b[0m  0.3800\n",
            "      2      \u001b[36m0.5305\u001b[0m      \u001b[32m0.4034\u001b[0m        \u001b[35m1.1467\u001b[0m  0.3768\n",
            "      3      \u001b[36m0.7103\u001b[0m      \u001b[32m0.6398\u001b[0m        \u001b[35m0.9219\u001b[0m  0.3735\n",
            "      4      \u001b[36m0.8124\u001b[0m      \u001b[32m0.7622\u001b[0m        \u001b[35m0.5991\u001b[0m  0.3754\n",
            "      5      \u001b[36m0.9183\u001b[0m      \u001b[32m0.9107\u001b[0m        \u001b[35m0.3391\u001b[0m  0.3756\n",
            "      6      \u001b[36m0.9687\u001b[0m      \u001b[32m0.9677\u001b[0m        \u001b[35m0.1882\u001b[0m  0.3745\n",
            "      7      \u001b[36m0.9869\u001b[0m      \u001b[32m0.9867\u001b[0m        \u001b[35m0.1118\u001b[0m  0.3761\n",
            "      8      \u001b[36m0.9927\u001b[0m      \u001b[32m0.9927\u001b[0m        \u001b[35m0.0728\u001b[0m  0.3776\n",
            "      9      \u001b[36m0.9952\u001b[0m      \u001b[32m0.9952\u001b[0m        \u001b[35m0.0510\u001b[0m  0.3769\n",
            "     10      \u001b[36m0.9969\u001b[0m      \u001b[32m0.9969\u001b[0m        \u001b[35m0.0376\u001b[0m  0.3774\n"
          ]
        }
      ],
      "source": [
        "for i in range(number_of_loops):\n",
        "\n",
        "    # query new instances\n",
        "    query_idx, query_inst = learner.query(X_pool, n_instances=n_instances)\n",
        "    predicted_proba = get_learners_preds(learner.predict_proba(X_pool[query_idx]))\n",
        "    sentences = pool.text.iloc[query_idx]\n",
        "\n",
        "    # annotate the queried instances\n",
        "    annotation = list()\n",
        "    counter = 0\n",
        "    for sent, proba in zip(sentences, predicted_proba):\n",
        "        counter += 1\n",
        "        sorted_proba = sorted(proba.items(), key=lambda kv: kv[1], reverse=True)\n",
        "        prompt = '\\n'+'loop: '+str(i+1)+'\\n'+'sentence: '+str(counter)+'\\n'+'The learners predictions are:'+'\\n'+str(sorted_proba)+'\\n\\n'+sent+'\\n'\n",
        "        label = str(input(prompt))\n",
        "        annotation.append(label)\n",
        "\n",
        "    # keep track of annotations\n",
        "    sent_list = sentences.to_list()\n",
        "    pool_sent_list.append(sent_list)\n",
        "    pool_label_list.append(annotation)\n",
        "\n",
        "    # filter out sentences that were assigned 'None'; the learner should not see them\n",
        "    if 'None' in annotation:\n",
        "        print('Note: you either discarded samples or did not annotate all samples')\n",
        "        discarded_idxs=[idx for idx, sample in enumerate(annotation) if sample == 'None'] # TODO\n",
        "        discarded_idxs = sorted(discarded_idxs, reverse=True)\n",
        "        for index in discarded_idxs:\n",
        "            query_inst = np.delete(query_inst, index, axis=0)\n",
        "        annotation = list(filter('None'.__ne__, annotation))\n",
        "\n",
        "\n",
        "    # teach the learner\n",
        "    y_pool = label_encoder.transform(annotation)\n",
        "    learner.teach(query_inst, y_pool)\n",
        "    accuracies.append(learner.score(X=test_features, y=test_labels))\n",
        "\n",
        "    # delete queried instances from pool\n",
        "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "ekLqvEGEniwD",
        "outputId": "33ba6bd3-b279-4cc6-e46b-945e6f6ed38d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "with plt.style.context('bmh'):\n",
        "    csfont = {'fontname':'Times New Roman'}\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(range(number_of_loops+1), accuracies)\n",
        "    plt.scatter(range(number_of_loops+1), accuracies)\n",
        "    plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20, **csfont)\n",
        "    plt.xticks(np.arange(0, 11, 1), fontsize=20, **csfont)\n",
        "    plt.xlabel('loop number',fontsize=24, **csfont)\n",
        "    plt.ylabel('accuracy',fontsize=24, **csfont)\n",
        "    plt.savefig('/content/drive/MyDrive/Colab Notebooks/es_pytorch.png')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhOsoqwmniwE",
        "outputId": "f9bf2f4f-b661-483d-e8f4-20c2c23364e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5623529411764706"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(accuracies)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT7ALb21niwE",
        "outputId": "ad9fa213-c82c-4154-e166-1f3d30ae51e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 2)\n",
            "                                                text   se_label\n",
            "0  En definitiva , los compradores ( y presumible...       iobj\n",
            "1  Una respuesta a Bebedores de vino se alimentan...       expl\n",
            "2  Freud sabía con antelación que , si Valéry no ...       expl\n",
            "3  En este momento no se permiten comentarios , p...  expl:pass\n",
            "4  La sociología positivista de la ciencia no se ...       expl\n"
          ]
        }
      ],
      "source": [
        "# create df from annotations\n",
        "sent_flattened = get_flattened_list(pool_sent_list)\n",
        "label_flattened = get_flattened_list(pool_label_list)\n",
        "\n",
        "labeled_pool = pd.DataFrame(list(zip(sent_flattened, label_flattened)),\n",
        "               columns =['text', 'se_label'])\n",
        "print(labeled_pool.shape)\n",
        "print(labeled_pool.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "24y3gUVdniwE"
      },
      "outputs": [],
      "source": [
        "# save labeled pool\n",
        "labeled_pool.to_csv('/content/drive/MyDrive/Colab Notebooks/es_pytorch_annotations.txt', header=None, index=False,  sep='\\t')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "X6DcSBGOniv2",
        "gonCBBoWniv4",
        "t-mX19N0niv6"
      ],
      "name": "es_pytorch_active_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}