{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxhof905/se_corpus/blob/main/task/scripts/pt_pytorch_active_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "I1ryVWjsp2C7"
      },
      "source": [
        "# Pytorch active learning loop: Portuguese\n",
        "\n",
        "maxhof905"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh6mUpU9p2C7"
      },
      "source": [
        "\n",
        "sources :\n",
        "- https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
        "- https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_lstm_neuralnetwork/#step-2-make-dataset-iterable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yCVhFC4p55R",
        "outputId": "ab81bdef-7dae-49eb-c160-6db4b56c5b9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Imports"
      ],
      "metadata": {
        "id": "hNzOCU1A9n8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkjctjBXp2C-",
        "outputId": "f05403fd-9498-463b-f110-297a4b1536af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-0.11.0-py3-none-any.whl (155 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 30 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 40 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 51 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 61 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 71 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 81 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 102 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 112 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 122 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 133 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 143 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 153 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 155 kB 11.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.1.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.11.0\n",
            "Collecting modal\n",
            "  Downloading modAL-0.4.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from modal) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from modal) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.7/dist-packages (from modal) (1.4.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from modal) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modal) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->modal) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->modal) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modal) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->modal) (1.1.0)\n",
            "Installing collected packages: modal\n",
            "Successfully installed modal-0.4.1\n"
          ]
        }
      ],
      "source": [
        "# installations for colab\n",
        "!pip install skorch\n",
        "!pip install modal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1-JVl-aXp2C_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.callbacks import EpochScoring\n",
        "\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcT5QKYzp2DA"
      },
      "source": [
        "## 2) helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mmsVMbmWp2DA"
      },
      "outputs": [],
      "source": [
        "def get_class_dist(df_col):\n",
        "    \"\"\"\n",
        "    plot label distribution\n",
        "    \"\"\"\n",
        "    data = df_col.value_counts(normalize=True).rename('percentage').mul(100).reset_index().rename(columns = {\"index\":\"label\"})\n",
        "    plot = sns.barplot(x=\"label\", y=\"percentage\", data=data)\n",
        "    plot.set_xticklabels(plot.get_xticklabels(),\n",
        "                          rotation=90,\n",
        "                          horizontalalignment='right')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wgEsHgdwp2DB"
      },
      "outputs": [],
      "source": [
        "def get_balanced_set(df):\n",
        "    \"\"\"\n",
        "    create balanced data set (oversampling)\n",
        "    \"\"\"\n",
        "    max_size = df['se_label'].value_counts().max()\n",
        "    balanced_list = [df]\n",
        "    for class_index, group in df.groupby('se_label'):\n",
        "        balanced_list.append(group.sample(max_size-len(group), replace=True))\n",
        "    return pd.concat(balanced_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "u9u1sAApp2DB"
      },
      "outputs": [],
      "source": [
        "def get_flattened_list(nested_list):\n",
        "    return [item for sublist in nested_list for item in sublist]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1TjQU0TGp2DB"
      },
      "outputs": [],
      "source": [
        "def get_learners_preds(prediction_proba):\n",
        "    \"\"\"\n",
        "    return the learners predictions as a dict with labels as keys and the probabilities as values\n",
        "    :param prediction_proba: values obtained from learner.predict()\n",
        "    :return: dict with probability per label\n",
        "    \"\"\"\n",
        "    prediction_proba = np.round(prediction_proba, 2)\n",
        "    prediction_list = list()\n",
        "    for i in range(len(prediction_proba)):\n",
        "        predictions = {'expl': prediction_proba[i][0], 'fixed': prediction_proba[i][1],\n",
        "                      'iobj': prediction_proba[i][2], 'mark': prediction_proba[i][3], \n",
        "                       'nsubj': prediction_proba[i][4], 'obj': prediction_proba[i][5]}\n",
        "        prediction_list.append(predictions)\n",
        "    return prediction_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qoyt9cOp2DD"
      },
      "source": [
        "## 3) load and preprocess data\n",
        "- initial_train: labeled test set ('seed')\n",
        "- pool: pool of unlabeled data\n",
        "- test: small labeled test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "x2_jBdptp2DD"
      },
      "outputs": [],
      "source": [
        "train_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/pt_data/pt_bosque-ud-train.txt'\n",
        "test_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/pt_data/pt_bosque-ud-test.txt'\n",
        "dev_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/ud/pt_data/pt_bosque-ud-dev.txt'\n",
        "pool_path = 'https://raw.githubusercontent.com/maxhof905/se_corpus/main/corpusdata_org/pt_text_se_corpus.txt'\n",
        "\n",
        "train = pd.read_csv(train_path, sep='\\t', names=['text', 'tokenized_text', 'se_label'])\n",
        "train.drop(columns=['text'], inplace = True)\n",
        "dev = pd.read_csv(dev_path, sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
        "dev.drop(columns=['text'], inplace = True)\n",
        "test = pd.read_csv(test_path, sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
        "test.drop(columns=['text'], inplace = True)\n",
        "\n",
        "se_corpus = pd.concat([train, dev, test]) # because the data was fileted for 'se' the data splits are not reliable anymore\n",
        "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'case')].index)\n",
        "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'nmod')].index)\n",
        "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'expl:pass')].index)\n",
        "\n",
        "pool = pd.read_csv(pool_path, sep='\\t', names=['text'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ygIoN5Dtp2DD",
        "outputId": "7c2e1db8-7b4b-470f-9ba4-e522d10451f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "get_class_dist(se_corpus.se_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1leMNrbXp2DF"
      },
      "outputs": [],
      "source": [
        "X = se_corpus.tokenized_text\n",
        "y = se_corpus.se_label\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2022)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NxnZw-YSp2DF"
      },
      "outputs": [],
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "pool_vectorized = vectorizer.transform(pool.text).toarray()\n",
        "\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F2cDu0ijp2DF"
      },
      "outputs": [],
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jMfNtq6jp2DF"
      },
      "outputs": [],
      "source": [
        "class PoolDataset(Dataset):\n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_data)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zZQT1J-Qp2DG"
      },
      "outputs": [],
      "source": [
        "train_set = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "test_set = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "pool_set = PoolDataset(torch.from_numpy(pool_vectorized).float())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DuzJZKakp2DG"
      },
      "outputs": [],
      "source": [
        "train_features = torch.reshape(train_set.X_data,   (train_set.X_data.shape[0], 1,train_set.X_data.shape[1]))\n",
        "train_labels = train_set.y_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8tLkX2trp2DG"
      },
      "outputs": [],
      "source": [
        "test_features = torch.reshape(test_set.X_data,   (test_set.X_data.shape[0], 1,test_set.X_data.shape[1]))\n",
        "test_labels = test_set.y_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asa2TgM4rjwF",
        "outputId": "d866381c-700b-4958-9ff4-532e76abf376"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7342"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SLD_dpYvp2DG"
      },
      "outputs": [],
      "source": [
        "X_pool = pool_set.X_data\n",
        "X_pool = torch.reshape(X_pool,   (X_pool.shape[0], 1, X_pool.shape[1]))\n",
        "X_pool = X_pool.detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbudqpM-p2DG"
      },
      "source": [
        "## 4) Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJH2qaBorvA5",
        "outputId": "8985e2f3-64fb-492c-ba34-835be4b5a3a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['expl', 'fixed', 'iobj', 'mark', 'nsubj', 'obj'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RMogkBRUp2DH"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, hidden_dim=64):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = 1\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # tensor shape: (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(train_features.shape[2], hidden_dim, 1, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 6) #equals the number of label encoder classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdR11kUnp2DH",
        "outputId": "b9147733-8872-4bd3-bb00-713ca6e7d8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using:  cuda\n"
          ]
        }
      ],
      "source": [
        "# skorch library creates sklearn classifier from torch neural net\n",
        "# infer initial parameters from es_pytorch_active_learning (which was run first with extensive GridSearch)\n",
        "\n",
        "# create the classifier\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print('using: ', device)\n",
        "\n",
        "# Callbacks: print accuracy when model is fitted\n",
        "acc = EpochScoring(scoring='accuracy', on_train=True,\n",
        "                         name='accuracy', lower_is_better=False)\n",
        "\n",
        "f1 = EpochScoring(scoring='f1_weighted', on_train=True,\n",
        "                         name='f1-score', lower_is_better=False)\n",
        "\n",
        "callbacks = [acc, f1]\n",
        "\n",
        "classifier = NeuralNetClassifier(module=LSTMModel,\n",
        "                                 batch_size=64,\n",
        "                                 max_epochs= 10,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.Adam,\n",
        "                                 lr=0.001,\n",
        "                                 train_split=None,\n",
        "                                 callbacks=callbacks,\n",
        "                                 verbose=1,\n",
        "                                 device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL6ILTLLp2DI",
        "outputId": "b943bf00-1a64-499e-a912-805d87d4c286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4410\u001b[0m      \u001b[32m0.4070\u001b[0m        \u001b[35m1.7037\u001b[0m  0.0756\n",
            "      2      \u001b[36m0.6170\u001b[0m      \u001b[32m0.4719\u001b[0m        \u001b[35m1.5089\u001b[0m  0.0606\n",
            "      3      0.6160      0.4696        \u001b[35m1.2841\u001b[0m  0.0637\n",
            "      4      0.6160      0.4696        \u001b[35m1.0947\u001b[0m  0.0706\n",
            "      5      0.6160      0.4696        \u001b[35m0.9596\u001b[0m  0.0626\n",
            "      6      \u001b[36m0.6430\u001b[0m      \u001b[32m0.5258\u001b[0m        \u001b[35m0.8239\u001b[0m  0.0606\n",
            "      7      \u001b[36m0.7530\u001b[0m      \u001b[32m0.7026\u001b[0m        \u001b[35m0.6775\u001b[0m  0.0591\n",
            "      8      \u001b[36m0.8570\u001b[0m      \u001b[32m0.8374\u001b[0m        \u001b[35m0.5317\u001b[0m  0.0585\n",
            "      9      \u001b[36m0.9190\u001b[0m      \u001b[32m0.9081\u001b[0m        \u001b[35m0.4043\u001b[0m  0.0600\n",
            "     10      \u001b[36m0.9480\u001b[0m      \u001b[32m0.9410\u001b[0m        \u001b[35m0.3048\u001b[0m  0.0606\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=LSTMModel(\n",
              "    (lstm): LSTM(7342, 64, batch_first=True)\n",
              "    (fc): Linear(in_features=64, out_features=6, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "classifier.fit(train_features, train_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuwMlAfup2DI"
      },
      "source": [
        "***model is overfitting***: \n",
        "Run hyperparameter for best parameter setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6qb9lylp2DI",
        "outputId": "35fb4bb1-277a-403c-e631-c1b5f75f9411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5175\u001b[0m      \u001b[32m0.4404\u001b[0m        \u001b[35m1.6780\u001b[0m  0.0804\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.3630\u001b[0m  0.0802\n",
            "      3      0.6162      0.4699        \u001b[35m1.1085\u001b[0m  0.0799\n",
            "      4      \u001b[36m0.6175\u001b[0m      \u001b[32m0.4728\u001b[0m        \u001b[35m0.9461\u001b[0m  0.0801\n",
            "      5      \u001b[36m0.6713\u001b[0m      \u001b[32m0.5723\u001b[0m        \u001b[35m0.7750\u001b[0m  0.0813\n",
            "      6      \u001b[36m0.8137\u001b[0m      \u001b[32m0.7685\u001b[0m        \u001b[35m0.5885\u001b[0m  0.0797\n",
            "      7      \u001b[36m0.9038\u001b[0m      \u001b[32m0.8803\u001b[0m        \u001b[35m0.4217\u001b[0m  0.0927\n",
            "      8      \u001b[36m0.9500\u001b[0m      \u001b[32m0.9444\u001b[0m        \u001b[35m0.2963\u001b[0m  0.0806\n",
            "      9      \u001b[36m0.9762\u001b[0m      \u001b[32m0.9751\u001b[0m        \u001b[35m0.2098\u001b[0m  0.0785\n",
            "     10      \u001b[36m0.9900\u001b[0m      \u001b[32m0.9897\u001b[0m        \u001b[35m0.1522\u001b[0m  0.0799\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.3725\u001b[0m      \u001b[32m0.3917\u001b[0m        \u001b[35m1.7347\u001b[0m  0.0773\n",
            "      2      \u001b[36m0.6225\u001b[0m      \u001b[32m0.4857\u001b[0m        \u001b[35m1.3882\u001b[0m  0.0804\n",
            "      3      0.6162      0.4699        \u001b[35m1.1065\u001b[0m  0.0792\n",
            "      4      0.6188      0.4756        \u001b[35m0.9477\u001b[0m  0.0795\n",
            "      5      \u001b[36m0.6675\u001b[0m      \u001b[32m0.5709\u001b[0m        \u001b[35m0.7899\u001b[0m  0.0816\n",
            "      6      \u001b[36m0.7925\u001b[0m      \u001b[32m0.7484\u001b[0m        \u001b[35m0.6178\u001b[0m  0.0851\n",
            "      7      \u001b[36m0.8912\u001b[0m      \u001b[32m0.8736\u001b[0m        \u001b[35m0.4544\u001b[0m  0.0791\n",
            "      8      \u001b[36m0.9463\u001b[0m      \u001b[32m0.9405\u001b[0m        \u001b[35m0.3248\u001b[0m  0.0798\n",
            "      9      \u001b[36m0.9688\u001b[0m      \u001b[32m0.9673\u001b[0m        \u001b[35m0.2334\u001b[0m  0.0775\n",
            "     10      \u001b[36m0.9800\u001b[0m      \u001b[32m0.9792\u001b[0m        \u001b[35m0.1716\u001b[0m  0.0786\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.2725\u001b[0m      \u001b[32m0.3118\u001b[0m        \u001b[35m1.7552\u001b[0m  0.0891\n",
            "      2      \u001b[36m0.6250\u001b[0m      \u001b[32m0.5006\u001b[0m        \u001b[35m1.4438\u001b[0m  0.0836\n",
            "      3      0.6150      0.4684        \u001b[35m1.1385\u001b[0m  0.0819\n",
            "      4      0.6162      0.4712        \u001b[35m0.9632\u001b[0m  0.0801\n",
            "      5      \u001b[36m0.6675\u001b[0m      \u001b[32m0.5731\u001b[0m        \u001b[35m0.7885\u001b[0m  0.0754\n",
            "      6      \u001b[36m0.8187\u001b[0m      \u001b[32m0.7806\u001b[0m        \u001b[35m0.5963\u001b[0m  0.0778\n",
            "      7      \u001b[36m0.9137\u001b[0m      \u001b[32m0.8951\u001b[0m        \u001b[35m0.4213\u001b[0m  0.0801\n",
            "      8      \u001b[36m0.9575\u001b[0m      \u001b[32m0.9528\u001b[0m        \u001b[35m0.2912\u001b[0m  0.0816\n",
            "      9      \u001b[36m0.9712\u001b[0m      \u001b[32m0.9695\u001b[0m        \u001b[35m0.2047\u001b[0m  0.0770\n",
            "     10      \u001b[36m0.9838\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.1487\u001b[0m  0.0759\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5000\u001b[0m      \u001b[32m0.4405\u001b[0m        \u001b[35m1.6979\u001b[0m  0.0757\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.3810\u001b[0m  0.0800\n",
            "      3      0.6162      0.4699        \u001b[35m1.1086\u001b[0m  0.0821\n",
            "      4      0.6162      0.4699        \u001b[35m0.9418\u001b[0m  0.0781\n",
            "      5      \u001b[36m0.6737\u001b[0m      \u001b[32m0.5799\u001b[0m        \u001b[35m0.7635\u001b[0m  0.0775\n",
            "      6      \u001b[36m0.8150\u001b[0m      \u001b[32m0.7823\u001b[0m        \u001b[35m0.5697\u001b[0m  0.0800\n",
            "      7      \u001b[36m0.9187\u001b[0m      \u001b[32m0.9090\u001b[0m        \u001b[35m0.3989\u001b[0m  0.0771\n",
            "      8      \u001b[36m0.9637\u001b[0m      \u001b[32m0.9603\u001b[0m        \u001b[35m0.2747\u001b[0m  0.0848\n",
            "      9      \u001b[36m0.9775\u001b[0m      \u001b[32m0.9752\u001b[0m        \u001b[35m0.1932\u001b[0m  0.0747\n",
            "     10      \u001b[36m0.9862\u001b[0m      \u001b[32m0.9859\u001b[0m        \u001b[35m0.1408\u001b[0m  0.0780\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4338\u001b[0m      \u001b[32m0.4264\u001b[0m        \u001b[35m1.6982\u001b[0m  0.0763\n",
            "      2      \u001b[36m0.6175\u001b[0m      \u001b[32m0.4728\u001b[0m        \u001b[35m1.3803\u001b[0m  0.0790\n",
            "      3      0.6162      0.4699        \u001b[35m1.1174\u001b[0m  0.0810\n",
            "      4      0.6162      0.4699        \u001b[35m0.9515\u001b[0m  0.0862\n",
            "      5      \u001b[36m0.6800\u001b[0m      \u001b[32m0.5946\u001b[0m        \u001b[35m0.7728\u001b[0m  0.0787\n",
            "      6      \u001b[36m0.8213\u001b[0m      \u001b[32m0.7865\u001b[0m        \u001b[35m0.5757\u001b[0m  0.0787\n",
            "      7      \u001b[36m0.9237\u001b[0m      \u001b[32m0.9112\u001b[0m        \u001b[35m0.4008\u001b[0m  0.0783\n",
            "      8      \u001b[36m0.9613\u001b[0m      \u001b[32m0.9573\u001b[0m        \u001b[35m0.2744\u001b[0m  0.0749\n",
            "      9      \u001b[36m0.9750\u001b[0m      \u001b[32m0.9731\u001b[0m        \u001b[35m0.1922\u001b[0m  0.0773\n",
            "     10      \u001b[36m0.9838\u001b[0m      \u001b[32m0.9831\u001b[0m        \u001b[35m0.1399\u001b[0m  0.0811\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5437\u001b[0m      \u001b[32m0.4500\u001b[0m        \u001b[35m1.6553\u001b[0m  0.0986\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.2447\u001b[0m  0.1011\n",
            "      3      0.6162      0.4699        \u001b[35m0.9973\u001b[0m  0.0990\n",
            "      4      \u001b[36m0.6625\u001b[0m      \u001b[32m0.5605\u001b[0m        \u001b[35m0.7885\u001b[0m  0.0993\n",
            "      5      \u001b[36m0.8313\u001b[0m      \u001b[32m0.8004\u001b[0m        \u001b[35m0.5445\u001b[0m  0.0996\n",
            "      6      \u001b[36m0.9400\u001b[0m      \u001b[32m0.9323\u001b[0m        \u001b[35m0.3345\u001b[0m  0.1003\n",
            "      7      \u001b[36m0.9738\u001b[0m      \u001b[32m0.9717\u001b[0m        \u001b[35m0.2029\u001b[0m  0.0973\n",
            "      8      \u001b[36m0.9875\u001b[0m      \u001b[32m0.9870\u001b[0m        \u001b[35m0.1302\u001b[0m  0.0999\n",
            "      9      \u001b[36m0.9950\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0895\u001b[0m  0.0987\n",
            "     10      0.9950      0.9948        \u001b[35m0.0652\u001b[0m  0.0994\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4813\u001b[0m      \u001b[32m0.4258\u001b[0m        \u001b[35m1.6661\u001b[0m  0.0980\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.2376\u001b[0m  0.1027\n",
            "      3      0.6162      0.4699        \u001b[35m1.0010\u001b[0m  0.1017\n",
            "      4      \u001b[36m0.6625\u001b[0m      \u001b[32m0.5615\u001b[0m        \u001b[35m0.7987\u001b[0m  0.1007\n",
            "      5      \u001b[36m0.8125\u001b[0m      \u001b[32m0.7762\u001b[0m        \u001b[35m0.5653\u001b[0m  0.0984\n",
            "      6      \u001b[36m0.9187\u001b[0m      \u001b[32m0.9055\u001b[0m        \u001b[35m0.3587\u001b[0m  0.0981\n",
            "      7      \u001b[36m0.9650\u001b[0m      \u001b[32m0.9616\u001b[0m        \u001b[35m0.2236\u001b[0m  0.0978\n",
            "      8      \u001b[36m0.9838\u001b[0m      \u001b[32m0.9828\u001b[0m        \u001b[35m0.1458\u001b[0m  0.1003\n",
            "      9      \u001b[36m0.9900\u001b[0m      \u001b[32m0.9898\u001b[0m        \u001b[35m0.1004\u001b[0m  0.0977\n",
            "     10      \u001b[36m0.9938\u001b[0m      \u001b[32m0.9935\u001b[0m        \u001b[35m0.0727\u001b[0m  0.0979\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4338\u001b[0m      \u001b[32m0.4010\u001b[0m        \u001b[35m1.6707\u001b[0m  0.0971\n",
            "      2      \u001b[36m0.6150\u001b[0m      \u001b[32m0.4684\u001b[0m        \u001b[35m1.2344\u001b[0m  0.0999\n",
            "      3      0.6150      0.4684        \u001b[35m1.0014\u001b[0m  0.0997\n",
            "      4      \u001b[36m0.6613\u001b[0m      \u001b[32m0.5594\u001b[0m        \u001b[35m0.7956\u001b[0m  0.0990\n",
            "      5      \u001b[36m0.8163\u001b[0m      \u001b[32m0.7809\u001b[0m        \u001b[35m0.5589\u001b[0m  0.0969\n",
            "      6      \u001b[36m0.9300\u001b[0m      \u001b[32m0.9181\u001b[0m        \u001b[35m0.3556\u001b[0m  0.1054\n",
            "      7      \u001b[36m0.9600\u001b[0m      \u001b[32m0.9562\u001b[0m        \u001b[35m0.2228\u001b[0m  0.1035\n",
            "      8      \u001b[36m0.9788\u001b[0m      \u001b[32m0.9774\u001b[0m        \u001b[35m0.1459\u001b[0m  0.1027\n",
            "      9      \u001b[36m0.9862\u001b[0m      \u001b[32m0.9857\u001b[0m        \u001b[35m0.1010\u001b[0m  0.1054\n",
            "     10      \u001b[36m0.9900\u001b[0m      \u001b[32m0.9898\u001b[0m        \u001b[35m0.0736\u001b[0m  0.1000\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4363\u001b[0m      \u001b[32m0.4069\u001b[0m        \u001b[35m1.6792\u001b[0m  0.1022\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.2474\u001b[0m  0.0988\n",
            "      3      0.6162      0.4699        \u001b[35m0.9982\u001b[0m  0.0993\n",
            "      4      \u001b[36m0.6687\u001b[0m      \u001b[32m0.5715\u001b[0m        \u001b[35m0.7852\u001b[0m  0.1014\n",
            "      5      \u001b[36m0.8313\u001b[0m      \u001b[32m0.7973\u001b[0m        \u001b[35m0.5433\u001b[0m  0.1018\n",
            "      6      \u001b[36m0.9313\u001b[0m      \u001b[32m0.9215\u001b[0m        \u001b[35m0.3377\u001b[0m  0.1017\n",
            "      7      \u001b[36m0.9750\u001b[0m      \u001b[32m0.9726\u001b[0m        \u001b[35m0.2086\u001b[0m  0.1032\n",
            "      8      \u001b[36m0.9825\u001b[0m      \u001b[32m0.9812\u001b[0m        \u001b[35m0.1358\u001b[0m  0.0999\n",
            "      9      \u001b[36m0.9900\u001b[0m      \u001b[32m0.9894\u001b[0m        \u001b[35m0.0938\u001b[0m  0.1009\n",
            "     10      \u001b[36m0.9925\u001b[0m      \u001b[32m0.9922\u001b[0m        \u001b[35m0.0682\u001b[0m  0.1017\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5650\u001b[0m      \u001b[32m0.4593\u001b[0m        \u001b[35m1.6178\u001b[0m  0.0976\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.2078\u001b[0m  0.0984\n",
            "      3      0.6162      0.4699        \u001b[35m0.9821\u001b[0m  0.0989\n",
            "      4      \u001b[36m0.6775\u001b[0m      \u001b[32m0.5803\u001b[0m        \u001b[35m0.7709\u001b[0m  0.1034\n",
            "      5      \u001b[36m0.8337\u001b[0m      \u001b[32m0.7972\u001b[0m        \u001b[35m0.5301\u001b[0m  0.1016\n",
            "      6      \u001b[36m0.9425\u001b[0m      \u001b[32m0.9356\u001b[0m        \u001b[35m0.3257\u001b[0m  0.0978\n",
            "      7      \u001b[36m0.9700\u001b[0m      \u001b[32m0.9677\u001b[0m        \u001b[35m0.1986\u001b[0m  0.0998\n",
            "      8      \u001b[36m0.9838\u001b[0m      \u001b[32m0.9832\u001b[0m        \u001b[35m0.1287\u001b[0m  0.0981\n",
            "      9      \u001b[36m0.9900\u001b[0m      \u001b[32m0.9898\u001b[0m        \u001b[35m0.0890\u001b[0m  0.0987\n",
            "     10      \u001b[36m0.9950\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0648\u001b[0m  0.1024\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5938\u001b[0m      \u001b[32m0.4613\u001b[0m        \u001b[35m1.2643\u001b[0m  0.0746\n",
            "      2      \u001b[36m0.8187\u001b[0m      \u001b[32m0.7881\u001b[0m        \u001b[35m0.5154\u001b[0m  0.0767\n",
            "      3      \u001b[36m0.9938\u001b[0m      \u001b[32m0.9933\u001b[0m        \u001b[35m0.0450\u001b[0m  0.0785\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0074\u001b[0m  0.0803\n",
            "      5      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  0.0760\n",
            "      6      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.0755\n",
            "      7      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.0773\n",
            "      8      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.0727\n",
            "      9      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0743\n",
            "     10      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0777\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5913\u001b[0m      \u001b[32m0.4616\u001b[0m        \u001b[35m1.2799\u001b[0m  0.0782\n",
            "      2      \u001b[36m0.7762\u001b[0m      \u001b[32m0.7342\u001b[0m        \u001b[35m0.5659\u001b[0m  0.0771\n",
            "      3      \u001b[36m0.9938\u001b[0m      \u001b[32m0.9937\u001b[0m        \u001b[35m0.0575\u001b[0m  0.0755\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0082\u001b[0m  0.0779\n",
            "      5      1.0000      1.0000        \u001b[35m0.0036\u001b[0m  0.0762\n",
            "      6      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  0.0812\n",
            "      7      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  0.0772\n",
            "      8      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.0786\n",
            "      9      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0800\n",
            "     10      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.0766\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5763\u001b[0m      \u001b[32m0.4598\u001b[0m        \u001b[35m1.2772\u001b[0m  0.0785\n",
            "      2      \u001b[36m0.8013\u001b[0m      \u001b[32m0.7613\u001b[0m        \u001b[35m0.5256\u001b[0m  0.0838\n",
            "      3      \u001b[36m0.9912\u001b[0m      \u001b[32m0.9911\u001b[0m        \u001b[35m0.0532\u001b[0m  0.0775\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0076\u001b[0m  0.0774\n",
            "      5      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  0.0799\n",
            "      6      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.0791\n",
            "      7      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.0843\n",
            "      8      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.0787\n",
            "      9      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0772\n",
            "     10      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0796\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.6112\u001b[0m      \u001b[32m0.4704\u001b[0m        \u001b[35m1.2577\u001b[0m  0.0755\n",
            "      2      \u001b[36m0.8187\u001b[0m      \u001b[32m0.7886\u001b[0m        \u001b[35m0.4930\u001b[0m  0.0794\n",
            "      3      \u001b[36m0.9938\u001b[0m      \u001b[32m0.9935\u001b[0m        \u001b[35m0.0448\u001b[0m  0.0766\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0077\u001b[0m  0.0805\n",
            "      5      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  0.0787\n",
            "      6      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.0765\n",
            "      7      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.0776\n",
            "      8      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.0844\n",
            "      9      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0801\n",
            "     10      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0801\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.6000\u001b[0m      \u001b[32m0.4735\u001b[0m        \u001b[35m1.2555\u001b[0m  0.0772\n",
            "      2      \u001b[36m0.8200\u001b[0m      \u001b[32m0.7881\u001b[0m        \u001b[35m0.5117\u001b[0m  0.0809\n",
            "      3      \u001b[36m0.9925\u001b[0m      \u001b[32m0.9923\u001b[0m        \u001b[35m0.0570\u001b[0m  0.0786\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0085\u001b[0m  0.0782\n",
            "      5      1.0000      1.0000        \u001b[35m0.0035\u001b[0m  0.0821\n",
            "      6      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.0805\n",
            "      7      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.0880\n",
            "      8      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.0776\n",
            "      9      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.0771\n",
            "     10      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0772\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5737\u001b[0m      \u001b[32m0.4575\u001b[0m        \u001b[35m1.2653\u001b[0m  0.1002\n",
            "      2      \u001b[36m0.8375\u001b[0m      \u001b[32m0.8147\u001b[0m        \u001b[35m0.4327\u001b[0m  0.1025\n",
            "      3      \u001b[36m0.9962\u001b[0m      \u001b[32m0.9961\u001b[0m        \u001b[35m0.0226\u001b[0m  0.0999\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0034\u001b[0m  0.1005\n",
            "      5      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.1017\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0985\n",
            "      7      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0988\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.0985\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.1071\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.0993\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5887\u001b[0m      \u001b[32m0.4593\u001b[0m        \u001b[35m1.2460\u001b[0m  0.0977\n",
            "      2      \u001b[36m0.8462\u001b[0m      \u001b[32m0.8276\u001b[0m        \u001b[35m0.3777\u001b[0m  0.0982\n",
            "      3      \u001b[36m0.9962\u001b[0m      \u001b[32m0.9962\u001b[0m        \u001b[35m0.0198\u001b[0m  0.0999\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0033\u001b[0m  0.1011\n",
            "      5      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.0991\n",
            "      6      1.0000      1.0000        \u001b[35m0.0011\u001b[0m  0.1011\n",
            "      7      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.1027\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.0991\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.0999\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.0973\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5875\u001b[0m      \u001b[32m0.4618\u001b[0m        \u001b[35m1.2715\u001b[0m  0.0972\n",
            "      2      \u001b[36m0.8762\u001b[0m      \u001b[32m0.8616\u001b[0m        \u001b[35m0.3711\u001b[0m  0.1058\n",
            "      3      \u001b[36m0.9975\u001b[0m      \u001b[32m0.9975\u001b[0m        \u001b[35m0.0212\u001b[0m  0.1021\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0028\u001b[0m  0.1068\n",
            "      5      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.0990\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0991\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.1015\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.1017\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.0993\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.0979\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.6000\u001b[0m      \u001b[32m0.4708\u001b[0m        \u001b[35m1.2459\u001b[0m  0.1002\n",
            "      2      \u001b[36m0.8925\u001b[0m      \u001b[32m0.8792\u001b[0m        \u001b[35m0.3608\u001b[0m  0.1037\n",
            "      3      \u001b[36m0.9975\u001b[0m      \u001b[32m0.9975\u001b[0m        \u001b[35m0.0223\u001b[0m  0.0997\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0030\u001b[0m  0.1005\n",
            "      5      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.0996\n",
            "      6      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.1019\n",
            "      7      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.1024\n",
            "      8      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.0997\n",
            "      9      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.0994\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.0998\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5950\u001b[0m      \u001b[32m0.4623\u001b[0m        \u001b[35m1.2556\u001b[0m  0.1030\n",
            "      2      \u001b[36m0.8938\u001b[0m      \u001b[32m0.8801\u001b[0m        \u001b[35m0.3467\u001b[0m  0.1030\n",
            "      3      \u001b[36m0.9988\u001b[0m      \u001b[32m0.9987\u001b[0m        \u001b[35m0.0216\u001b[0m  0.1031\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0033\u001b[0m  0.1007\n",
            "      5      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.1034\n",
            "      6      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.1072\n",
            "      7      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.1053\n",
            "      8      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.1043\n",
            "      9      1.0000      1.0000        \u001b[35m0.0005\u001b[0m  0.1037\n",
            "     10      1.0000      1.0000        \u001b[35m0.0004\u001b[0m  0.1080\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4250\u001b[0m      \u001b[32m0.4078\u001b[0m        \u001b[35m1.6833\u001b[0m  0.0508\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4703\u001b[0m        \u001b[35m1.5150\u001b[0m  0.0491\n",
            "      3      0.6162      0.4699        \u001b[35m1.3278\u001b[0m  0.0505\n",
            "      4      0.6162      0.4699        \u001b[35m1.1489\u001b[0m  0.0483\n",
            "      5      0.6162      0.4699        \u001b[35m1.0152\u001b[0m  0.0478\n",
            "      6      \u001b[36m0.6188\u001b[0m      \u001b[32m0.4756\u001b[0m        \u001b[35m0.9035\u001b[0m  0.0478\n",
            "      7      \u001b[36m0.6663\u001b[0m      \u001b[32m0.5698\u001b[0m        \u001b[35m0.7873\u001b[0m  0.0495\n",
            "      8      \u001b[36m0.7775\u001b[0m      \u001b[32m0.7303\u001b[0m        \u001b[35m0.6646\u001b[0m  0.0497\n",
            "      9      \u001b[36m0.8525\u001b[0m      \u001b[32m0.8154\u001b[0m        \u001b[35m0.5430\u001b[0m  0.0483\n",
            "     10      \u001b[36m0.9038\u001b[0m      \u001b[32m0.8765\u001b[0m        \u001b[35m0.4331\u001b[0m  0.0474\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.2313\u001b[0m      \u001b[32m0.2834\u001b[0m        \u001b[35m1.7766\u001b[0m  0.0467\n",
            "      2      \u001b[36m0.6150\u001b[0m      \u001b[32m0.5122\u001b[0m        \u001b[35m1.6023\u001b[0m  0.0520\n",
            "      3      \u001b[36m0.6212\u001b[0m      0.4829        \u001b[35m1.4018\u001b[0m  0.0477\n",
            "      4      0.6175      0.4728        \u001b[35m1.1999\u001b[0m  0.0491\n",
            "      5      0.6175      0.4728        \u001b[35m1.0503\u001b[0m  0.0481\n",
            "      6      0.6200      0.4784        \u001b[35m0.9351\u001b[0m  0.0541\n",
            "      7      \u001b[36m0.6475\u001b[0m      \u001b[32m0.5352\u001b[0m        \u001b[35m0.8189\u001b[0m  0.0487\n",
            "      8      \u001b[36m0.7300\u001b[0m      \u001b[32m0.6700\u001b[0m        \u001b[35m0.6972\u001b[0m  0.0485\n",
            "      9      \u001b[36m0.8175\u001b[0m      \u001b[32m0.7826\u001b[0m        \u001b[35m0.5751\u001b[0m  0.0480\n",
            "     10      \u001b[36m0.8912\u001b[0m      \u001b[32m0.8778\u001b[0m        \u001b[35m0.4617\u001b[0m  0.0481\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.0900\u001b[0m      \u001b[32m0.1255\u001b[0m        \u001b[35m1.7953\u001b[0m  0.0467\n",
            "      2      \u001b[36m0.5450\u001b[0m      \u001b[32m0.5002\u001b[0m        \u001b[35m1.6272\u001b[0m  0.0491\n",
            "      3      \u001b[36m0.6225\u001b[0m      0.4873        \u001b[35m1.4210\u001b[0m  0.0500\n",
            "      4      0.6150      0.4684        \u001b[35m1.2060\u001b[0m  0.0481\n",
            "      5      0.6150      0.4684        \u001b[35m1.0458\u001b[0m  0.0487\n",
            "      6      0.6225      0.4849        \u001b[35m0.9205\u001b[0m  0.0473\n",
            "      7      \u001b[36m0.6713\u001b[0m      \u001b[32m0.5759\u001b[0m        \u001b[35m0.7928\u001b[0m  0.0470\n",
            "      8      \u001b[36m0.7863\u001b[0m      \u001b[32m0.7408\u001b[0m        \u001b[35m0.6616\u001b[0m  0.0456\n",
            "      9      \u001b[36m0.8550\u001b[0m      \u001b[32m0.8271\u001b[0m        \u001b[35m0.5352\u001b[0m  0.0479\n",
            "     10      \u001b[36m0.9237\u001b[0m      \u001b[32m0.9088\u001b[0m        \u001b[35m0.4238\u001b[0m  0.0509\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4363\u001b[0m      \u001b[32m0.4074\u001b[0m        \u001b[35m1.7240\u001b[0m  0.0469\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.5573\u001b[0m  0.0512\n",
            "      3      0.6162      0.4699        \u001b[35m1.3689\u001b[0m  0.0527\n",
            "      4      0.6162      0.4699        \u001b[35m1.1829\u001b[0m  0.0505\n",
            "      5      0.6162      0.4699        \u001b[35m1.0430\u001b[0m  0.0502\n",
            "      6      \u001b[36m0.6175\u001b[0m      \u001b[32m0.4728\u001b[0m        \u001b[35m0.9281\u001b[0m  0.0486\n",
            "      7      \u001b[36m0.6562\u001b[0m      \u001b[32m0.5474\u001b[0m        \u001b[35m0.8066\u001b[0m  0.0524\n",
            "      8      \u001b[36m0.7450\u001b[0m      \u001b[32m0.6851\u001b[0m        \u001b[35m0.6761\u001b[0m  0.0525\n",
            "      9      \u001b[36m0.8488\u001b[0m      \u001b[32m0.8171\u001b[0m        \u001b[35m0.5461\u001b[0m  0.0501\n",
            "     10      \u001b[36m0.9062\u001b[0m      \u001b[32m0.8922\u001b[0m        \u001b[35m0.4294\u001b[0m  0.0507\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.6050\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.6858\u001b[0m  0.0500\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.5246\u001b[0m  0.0498\n",
            "      3      0.6162      0.4699        \u001b[35m1.3393\u001b[0m  0.0478\n",
            "      4      0.6162      0.4699        \u001b[35m1.1587\u001b[0m  0.0480\n",
            "      5      0.6162      0.4699        \u001b[35m1.0232\u001b[0m  0.0482\n",
            "      6      \u001b[36m0.6175\u001b[0m      \u001b[32m0.4728\u001b[0m        \u001b[35m0.9062\u001b[0m  0.0487\n",
            "      7      \u001b[36m0.6538\u001b[0m      \u001b[32m0.5465\u001b[0m        \u001b[35m0.7807\u001b[0m  0.0512\n",
            "      8      \u001b[36m0.7688\u001b[0m      \u001b[32m0.7226\u001b[0m        \u001b[35m0.6490\u001b[0m  0.0474\n",
            "      9      \u001b[36m0.8662\u001b[0m      \u001b[32m0.8464\u001b[0m        \u001b[35m0.5207\u001b[0m  0.0552\n",
            "     10      \u001b[36m0.9313\u001b[0m      \u001b[32m0.9208\u001b[0m        \u001b[35m0.4078\u001b[0m  0.0476\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4738\u001b[0m      \u001b[32m0.4211\u001b[0m        \u001b[35m1.7171\u001b[0m  0.0596\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.4480\u001b[0m  0.0612\n",
            "      3      0.6162      0.4699        \u001b[35m1.1834\u001b[0m  0.0604\n",
            "      4      0.6162      0.4699        \u001b[35m1.0163\u001b[0m  0.0619\n",
            "      5      \u001b[36m0.6200\u001b[0m      \u001b[32m0.4784\u001b[0m        \u001b[35m0.8827\u001b[0m  0.0604\n",
            "      6      \u001b[36m0.6913\u001b[0m      \u001b[32m0.6111\u001b[0m        \u001b[35m0.7355\u001b[0m  0.0634\n",
            "      7      \u001b[36m0.8187\u001b[0m      \u001b[32m0.7786\u001b[0m        \u001b[35m0.5786\u001b[0m  0.0703\n",
            "      8      \u001b[36m0.9062\u001b[0m      \u001b[32m0.8875\u001b[0m        \u001b[35m0.4314\u001b[0m  0.0705\n",
            "      9      \u001b[36m0.9475\u001b[0m      \u001b[32m0.9405\u001b[0m        \u001b[35m0.3126\u001b[0m  0.0595\n",
            "     10      \u001b[36m0.9675\u001b[0m      \u001b[32m0.9638\u001b[0m        \u001b[35m0.2266\u001b[0m  0.0617\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4875\u001b[0m      \u001b[32m0.4271\u001b[0m        \u001b[35m1.6835\u001b[0m  0.0619\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.4345\u001b[0m  0.0615\n",
            "      3      0.6162      0.4699        \u001b[35m1.1876\u001b[0m  0.0619\n",
            "      4      0.6162      0.4699        \u001b[35m1.0198\u001b[0m  0.0638\n",
            "      5      \u001b[36m0.6200\u001b[0m      \u001b[32m0.4784\u001b[0m        \u001b[35m0.8853\u001b[0m  0.0612\n",
            "      6      \u001b[36m0.6950\u001b[0m      \u001b[32m0.6150\u001b[0m        \u001b[35m0.7368\u001b[0m  0.0590\n",
            "      7      \u001b[36m0.8113\u001b[0m      \u001b[32m0.7701\u001b[0m        \u001b[35m0.5799\u001b[0m  0.0604\n",
            "      8      \u001b[36m0.8862\u001b[0m      \u001b[32m0.8697\u001b[0m        \u001b[35m0.4332\u001b[0m  0.0638\n",
            "      9      \u001b[36m0.9450\u001b[0m      \u001b[32m0.9397\u001b[0m        \u001b[35m0.3156\u001b[0m  0.0612\n",
            "     10      \u001b[36m0.9700\u001b[0m      \u001b[32m0.9678\u001b[0m        \u001b[35m0.2308\u001b[0m  0.0645\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5000\u001b[0m      \u001b[32m0.4306\u001b[0m        \u001b[35m1.7142\u001b[0m  0.0576\n",
            "      2      \u001b[36m0.6150\u001b[0m      \u001b[32m0.4684\u001b[0m        \u001b[35m1.4531\u001b[0m  0.0602\n",
            "      3      0.6150      0.4684        \u001b[35m1.1914\u001b[0m  0.0598\n",
            "      4      0.6150      0.4684        \u001b[35m1.0185\u001b[0m  0.0590\n",
            "      5      \u001b[36m0.6238\u001b[0m      \u001b[32m0.4879\u001b[0m        \u001b[35m0.8710\u001b[0m  0.0616\n",
            "      6      \u001b[36m0.7400\u001b[0m      \u001b[32m0.6834\u001b[0m        \u001b[35m0.7091\u001b[0m  0.0603\n",
            "      7      \u001b[36m0.8588\u001b[0m      \u001b[32m0.8348\u001b[0m        \u001b[35m0.5446\u001b[0m  0.0598\n",
            "      8      \u001b[36m0.9237\u001b[0m      \u001b[32m0.9117\u001b[0m        \u001b[35m0.3996\u001b[0m  0.0605\n",
            "      9      \u001b[36m0.9550\u001b[0m      \u001b[32m0.9499\u001b[0m        \u001b[35m0.2890\u001b[0m  0.0590\n",
            "     10      \u001b[36m0.9725\u001b[0m      \u001b[32m0.9705\u001b[0m        \u001b[35m0.2112\u001b[0m  0.0595\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5363\u001b[0m      \u001b[32m0.4588\u001b[0m        \u001b[35m1.6754\u001b[0m  0.0577\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.4441\u001b[0m  0.0623\n",
            "      3      0.6162      0.4699        \u001b[35m1.1959\u001b[0m  0.0598\n",
            "      4      0.6162      0.4699        \u001b[35m1.0136\u001b[0m  0.0605\n",
            "      5      \u001b[36m0.6288\u001b[0m      \u001b[32m0.4974\u001b[0m        \u001b[35m0.8594\u001b[0m  0.0598\n",
            "      6      \u001b[36m0.7412\u001b[0m      \u001b[32m0.6830\u001b[0m        \u001b[35m0.6906\u001b[0m  0.0595\n",
            "      7      \u001b[36m0.8612\u001b[0m      \u001b[32m0.8388\u001b[0m        \u001b[35m0.5221\u001b[0m  0.0592\n",
            "      8      \u001b[36m0.9225\u001b[0m      \u001b[32m0.9104\u001b[0m        \u001b[35m0.3785\u001b[0m  0.0613\n",
            "      9      \u001b[36m0.9600\u001b[0m      \u001b[32m0.9551\u001b[0m        \u001b[35m0.2723\u001b[0m  0.0603\n",
            "     10      \u001b[36m0.9762\u001b[0m      \u001b[32m0.9739\u001b[0m        \u001b[35m0.1987\u001b[0m  0.0597\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.3800\u001b[0m      \u001b[32m0.3885\u001b[0m        \u001b[35m1.7310\u001b[0m  0.0577\n",
            "      2      \u001b[36m0.6162\u001b[0m      \u001b[32m0.4699\u001b[0m        \u001b[35m1.4653\u001b[0m  0.0640\n",
            "      3      0.6162      0.4699        \u001b[35m1.1944\u001b[0m  0.0674\n",
            "      4      0.6162      0.4699        \u001b[35m1.0145\u001b[0m  0.0619\n",
            "      5      \u001b[36m0.6225\u001b[0m      \u001b[32m0.4839\u001b[0m        \u001b[35m0.8676\u001b[0m  0.0614\n",
            "      6      \u001b[36m0.7262\u001b[0m      \u001b[32m0.6594\u001b[0m        \u001b[35m0.7104\u001b[0m  0.0601\n",
            "      7      \u001b[36m0.8425\u001b[0m      \u001b[32m0.8088\u001b[0m        \u001b[35m0.5507\u001b[0m  0.0603\n",
            "      8      \u001b[36m0.9250\u001b[0m      \u001b[32m0.9128\u001b[0m        \u001b[35m0.4059\u001b[0m  0.0629\n",
            "      9      \u001b[36m0.9500\u001b[0m      \u001b[32m0.9439\u001b[0m        \u001b[35m0.2928\u001b[0m  0.0606\n",
            "     10      \u001b[36m0.9675\u001b[0m      \u001b[32m0.9638\u001b[0m        \u001b[35m0.2132\u001b[0m  0.0606\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5437\u001b[0m      \u001b[32m0.4474\u001b[0m        \u001b[35m1.4077\u001b[0m  0.0460\n",
            "      2      \u001b[36m0.6875\u001b[0m      \u001b[32m0.6047\u001b[0m        \u001b[35m0.8130\u001b[0m  0.0507\n",
            "      3      \u001b[36m0.9563\u001b[0m      \u001b[32m0.9493\u001b[0m        \u001b[35m0.2230\u001b[0m  0.0477\n",
            "      4      \u001b[36m0.9962\u001b[0m      \u001b[32m0.9962\u001b[0m        \u001b[35m0.0329\u001b[0m  0.0456\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0094\u001b[0m  0.0485\n",
            "      6      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  0.0483\n",
            "      7      1.0000      1.0000        \u001b[35m0.0028\u001b[0m  0.0531\n",
            "      8      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  0.0566\n",
            "      9      1.0000      1.0000        \u001b[35m0.0016\u001b[0m  0.0542\n",
            "     10      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.0523\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5675\u001b[0m      \u001b[32m0.4592\u001b[0m        \u001b[35m1.3643\u001b[0m  0.0484\n",
            "      2      \u001b[36m0.7075\u001b[0m      \u001b[32m0.6366\u001b[0m        \u001b[35m0.7806\u001b[0m  0.0514\n",
            "      3      \u001b[36m0.9563\u001b[0m      \u001b[32m0.9517\u001b[0m        \u001b[35m0.2348\u001b[0m  0.0497\n",
            "      4      \u001b[36m0.9962\u001b[0m      \u001b[32m0.9962\u001b[0m        \u001b[35m0.0396\u001b[0m  0.0505\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0116\u001b[0m  0.0475\n",
            "      6      1.0000      1.0000        \u001b[35m0.0055\u001b[0m  0.0475\n",
            "      7      1.0000      1.0000        \u001b[35m0.0034\u001b[0m  0.0478\n",
            "      8      1.0000      1.0000        \u001b[35m0.0024\u001b[0m  0.0509\n",
            "      9      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  0.0485\n",
            "     10      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.0503\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5850\u001b[0m      \u001b[32m0.4576\u001b[0m        \u001b[35m1.3611\u001b[0m  0.0453\n",
            "      2      \u001b[36m0.7250\u001b[0m      \u001b[32m0.6603\u001b[0m        \u001b[35m0.7758\u001b[0m  0.0479\n",
            "      3      \u001b[36m0.9525\u001b[0m      \u001b[32m0.9469\u001b[0m        \u001b[35m0.2263\u001b[0m  0.0476\n",
            "      4      \u001b[36m0.9950\u001b[0m      \u001b[32m0.9948\u001b[0m        \u001b[35m0.0395\u001b[0m  0.0493\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0110\u001b[0m  0.0537\n",
            "      6      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  0.0482\n",
            "      7      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  0.0494\n",
            "      8      1.0000      1.0000        \u001b[35m0.0023\u001b[0m  0.0496\n",
            "      9      1.0000      1.0000        \u001b[35m0.0018\u001b[0m  0.0473\n",
            "     10      1.0000      1.0000        \u001b[35m0.0015\u001b[0m  0.0490\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5663\u001b[0m      \u001b[32m0.4585\u001b[0m        \u001b[35m1.3958\u001b[0m  0.0479\n",
            "      2      \u001b[36m0.7238\u001b[0m      \u001b[32m0.6594\u001b[0m        \u001b[35m0.7732\u001b[0m  0.0470\n",
            "      3      \u001b[36m0.9750\u001b[0m      \u001b[32m0.9705\u001b[0m        \u001b[35m0.2284\u001b[0m  0.0489\n",
            "      4      \u001b[36m0.9975\u001b[0m      \u001b[32m0.9974\u001b[0m        \u001b[35m0.0399\u001b[0m  0.0476\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0113\u001b[0m  0.0491\n",
            "      6      1.0000      1.0000        \u001b[35m0.0051\u001b[0m  0.0475\n",
            "      7      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  0.0474\n",
            "      8      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.0539\n",
            "      9      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  0.0477\n",
            "     10      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.0485\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5737\u001b[0m      \u001b[32m0.4676\u001b[0m        \u001b[35m1.3772\u001b[0m  0.0456\n",
            "      2      \u001b[36m0.7225\u001b[0m      \u001b[32m0.6582\u001b[0m        \u001b[35m0.7628\u001b[0m  0.0564\n",
            "      3      \u001b[36m0.9475\u001b[0m      \u001b[32m0.9381\u001b[0m        \u001b[35m0.2337\u001b[0m  0.0477\n",
            "      4      \u001b[36m0.9938\u001b[0m      \u001b[32m0.9935\u001b[0m        \u001b[35m0.0415\u001b[0m  0.0504\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0113\u001b[0m  0.0477\n",
            "      6      1.0000      1.0000        \u001b[35m0.0050\u001b[0m  0.0476\n",
            "      7      1.0000      1.0000        \u001b[35m0.0031\u001b[0m  0.0485\n",
            "      8      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.0496\n",
            "      9      1.0000      1.0000        \u001b[35m0.0017\u001b[0m  0.0477\n",
            "     10      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.0478\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.6025\u001b[0m      \u001b[32m0.4674\u001b[0m        \u001b[35m1.3191\u001b[0m  0.0579\n",
            "      2      \u001b[36m0.8113\u001b[0m      \u001b[32m0.7689\u001b[0m        \u001b[35m0.5981\u001b[0m  0.0617\n",
            "      3      \u001b[36m0.9888\u001b[0m      \u001b[32m0.9883\u001b[0m        \u001b[35m0.0860\u001b[0m  0.0597\n",
            "      4      \u001b[36m0.9988\u001b[0m      \u001b[32m0.9987\u001b[0m        \u001b[35m0.0129\u001b[0m  0.0599\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0043\u001b[0m  0.0603\n",
            "      6      1.0000      1.0000        \u001b[35m0.0020\u001b[0m  0.0631\n",
            "      7      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.0611\n",
            "      8      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0644\n",
            "      9      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0613\n",
            "     10      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.0607\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5663\u001b[0m      \u001b[32m0.4565\u001b[0m        \u001b[35m1.3426\u001b[0m  0.0584\n",
            "      2      \u001b[36m0.8113\u001b[0m      \u001b[32m0.7756\u001b[0m        \u001b[35m0.5981\u001b[0m  0.0621\n",
            "      3      \u001b[36m0.9862\u001b[0m      \u001b[32m0.9856\u001b[0m        \u001b[35m0.0898\u001b[0m  0.0614\n",
            "      4      \u001b[36m0.9975\u001b[0m      \u001b[32m0.9975\u001b[0m        \u001b[35m0.0139\u001b[0m  0.0597\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0047\u001b[0m  0.0611\n",
            "      6      1.0000      1.0000        \u001b[35m0.0022\u001b[0m  0.0603\n",
            "      7      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.0600\n",
            "      8      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0607\n",
            "      9      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0603\n",
            "     10      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.0615\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5550\u001b[0m      \u001b[32m0.4485\u001b[0m        \u001b[35m1.3558\u001b[0m  0.0583\n",
            "      2      \u001b[36m0.8200\u001b[0m      \u001b[32m0.7857\u001b[0m        \u001b[35m0.6016\u001b[0m  0.0664\n",
            "      3      \u001b[36m0.9862\u001b[0m      \u001b[32m0.9850\u001b[0m        \u001b[35m0.0914\u001b[0m  0.0601\n",
            "      4      \u001b[36m0.9975\u001b[0m      \u001b[32m0.9975\u001b[0m        \u001b[35m0.0141\u001b[0m  0.0608\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0041\u001b[0m  0.0602\n",
            "      6      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  0.0612\n",
            "      7      1.0000      1.0000        \u001b[35m0.0013\u001b[0m  0.0602\n",
            "      8      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0596\n",
            "      9      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0598\n",
            "     10      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.0595\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5925\u001b[0m      \u001b[32m0.4637\u001b[0m        \u001b[35m1.3190\u001b[0m  0.0587\n",
            "      2      \u001b[36m0.8125\u001b[0m      \u001b[32m0.7722\u001b[0m        \u001b[35m0.6037\u001b[0m  0.0607\n",
            "      3      \u001b[36m0.9888\u001b[0m      \u001b[32m0.9878\u001b[0m        \u001b[35m0.1037\u001b[0m  0.0604\n",
            "      4      \u001b[36m0.9975\u001b[0m      \u001b[32m0.9975\u001b[0m        \u001b[35m0.0147\u001b[0m  0.0618\n",
            "      5      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0048\u001b[0m  0.0623\n",
            "      6      1.0000      1.0000        \u001b[35m0.0019\u001b[0m  0.0649\n",
            "      7      1.0000      1.0000        \u001b[35m0.0012\u001b[0m  0.0604\n",
            "      8      1.0000      1.0000        \u001b[35m0.0009\u001b[0m  0.0606\n",
            "      9      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.0604\n",
            "     10      1.0000      1.0000        \u001b[35m0.0006\u001b[0m  0.0621\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5637\u001b[0m      \u001b[32m0.4527\u001b[0m        \u001b[35m1.3459\u001b[0m  0.0601\n",
            "      2      \u001b[36m0.8475\u001b[0m      \u001b[32m0.8190\u001b[0m        \u001b[35m0.5798\u001b[0m  0.0620\n",
            "      3      \u001b[36m0.9825\u001b[0m      \u001b[32m0.9815\u001b[0m        \u001b[35m0.0898\u001b[0m  0.0605\n",
            "      4      \u001b[36m1.0000\u001b[0m      \u001b[32m1.0000\u001b[0m        \u001b[35m0.0133\u001b[0m  0.0586\n",
            "      5      1.0000      1.0000        \u001b[35m0.0044\u001b[0m  0.0604\n",
            "      6      1.0000      1.0000        \u001b[35m0.0021\u001b[0m  0.0613\n",
            "      7      1.0000      1.0000        \u001b[35m0.0014\u001b[0m  0.0605\n",
            "      8      1.0000      1.0000        \u001b[35m0.0010\u001b[0m  0.0624\n",
            "      9      1.0000      1.0000        \u001b[35m0.0008\u001b[0m  0.0609\n",
            "     10      1.0000      1.0000        \u001b[35m0.0007\u001b[0m  0.0603\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=LSTMModel(\n",
              "    (lstm): LSTM(7342, 64, batch_first=True)\n",
              "    (fc): Linear(in_features=64, out_features=6, bias=True)\n",
              "  ),\n",
              "),\n",
              "             param_grid={'batch_size': [32, 64], 'lr': [0.001, 0.01],\n",
              "                         'max_epochs': [10], 'module__hidden_dim': [64, 128]},\n",
              "             refit=False, scoring='accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# infer suited parameters from es_pytorch_active_learning and run smaller hyperparameter search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'max_epochs': [10],\n",
        "    'batch_size':[32, 64],\n",
        "    'lr': [0.001, 0.01],\n",
        "    'module__hidden_dim': [64, 128],\n",
        "}\n",
        "gs = GridSearchCV(classifier, params, refit=False, cv=5, scoring='accuracy')\n",
        "\n",
        "gs.fit(train_features, train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G977iYEep2DI",
        "outputId": "b404364a-e239-4771-ecc8-91eeb1500f6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "gs.best_score_  0.634 \n",
            "gs.best_params_ {'batch_size': 32, 'lr': 0.001, 'max_epochs': 10, 'module__hidden_dim': 128}\n"
          ]
        }
      ],
      "source": [
        "print('\\ngs.best_score_ ', gs.best_score_, '\\ngs.best_params_', gs.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kokQy6x3p2DJ",
        "outputId": "75087518-061c-4163-bbaf-5025c29ffe42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5560\u001b[0m      \u001b[32m0.4617\u001b[0m        \u001b[35m1.5997\u001b[0m  0.2511\n",
            "      2      \u001b[36m0.6160\u001b[0m      \u001b[32m0.4696\u001b[0m        \u001b[35m1.1570\u001b[0m  0.1454\n",
            "      3      \u001b[36m0.6220\u001b[0m      \u001b[32m0.4830\u001b[0m        \u001b[35m0.9302\u001b[0m  0.1431\n",
            "      4      \u001b[36m0.7490\u001b[0m      \u001b[32m0.6929\u001b[0m        \u001b[35m0.6672\u001b[0m  0.1378\n",
            "      5      \u001b[36m0.9060\u001b[0m      \u001b[32m0.8892\u001b[0m        \u001b[35m0.3954\u001b[0m  0.1343\n",
            "      6      \u001b[36m0.9640\u001b[0m      \u001b[32m0.9611\u001b[0m        \u001b[35m0.2204\u001b[0m  0.1378\n",
            "      7      \u001b[36m0.9810\u001b[0m      \u001b[32m0.9801\u001b[0m        \u001b[35m0.1317\u001b[0m  0.1399\n",
            "      8      \u001b[36m0.9900\u001b[0m      \u001b[32m0.9898\u001b[0m        \u001b[35m0.0859\u001b[0m  0.1381\n",
            "      9      \u001b[36m0.9940\u001b[0m      \u001b[32m0.9939\u001b[0m        \u001b[35m0.0601\u001b[0m  0.1344\n",
            "     10      \u001b[36m0.9970\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0443\u001b[0m  0.1448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=LSTMModel(\n",
              "    (lstm): LSTM(7342, 128, batch_first=True)\n",
              "    (fc): Linear(in_features=128, out_features=6, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# refit with optimal parameters\n",
        "\n",
        "classifier = NeuralNetClassifier(module=LSTMModel,\n",
        "                                 module__hidden_dim = 128,\n",
        "                                 batch_size=32,\n",
        "                                 max_epochs= 10,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.Adam,\n",
        "                                 lr=0.001,\n",
        "                                 train_split=None,\n",
        "                                 callbacks=callbacks,\n",
        "                                 #callbacks__train_loss=None,\n",
        "                                 verbose=1,\n",
        "                                 device=device)\n",
        "\n",
        "classifier.fit(train_features, train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vlbYtszp2DJ",
        "outputId": "445d1447-7317-4eae-981f-36524b86cbaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        expl       0.66      0.96      0.78       155\n",
            "       fixed       0.00      0.00      0.00         2\n",
            "        iobj       0.00      0.00      0.00         2\n",
            "        mark       1.00      0.16      0.28        31\n",
            "       nsubj       0.29      0.14      0.19        43\n",
            "         obj       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.64       251\n",
            "   macro avg       0.32      0.21      0.21       251\n",
            "weighted avg       0.58      0.64      0.55       251\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "targets = label_encoder.classes_\n",
        "\n",
        "y_pred_test = classifier.predict(test_features)\n",
        "print(classification_report(test_labels, y_pred_test, target_names=targets, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLgsxuAwp2DJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzMdeiEpp2DK"
      },
      "source": [
        "## 5) Active Learner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = train_features.detach().cpu().numpy()\n",
        "train_labels = train_labels.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "TxlojtZOxKiO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLc1PJUgp2DK",
        "outputId": "b299f162-f65b-4904-b2ae-92b24a3c2b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5600\u001b[0m      \u001b[32m0.4687\u001b[0m        \u001b[35m1.5879\u001b[0m  0.4224\n",
            "      2      \u001b[36m0.6160\u001b[0m      \u001b[32m0.4696\u001b[0m        \u001b[35m1.1448\u001b[0m  0.2715\n",
            "      3      \u001b[36m0.6190\u001b[0m      \u001b[32m0.4764\u001b[0m        \u001b[35m0.9251\u001b[0m  0.2392\n",
            "      4      \u001b[36m0.7570\u001b[0m      \u001b[32m0.7040\u001b[0m        \u001b[35m0.6647\u001b[0m  0.2498\n",
            "      5      \u001b[36m0.9020\u001b[0m      \u001b[32m0.8869\u001b[0m        \u001b[35m0.3986\u001b[0m  0.2574\n",
            "      6      \u001b[36m0.9600\u001b[0m      \u001b[32m0.9565\u001b[0m        \u001b[35m0.2260\u001b[0m  0.2672\n",
            "      7      \u001b[36m0.9840\u001b[0m      \u001b[32m0.9833\u001b[0m        \u001b[35m0.1358\u001b[0m  0.1897\n",
            "      8      \u001b[36m0.9910\u001b[0m      \u001b[32m0.9908\u001b[0m        \u001b[35m0.0885\u001b[0m  0.2122\n",
            "      9      \u001b[36m0.9940\u001b[0m      \u001b[32m0.9939\u001b[0m        \u001b[35m0.0618\u001b[0m  0.1946\n",
            "     10      \u001b[36m0.9970\u001b[0m      \u001b[32m0.9970\u001b[0m        \u001b[35m0.0455\u001b[0m  0.2144\n"
          ]
        }
      ],
      "source": [
        "# no training arguments because classifier is already fitted\n",
        "learner = ActiveLearner(estimator=classifier,\n",
        "                        query_strategy=uncertainty_sampling,\n",
        "                        X_training=train_features,\n",
        "                        y_training=train_labels,\n",
        "                        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wCn2vA3ep2DK"
      },
      "outputs": [],
      "source": [
        "number_of_loops = 10\n",
        "n_instances = 20\n",
        "accuracies = [learner.score(test_features, test_labels)] # append first accuracy without learning\n",
        "pool_sent_list= list() # store annotated sentences and the labels\n",
        "pool_label_list= list()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWTyhVKFp2DK"
      },
      "source": [
        "### Loop\n",
        "- stops after 20 iterations\n",
        "- prompt sentence\n",
        "\n",
        "Problem: if annotation is 'None' (e.g in the case a sentence is discarded) the loop breaks. We have to discard certain sentences because when creating the underlying corpus\n",
        "phrases that do not contain 'se' like 'aunque a tu mac no le pase nada' were not discarded because there is no suited programmatical way to differentiate btw. 'pase' and 'siéntese'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8eJhW4Ap2DL",
        "outputId": "3ea24c21-8dbd-4442-941c-d21e01d3a10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "loop: 1\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('mark', 0.23), ('nsubj', 0.21), ('obj', 0.19), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "tornaram se prisioneiros esperando para acontecer .\n",
            "iobj\n",
            "\n",
            "loop: 1\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl', 0.22), ('fixed', 0.21), ('nsubj', 0.18), ('mark', 0.15), ('obj', 0.14), ('iobj', 0.09)]\n",
            "\n",
            "Ou pior , vender como se fosse uma guitarra de luthier fabricada a mão .\n",
            "fixed\n",
            "\n",
            "loop: 1\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.23), ('expl', 0.22), ('obj', 0.22), ('mark', 0.21), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "EU penso que a essas temperaturas se chama estado sub-febril .\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('mark', 0.24), ('expl', 0.22), ('nsubj', 0.22), ('obj', 0.19), ('iobj', 0.07), ('fixed', 0.06)]\n",
            "\n",
            "Informe o seu médico ou farmacêutico se estiver a tomar outros medicamentos .\n",
            "mark\n",
            "\n",
            "loop: 1\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl', 0.24), ('obj', 0.21), ('nsubj', 0.2), ('mark', 0.19), ('iobj', 0.09), ('fixed', 0.07)]\n",
            "\n",
            "Eh um motivador pessoal para se estudar guitarra ...\n",
            "nsubj\n",
            "\n",
            "loop: 1\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl', 0.23), ('obj', 0.23), ('nsubj', 0.2), ('mark', 0.13), ('fixed', 0.12), ('iobj', 0.09)]\n",
            "\n",
            "O espermatozóide se move a cerca de 45 km / hora .\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('mark', 0.25), ('expl', 0.2), ('nsubj', 0.2), ('fixed', 0.19), ('iobj', 0.1), ('obj', 0.06)]\n",
            "\n",
            "Eu me sentia , sempre , como se fosse uma ` coisa ' .\n",
            "fixed\n",
            "\n",
            "loop: 1\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('obj', 0.25), ('nsubj', 0.23), ('mark', 0.18), ('iobj', 0.05), ('fixed', 0.04)]\n",
            "\n",
            "Assim , o princípio de a conservação de a energia está bom e recomenda se : é ciência .\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('mark', 0.23), ('fixed', 0.18), ('nsubj', 0.17), ('obj', 0.1), ('iobj', 0.07)]\n",
            "\n",
            "Para mim , não , é como se fosse um jogo .\n",
            "fixed\n",
            "\n",
            "loop: 1\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('mark', 0.25), ('nsubj', 0.24), ('expl', 0.23), ('obj', 0.2), ('iobj', 0.04), ('fixed', 0.03)]\n",
            "\n",
            "Crianças e adultos até 40 anos - Uma colher para cada 10 kg de peso , se estiver doente ou crescendo muito .\n",
            "mark\n",
            "\n",
            "loop: 1\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('fixed', 0.17), ('nsubj', 0.17), ('obj', 0.16), ('mark', 0.13), ('iobj', 0.11)]\n",
            "\n",
            "Tudo é tão vago como se fosse nada . \"\n",
            "fixed\n",
            "\n",
            "loop: 1\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('mark', 0.25), ('obj', 0.24), ('nsubj', 0.2), ('expl', 0.14), ('fixed', 0.09), ('iobj', 0.07)]\n",
            "\n",
            "ou se dirige a a Secretaria de Estado da Defesa do Consumidor ?\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('nsubj', 0.24), ('expl', 0.21), ('obj', 0.21), ('fixed', 0.05), ('iobj', 0.04)]\n",
            "\n",
            "Então , você pode ou deve se casar novamente ?\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('nsubj', 0.25), ('mark', 0.24), ('obj', 0.18), ('fixed', 0.04), ('iobj', 0.04)]\n",
            "\n",
            "Quando um homem tem um problema , ele se fecha .\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('mark', 0.25), ('nsubj', 0.18), ('obj', 0.18), ('fixed', 0.08), ('iobj', 0.07)]\n",
            "\n",
            "Tentei averiguar se podia lá ir comer a a borla .\n",
            "mark\n",
            "\n",
            "loop: 1\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('obj', 0.24), ('nsubj', 0.23), ('mark', 0.2), ('fixed', 0.04), ('iobj', 0.03)]\n",
            "\n",
            "Dava me frutas e cobria me de atenções ... criança gosta de ser notada , criança gosta de se sentir « gente » .\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('fixed', 0.19), ('nsubj', 0.18), ('obj', 0.13), ('mark', 0.12), ('iobj', 0.11)]\n",
            "\n",
            "Chegamos a um ponto em o qual o Sporting lida com o jogador como se fosse uma mercadoria .\n",
            "fixed\n",
            "\n",
            "loop: 1\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('expl', 0.24), ('nsubj', 0.24), ('obj', 0.1), ('fixed', 0.09), ('iobj', 0.07)]\n",
            "\n",
            "Isso é lá coisa que se pergunte ?\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.26), ('obj', 0.23), ('mark', 0.21), ('iobj', 0.13), ('expl', 0.09), ('fixed', 0.08)]\n",
            "\n",
            "O líder não deve se forçar a escolher o candidato « menos pior » por o fato de a posição estar vaga .\n",
            "expl\n",
            "\n",
            "loop: 1\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.26), ('mark', 0.25), ('obj', 0.2), ('fixed', 0.01), ('iobj', 0.01)]\n",
            "\n",
            "Por incrível que pareça , Lupe Fiasco se apresentou em a festa de posse de o presidente Obama ( é claro que isso não iria dar certo ) .\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5176\u001b[0m      \u001b[32m0.4488\u001b[0m        \u001b[35m1.6159\u001b[0m  0.1509\n",
            "      2      \u001b[36m0.6137\u001b[0m      \u001b[32m0.4668\u001b[0m        \u001b[35m1.1658\u001b[0m  0.1429\n",
            "      3      \u001b[36m0.6157\u001b[0m      \u001b[32m0.4713\u001b[0m        \u001b[35m0.9545\u001b[0m  0.1412\n",
            "      4      \u001b[36m0.7235\u001b[0m      \u001b[32m0.6576\u001b[0m        \u001b[35m0.7084\u001b[0m  0.1355\n",
            "      5      \u001b[36m0.8775\u001b[0m      \u001b[32m0.8576\u001b[0m        \u001b[35m0.4423\u001b[0m  0.1341\n",
            "      6      \u001b[36m0.9510\u001b[0m      \u001b[32m0.9442\u001b[0m        \u001b[35m0.2579\u001b[0m  0.1350\n",
            "      7      \u001b[36m0.9755\u001b[0m      \u001b[32m0.9737\u001b[0m        \u001b[35m0.1584\u001b[0m  0.1357\n",
            "      8      \u001b[36m0.9873\u001b[0m      \u001b[32m0.9869\u001b[0m        \u001b[35m0.1053\u001b[0m  0.1337\n",
            "      9      \u001b[36m0.9922\u001b[0m      \u001b[32m0.9919\u001b[0m        \u001b[35m0.0746\u001b[0m  0.1327\n",
            "     10      \u001b[36m0.9941\u001b[0m      \u001b[32m0.9940\u001b[0m        \u001b[35m0.0555\u001b[0m  0.1457\n",
            "\n",
            "loop: 2\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('mark', 0.23), ('expl', 0.21), ('nsubj', 0.21), ('fixed', 0.19), ('iobj', 0.09), ('obj', 0.07)]\n",
            "\n",
            "E assim , mesmo que alma esteja chorando , vamos caminhando e sorrindo ... Sorri Sorri quando a dor te torturar E a saudade atormentar Os teus dias tristonhos vazios Um Vento Muito Leve Passa Leve , leve , muito leve , Um vento muito leve passa , E vai se , sempre muito leve .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('mark', 0.22), ('nsubj', 0.22), ('expl', 0.19), ('fixed', 0.15), ('obj', 0.13), ('iobj', 0.09)]\n",
            "\n",
            "« Questões chave de a estratégia de crescimento são a determinação de as necessidades de trabalhadores de a informação e a determinação de as necessidades de requalificação de trabalhadores que se convertem em trabalhadores de a informação .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.24), ('expl', 0.22), ('obj', 0.22), ('mark', 0.21), ('fixed', 0.08), ('iobj', 0.03)]\n",
            "\n",
            "Ela aveia e os dois bebem vinho enquanto preparam a refeição e em a hora de se despedir , ela beija o e ele corresponde .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl', 0.24), ('nsubj', 0.23), ('mark', 0.22), ('obj', 0.19), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "Em o mercado atual , os riscos permeiam todos os níveis de as atividades de o negócio e , se não forem gerenciados adequadamente , poderão resultar em perdas financeiras , deterioração de a imagem e reputação de a empresa .\n",
            "mark\n",
            "\n",
            "loop: 2\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('fixed', 0.24), ('mark', 0.23), ('expl', 0.22), ('obj', 0.13), ('iobj', 0.11), ('nsubj', 0.08)]\n",
            "\n",
            "Em breve cada um vai pra seu lado , seja por o destino , ou por algum desentendimento , segue a sua vida , talvez continuemos a nos encontrar quem sabe ... Podemos nos telefonar , conversar algumas bobagens ... Aí os dias vão passar , meses ... anos ... até este contato tornar se cada vez mais raro .\n",
            "iobj\n",
            "\n",
            "loop: 2\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('fixed', 0.22), ('mark', 0.21), ('nsubj', 0.2), ('obj', 0.18), ('expl', 0.12), ('iobj', 0.07)]\n",
            "\n",
            "Senti um suspiro agora mesmo e te o sentindo um negocio em a orelha como se ele estivesse olhando eu escrever .\n",
            "mark\n",
            "\n",
            "loop: 2\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.24), ('mark', 0.21), ('obj', 0.17), ('iobj', 0.16), ('fixed', 0.14), ('expl', 0.08)]\n",
            "\n",
            "está se aproximando o mês para o casamento e minha familia e de ele estão pcupados e ele não diz nada.os pais de ele chamaram me para conversar sobre o casamento e eu disse que ele andou dizendo que não está preparado para casar ja .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('obj', 0.24), ('mark', 0.22), ('nsubj', 0.21), ('expl', 0.19), ('fixed', 0.11), ('iobj', 0.03)]\n",
            "\n",
            "Algumas partes de esse lago se formaram em o século dezenove , com espécies novas ( Schilthuizen 2001 , 166-176 ) ; · Plantas de a espécie Mimulus adaptadas a solos ricos em cobre não existiam antes de surgirem as minas que extraiam esse material , em 1859 ( Macnair 1989 ) .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl', 0.23), ('mark', 0.23), ('obj', 0.23), ('nsubj', 0.21), ('fixed', 0.06), ('iobj', 0.04)]\n",
            "\n",
            "I , b ) Para excluir a inelegibilidade de que cuida o item I , a , supra deve o candidato a as próximas eleições municipais afastar se de o exercício de o cargo , emprego ou função até 2 de julho de 1992 .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('fixed', 0.24), ('mark', 0.22), ('expl', 0.21), ('obj', 0.17), ('iobj', 0.09), ('nsubj', 0.08)]\n",
            "\n",
            "E ele se justificou dizendo que de aquele só tinha o meu número ( pezinho de Cinderela ) .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl', 0.24), ('mark', 0.21), ('nsubj', 0.2), ('fixed', 0.17), ('obj', 0.11), ('iobj', 0.08)]\n",
            "\n",
            "Foi como se eu não estivesse ali .\n",
            "fixed\n",
            "\n",
            "loop: 2\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('fixed', 0.23), ('mark', 0.16), ('obj', 0.14), ('nsubj', 0.12), ('iobj', 0.1)]\n",
            "\n",
            "É como se fosse eu em o palco .\n",
            "fixed\n",
            "\n",
            "loop: 2\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('fixed', 0.24), ('obj', 0.2), ('nsubj', 0.19), ('expl', 0.13), ('iobj', 0.11), ('mark', 0.11)]\n",
            "\n",
            "- Ela se interrompeu , seus olhos fixados em Jace .\n",
            "obj\n",
            "\n",
            "loop: 2\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl', 0.24), ('fixed', 0.2), ('iobj', 0.19), ('obj', 0.14), ('nsubj', 0.12), ('mark', 0.11)]\n",
            "\n",
            "SAÚDE Alimentos que podem causar dor de cabeça Segundo a Organização Mundial da Saúde , estima se que mais de 90 % de as pessoas sofrem ou sofreram de cefaleia ( dor de cabeça ) em algum momento de a vida .\n",
            "nsubj\n",
            "\n",
            "loop: 2\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('mark', 0.25), ('nsubj', 0.21), ('obj', 0.2), ('expl', 0.19), ('fixed', 0.09), ('iobj', 0.06)]\n",
            "\n",
            "Este espaço aparecerá APENAS em a primeira página e o seu uso será esporádico ; Bandeiras de Tema ( espaço 8 ) : Esta bandeira de tamanho variável adequa se a os anunciantes que pretendem APENAS publicitar após artigos de determinado tema ( por exemplo aparecer apenas junto com artigos de astrologia ) .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('mark', 0.25), ('nsubj', 0.24), ('expl', 0.22), ('obj', 0.15), ('fixed', 0.09), ('iobj', 0.05)]\n",
            "\n",
            "Essa ideia de tzimtzum se expressa em a linda cerimônia judaica de casamento , conhecida como « bedeken » , ou velar .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.25), ('mark', 0.23), ('obj', 0.2), ('expl', 0.14), ('fixed', 0.13), ('iobj', 0.05)]\n",
            "\n",
            "Vê se fazes por arranjar uma profissão com bastante reconhecimento social - gestor , economista , advogado ou engenheiro , de preferência - para que as pessoas te respeitem .\n",
            "mark\n",
            "\n",
            "loop: 2\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('obj', 0.25), ('mark', 0.19), ('nsubj', 0.14), ('fixed', 0.11), ('iobj', 0.06)]\n",
            "\n",
            "Sabe se muito pouco a respeito de Forever King of Pop em o Brasil até agora .\n",
            "nsubj\n",
            "\n",
            "loop: 2\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('obj', 0.24), ('mark', 0.18), ('nsubj', 0.16), ('fixed', 0.1), ('iobj', 0.08)]\n",
            "\n",
            "Abriu mão de inventário , tomou a frente de o compromisso de concluir o Parque Aza Branca e se uniu a o povo de Exu .\n",
            "expl\n",
            "\n",
            "loop: 2\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('nsubj', 0.24), ('mark', 0.23), ('obj', 0.17), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "Inês Barbosa : « Câmara não pode ser indiferente a a degradação de a coesão social » autor « A Câmara Municipal de Braga não pode manter se apática e indiferente a o empobrecimento e a a degradação profunda de a coesão social » , reivindica a candidatura Cidadania em Movimento , recordando , em comunicado , que « em o primeiro dia após as férias aumentam em muito as preocupações de os bracarenses » devido a as políticas de austeridade que têm em o horizonte novas perspectivas de intensificação .\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5990\u001b[0m      \u001b[32m0.4644\u001b[0m        \u001b[35m1.5649\u001b[0m  0.1380\n",
            "      2      \u001b[36m0.6125\u001b[0m      \u001b[32m0.4653\u001b[0m        \u001b[35m1.1506\u001b[0m  0.1474\n",
            "      3      \u001b[36m0.6154\u001b[0m      \u001b[32m0.4718\u001b[0m        \u001b[35m0.9455\u001b[0m  0.1408\n",
            "      4      \u001b[36m0.7375\u001b[0m      \u001b[32m0.6781\u001b[0m        \u001b[35m0.6879\u001b[0m  0.1388\n",
            "      5      \u001b[36m0.8923\u001b[0m      \u001b[32m0.8761\u001b[0m        \u001b[35m0.4202\u001b[0m  0.1497\n",
            "      6      \u001b[36m0.9500\u001b[0m      \u001b[32m0.9443\u001b[0m        \u001b[35m0.2469\u001b[0m  0.1433\n",
            "      7      \u001b[36m0.9740\u001b[0m      \u001b[32m0.9722\u001b[0m        \u001b[35m0.1552\u001b[0m  0.1406\n",
            "      8      \u001b[36m0.9846\u001b[0m      \u001b[32m0.9841\u001b[0m        \u001b[35m0.1052\u001b[0m  0.1385\n",
            "      9      \u001b[36m0.9913\u001b[0m      \u001b[32m0.9910\u001b[0m        \u001b[35m0.0755\u001b[0m  0.1412\n",
            "     10      \u001b[36m0.9933\u001b[0m      \u001b[32m0.9931\u001b[0m        \u001b[35m0.0564\u001b[0m  0.1440\n",
            "\n",
            "loop: 3\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('mark', 0.25), ('nsubj', 0.21), ('expl', 0.2), ('obj', 0.16), ('fixed', 0.13), ('iobj', 0.05)]\n",
            "\n",
            "Dêem uma olhada em este blog « tentando desmerecer » o trabalho de o Danizudo por causa de um rapaz que se sente mal por ser fã de os cantores fantoches ... seguidores de o Knowledge is power , não deixem de postar seus comentários lá e fazer valer a verdade ... http://cacadordemisterio.blogspot.com/20 \\\\ ...\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('obj', 0.25), ('nsubj', 0.24), ('mark', 0.18), ('fixed', 0.05), ('iobj', 0.02)]\n",
            "\n",
            "Esforcei me para fazer los entender que Deus responderia suas orações imediatamente , contanto que eles cumprissem as condições sob as quais Ele prometeu responder las e especialmente se acreditassem em o sentido de esperarem que Ele responderia a seus pedidos .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('nsubj', 0.25), ('mark', 0.23), ('obj', 0.13), ('fixed', 0.09), ('iobj', 0.05)]\n",
            "\n",
            "E se reuniram todos os chefes de os sacerdotes , os anciãos e os doutores de a Lei .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('nsubj', 0.23), ('fixed', 0.19), ('mark', 0.15), ('obj', 0.15), ('iobj', 0.03)]\n",
            "\n",
            "Ausência de burocracia para se manter formal , fazendo uma única declaração por ano sobre o seu faturamento que deve ser controlado mês a mês para a o final de o ano estar devidamente organizado .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('obj', 0.22), ('nsubj', 0.19), ('mark', 0.18), ('fixed', 0.11), ('iobj', 0.06)]\n",
            "\n",
            "Vocês vão dizer « não , mas o rádio tem que ser coloquial » ; eu acho que o rádio deve ser , pode ser coloquial desde que o ouvinte entenda o que se está dizendo .\n",
            "nsubj\n",
            "\n",
            "loop: 3\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('mark', 0.24), ('expl', 0.23), ('nsubj', 0.22), ('fixed', 0.11), ('obj', 0.1), ('iobj', 0.09)]\n",
            "\n",
            "O pai acaba por despertar a compaixão sim , mas de o leitor , por se ver incompreendido e muito pouco amado .\n",
            "iobj\n",
            "\n",
            "loop: 3\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.25), ('mark', 0.21), ('expl', 0.19), ('fixed', 0.14), ('obj', 0.14), ('iobj', 0.08)]\n",
            "\n",
            "Collins viu muito bem , muito antes de encontrar a fé cristã , que , « se Deus existe , deve estar fora de o mundo natural e , portanto , as ferramentas de a ciência não são adequadas para conhecer lo . \"\n",
            "mark\n",
            "\n",
            "loop: 3\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('fixed', 0.25), ('expl', 0.23), ('mark', 0.2), ('nsubj', 0.14), ('obj', 0.13), ('iobj', 0.05)]\n",
            "\n",
            "Agora é a vez de as empresas Agora que já se ouviram os novos valores falta promover a presença de as empresas em a final .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('fixed', 0.25), ('nsubj', 0.24), ('expl', 0.2), ('mark', 0.13), ('iobj', 0.09), ('obj', 0.09)]\n",
            "\n",
            "Não se sabe o que aconteceu em o quarto floresta onde alguns brothers , de o BBB12 , dormiam em a madrugada de o domingo ( 15 ) .\n",
            "nsubj\n",
            "\n",
            "loop: 3\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl', 0.23), ('obj', 0.21), ('fixed', 0.19), ('iobj', 0.14), ('mark', 0.14), ('nsubj', 0.09)]\n",
            "\n",
            "Estou começando como dj agora , tenho 15 anos , estou com uma aparelhagem , tbm quero começar a entrar em a area de a produção musical , sempre me interresei em tentar fazer um tipo de track eletronica ... Mto obrigado Ilan Kriger agradeço desde ja ... se pode ser um produtor musical só para faturamentos .\n",
            "mark\n",
            "\n",
            "loop: 3\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('nsubj', 0.26), ('obj', 0.23), ('expl', 0.21), ('fixed', 0.03), ('iobj', 0.02)]\n",
            "\n",
            "[...] Veja que maravilha , seria muito bom se apenas ficassem apenas em o amor de Jesus e não ficassem difamando a sua mãe ... !\n",
            "mark\n",
            "\n",
            "loop: 3\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('mark', 0.26), ('fixed', 0.13), ('nsubj', 0.13), ('iobj', 0.12), ('obj', 0.09)]\n",
            "\n",
            "Agora , voltemos para as palavras iniciais , que nos motivaram a abrir os pontos 1 e 2 ( que acabaram se mesclando ) .\n",
            "obj\n",
            "\n",
            "loop: 3\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('mark', 0.26), ('fixed', 0.13), ('nsubj', 0.13), ('iobj', 0.12), ('obj', 0.09)]\n",
            "\n",
            "Além disso , podemos constatar uma apatia existencial de o homem , até que a morte se aproxime .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('obj', 0.23), ('expl', 0.21), ('nsubj', 0.19), ('fixed', 0.07), ('iobj', 0.02)]\n",
            "\n",
            "Brasil quer dizer algo como « em brasa » , por causa de a cor vermelha de a madeira , de onde se extrai um corante .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('nsubj', 0.22), ('expl', 0.2), ('obj', 0.13), ('fixed', 0.1), ('iobj', 0.1)]\n",
            "\n",
            "Deixe um comentário : Antes de escrever seu comentário , lembre se : o iG não publica comentários ofensivos , obscenos , que vão contra a lei , que não tenham o remetente identificado ou que não tenham relação com o conteúdo comentado .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('nsubj', 0.21), ('expl', 0.2), ('obj', 0.15), ('fixed', 0.11), ('iobj', 0.08)]\n",
            "\n",
            "Não existe nenhum clube em o mundo que aproveite as suas camadas jovens a 100 % , se tirares um aproveitamento de 40 a 60 % já é muito bom !\n",
            "mark\n",
            "\n",
            "loop: 3\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('mark', 0.24), ('obj', 0.21), ('nsubj', 0.16), ('iobj', 0.07), ('fixed', 0.05)]\n",
            "\n",
            "Por o que , querendo Deus mostrar mais abundantemente a imutabilidade de o seu conselho a os herdeiros de a promessa , se interpôs com juramento ; Para que por duas coisas imutáveis , em as quais é impossível que Deus minta , tenhamos a firme consolação , nós , os que pomos o nosso refúgio em reter a esperança proposta » ( Epístola de São Paulo , apóstolo , a os Hebreus 6:16-18 ) .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('expl', 0.23), ('obj', 0.22), ('fixed', 0.11), ('nsubj', 0.09), ('iobj', 0.08)]\n",
            "\n",
            "Em a verdade , essa situação , antes de ser pessoal , resulta de a situação política em que vivemos - de aí o regime não ter o direito de se pronunciar sobre a situação pessoal de o Deputado Vítor Freitas ou de o Dr. Jaime Leandro .\n",
            "expl\n",
            "\n",
            "loop: 3\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.21), ('fixed', 0.19), ('obj', 0.14), ('mark', 0.11), ('iobj', 0.09)]\n",
            "\n",
            "Os livros de estratégias de blackjack estão por todo o lado e se começar a ler los e a aprender com eles terá a chance de aumentar consideravelmente as suas hipóteses de ganhar .\n",
            "mark\n",
            "\n",
            "loop: 3\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('mark', 0.26), ('nsubj', 0.25), ('fixed', 0.1), ('obj', 0.1), ('iobj', 0.03)]\n",
            "\n",
            "Casou se com o escultor Dante Casarini pressionada por sua mãe conservadora , talvez cansada de ver la solteira e alvo de línguas ferinas .\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5425\u001b[0m      \u001b[32m0.4517\u001b[0m        \u001b[35m1.6249\u001b[0m  0.1513\n",
            "      2      \u001b[36m0.6113\u001b[0m      \u001b[32m0.4639\u001b[0m        \u001b[35m1.1767\u001b[0m  0.1507\n",
            "      3      \u001b[36m0.6123\u001b[0m      \u001b[32m0.4660\u001b[0m        \u001b[35m0.9612\u001b[0m  0.1543\n",
            "      4      \u001b[36m0.7226\u001b[0m      \u001b[32m0.6589\u001b[0m        \u001b[35m0.7085\u001b[0m  0.1487\n",
            "      5      \u001b[36m0.8811\u001b[0m      \u001b[32m0.8627\u001b[0m        \u001b[35m0.4394\u001b[0m  0.1469\n",
            "      6      \u001b[36m0.9472\u001b[0m      \u001b[32m0.9392\u001b[0m        \u001b[35m0.2639\u001b[0m  0.1466\n",
            "      7      \u001b[36m0.9670\u001b[0m      \u001b[32m0.9632\u001b[0m        \u001b[35m0.1700\u001b[0m  0.1513\n",
            "      8      \u001b[36m0.9811\u001b[0m      \u001b[32m0.9800\u001b[0m        \u001b[35m0.1180\u001b[0m  0.1406\n",
            "      9      \u001b[36m0.9858\u001b[0m      \u001b[32m0.9851\u001b[0m        \u001b[35m0.0866\u001b[0m  0.1421\n",
            "     10      \u001b[36m0.9915\u001b[0m      \u001b[32m0.9911\u001b[0m        \u001b[35m0.0662\u001b[0m  0.1434\n",
            "\n",
            "loop: 4\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.25), ('mark', 0.22), ('obj', 0.21), ('expl', 0.18), ('fixed', 0.08), ('iobj', 0.07)]\n",
            "\n",
            "Porém se um cara quiser de morde , ATIRE EM A CABEÇA .\n",
            "mark\n",
            "\n",
            "loop: 4\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('mark', 0.24), ('expl', 0.22), ('nsubj', 0.2), ('fixed', 0.13), ('obj', 0.12), ('iobj', 0.09)]\n",
            "\n",
            "Se não seguir estas sugestões é porque não quer sair de a situação em que se encontra .\n",
            "mark\n",
            "\n",
            "loop: 4\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl', 0.23), ('fixed', 0.21), ('obj', 0.21), ('nsubj', 0.19), ('iobj', 0.08), ('mark', 0.08)]\n",
            "\n",
            "A justificação , como quase sempre , encontra se em a ciência , mais propriamente em a genética !\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('obj', 0.26), ('nsubj', 0.25), ('expl', 0.21), ('mark', 0.18), ('iobj', 0.06), ('fixed', 0.04)]\n",
            "\n",
            "Mas a situação está a tornar se insuportável para o Atila .\n",
            "iobj\n",
            "\n",
            "loop: 4\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl', 0.24), ('obj', 0.23), ('mark', 0.21), ('nsubj', 0.18), ('fixed', 0.08), ('iobj', 0.06)]\n",
            "\n",
            "Fiquei desapontada Mas depois pensei , pelo menos ele vai estar com mim grudado o dia todo , e eu vou transformar a loja em um parque de diversões se for preciso !\n",
            "mark\n",
            "\n",
            "loop: 4\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.24), ('obj', 0.23), ('expl', 0.21), ('mark', 0.18), ('fixed', 0.07), ('iobj', 0.06)]\n",
            "\n",
            "Evidentemente , isto não se torna mais fácil em períodos de incerteza económica , quando muitas pessoas manifestam , com justificação , ansiedade perante o seu próprio futuro económico .\n",
            "iobj\n",
            "\n",
            "loop: 4\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('obj', 0.21), ('nsubj', 0.2), ('mark', 0.19), ('fixed', 0.07), ('iobj', 0.07)]\n",
            "\n",
            "Gradualmente , o computador vai tornando se um aparelho corriqueiro em nosso meio social .\n",
            "iobj\n",
            "\n",
            "loop: 4\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('nsubj', 0.24), ('obj', 0.21), ('expl', 0.2), ('iobj', 0.06), ('fixed', 0.02)]\n",
            "\n",
            "Mas a razão era óbvia : tratava se de o único pão disponível em a altura .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('fixed', 0.26), ('mark', 0.23), ('expl', 0.22), ('nsubj', 0.16), ('iobj', 0.07), ('obj', 0.05)]\n",
            "\n",
            "Também podemos usar um elástico em o pulso ( a evitar por os masoquistas ) e quando a perturbação se iniciar : esticamos gentilmente o elástico e uma pequena dor distrai nos de as imagens aterradoras e somos chamados a a realidade .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('obj', 0.24), ('expl', 0.23), ('nsubj', 0.11), ('fixed', 0.07), ('iobj', 0.07)]\n",
            "\n",
            "Me a se faltam os dois elementos de a fidelidade e de a prole , ou mesmo só um de eles , não vejo de que maneira poderemos chamar matrimónio a semelhantes uniões ' ( Agostino , La dignità del matrimonio [ A dignidade de o matrimónio ] , Roma 1982 , pag.\n",
            "mark\n",
            "\n",
            "loop: 4\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('obj', 0.26), ('mark', 0.25), ('expl', 0.24), ('nsubj', 0.13), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "O lingüista brasileiro Aryon Dall'Igna Rodrigues estabeleceu uma classificação de as línguas indígenas faladas em o Brasil , sendo esta a mais utilizada por a comunidade científica que se dedica a os estudos pertinentes a as populações indígenas .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.27), ('expl', 0.26), ('obj', 0.21), ('mark', 0.13), ('iobj', 0.07), ('fixed', 0.06)]\n",
            "\n",
            "Em vez de aquelas estações multiuso ( que oferecem quase nenhum benefício para o condicionamento e , ainda por cima , perigo de você se machucar ) , é melhor que tenha pelo menos um aparelho de cardio ( esteira , bicicleta ergométrica ou elíptico ) , um banco e pesos livres ( barras , anilhas e dumbbells ) , que você vai usar para fazer exercícios de força .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('expl', 0.25), ('nsubj', 0.23), ('obj', 0.14), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "Mas é também o teste de os seus limites , que se vão revelando à medida que o poeta deixa os reinos de a expiação ( o Inferno e o Purgatório ) e adentra o de a glória .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('mark', 0.26), ('nsubj', 0.24), ('obj', 0.09), ('fixed', 0.07), ('iobj', 0.07)]\n",
            "\n",
            "Em a verdade , nossos médicos e suas corporações não estão brigando por postos de trabalho para si ou para outros profissionais brasileiros , que se encontram à margem de o mercado de trabalho .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.24), ('mark', 0.22), ('obj', 0.16), ('iobj', 0.06), ('fixed', 0.05)]\n",
            "\n",
            "Colei retratos de gente que se ia cruzando com mim , bilhetes postais , etiquetas , bilhetes de comboio e de avião ... \" Al Berto\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.27), ('mark', 0.2), ('obj', 0.19), ('fixed', 0.04), ('iobj', 0.04)]\n",
            "\n",
            "Não se trata de lutar contra a liberdade de ninguém , mas sim de fazer que a nossa sociedade possua valores claros e que os mais indefesos sejam de fato os mais protegidos .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('nsubj', 0.26), ('expl', 0.23), ('fixed', 0.09), ('iobj', 0.09), ('obj', 0.05)]\n",
            "\n",
            "limite se ?\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.27), ('obj', 0.26), ('expl', 0.25), ('mark', 0.12), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "É preciso perguntar , publicamente , a os « notáveis » de a cidade , qual a sua opinião sobre este assunto e até onde se dispõem a ir em defesa de esta causa .\n",
            "obj\n",
            "\n",
            "loop: 4\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('expl', 0.25), ('nsubj', 0.21), ('obj', 0.14), ('fixed', 0.07), ('iobj', 0.06)]\n",
            "\n",
            "Vestido com roupas de vagabundo , está afectado por uma amnésia que o impede de se recordar , entre outras coisas , de o seu estatuto profissional .\n",
            "expl\n",
            "\n",
            "loop: 4\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.21), ('mark', 0.2), ('obj', 0.2), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "Para que você não se confunda , eis aqui um post com tudo o que você precisa saber sobre os ultrabooks .\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4602\u001b[0m      \u001b[32m0.4205\u001b[0m        \u001b[35m1.6560\u001b[0m  0.1442\n",
            "      2      \u001b[36m0.6111\u001b[0m      \u001b[32m0.4636\u001b[0m        \u001b[35m1.1869\u001b[0m  0.1501\n",
            "      3      \u001b[36m0.6130\u001b[0m      \u001b[32m0.4678\u001b[0m        \u001b[35m0.9682\u001b[0m  0.1447\n",
            "      4      \u001b[36m0.7222\u001b[0m      \u001b[32m0.6570\u001b[0m        \u001b[35m0.7179\u001b[0m  0.1436\n",
            "      5      \u001b[36m0.8796\u001b[0m      \u001b[32m0.8590\u001b[0m        \u001b[35m0.4520\u001b[0m  0.1415\n",
            "      6      \u001b[36m0.9454\u001b[0m      \u001b[32m0.9370\u001b[0m        \u001b[35m0.2737\u001b[0m  0.1588\n",
            "      7      \u001b[36m0.9639\u001b[0m      \u001b[32m0.9598\u001b[0m        \u001b[35m0.1774\u001b[0m  0.1429\n",
            "      8      \u001b[36m0.9731\u001b[0m      \u001b[32m0.9711\u001b[0m        \u001b[35m0.1235\u001b[0m  0.1532\n",
            "      9      \u001b[36m0.9824\u001b[0m      \u001b[32m0.9815\u001b[0m        \u001b[35m0.0907\u001b[0m  0.1472\n",
            "     10      \u001b[36m0.9935\u001b[0m      \u001b[32m0.9934\u001b[0m        \u001b[35m0.0690\u001b[0m  0.1471\n",
            "\n",
            "loop: 5\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.25), ('expl', 0.23), ('fixed', 0.22), ('mark', 0.14), ('iobj', 0.09), ('obj', 0.08)]\n",
            "\n",
            "O concílio de Tolosa em 1229 estendeu o preceito de Inocêncio III , ordenando que a confissão fosse feita três vezes por ano , dizendo que emanava aquele decreto para poder mais eficazmente destruir a heresia e que declarava suspeitos de heresia aqueles que não se confessassem três vezes por ano .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.25), ('obj', 0.2), ('expl', 0.16), ('mark', 0.15), ('fixed', 0.13), ('iobj', 0.12)]\n",
            "\n",
            "Diz se que o site possui autoridade sobre seu assunto ou área .\n",
            "nsubj\n",
            "\n",
            "loop: 5\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('nsubj', 0.25), ('obj', 0.22), ('mark', 0.2), ('iobj', 0.05), ('fixed', 0.03)]\n",
            "\n",
            "A fortuna de cada um de nós , não está em o dinheiro que se tem .\n",
            "nsubj\n",
            "\n",
            "loop: 5\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('obj', 0.24), ('nsubj', 0.2), ('fixed', 0.16), ('expl', 0.15), ('mark', 0.13), ('iobj', 0.12)]\n",
            "\n",
            "A intenção ( boa ) era a de prevenir e combater o SPAM ( correio indesejado ) automático ... Alertado para os problemas que estava a causar a os leitores , desencorajando os de participar , já fizemos as alterações que se impunham a as nossas definições , em meados de julho de 2012.. .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl', 0.25), ('nsubj', 0.25), ('obj', 0.22), ('mark', 0.2), ('iobj', 0.05), ('fixed', 0.03)]\n",
            "\n",
            "Então veja - além de ser um filme magnífico , de certeza que se vai identificar com o protagonista .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('obj', 0.24), ('expl', 0.23), ('nsubj', 0.14), ('iobj', 0.07), ('fixed', 0.06)]\n",
            "\n",
            "Mas a minha pergunta pra vocês é : Em que momento noto que torna se um vício ?\n",
            "iobj\n",
            "\n",
            "loop: 5\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('mark', 0.26), ('obj', 0.26), ('nsubj', 0.12), ('iobj', 0.05), ('fixed', 0.04)]\n",
            "\n",
            "Aqui é mais um « acto falhado » , um objecto anódino que se esquece , sendo o esquecimento a distracção de os presentes , atarefados por o trabalho de a montagem de o varandim .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('expl', 0.25), ('obj', 0.21), ('nsubj', 0.11), ('fixed', 0.08), ('iobj', 0.07)]\n",
            "\n",
            "Um outro ponto importante a se observar a respeito de a generosidade é que ela gera uma maior confiança e respeito em o time , melhorando a comunicação interpessoal , que contribui para o alcance de melhores resultados .\n",
            "nsubj\n",
            "\n",
            "loop: 5\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('obj', 0.26), ('nsubj', 0.24), ('mark', 0.13), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "Ora se uma auditoria a uma qualquer autarquia , respeitanto a um período de por exemplo um triénio , demora meses , o que dizer de uma auditoria a uma Sociedade Anónima Desportiva de 15 anos .\n",
            "mark\n",
            "\n",
            "loop: 5\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('mark', 0.27), ('nsubj', 0.26), ('obj', 0.08), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "Assumo que sim , mas para mim fica se por aí .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.26), ('mark', 0.23), ('obj', 0.12), ('iobj', 0.08), ('fixed', 0.06)]\n",
            "\n",
            "Se Cristo é o centro a partir de o qual tudo se constrói , convém escutar-l ' O atentamente e fazer de o amor a Deus e a os outros uma exigência fundamental de a nossa caminhada .\n",
            "mark\n",
            "\n",
            "loop: 5\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.22), ('mark', 0.16), ('iobj', 0.13), ('obj', 0.12), ('fixed', 0.1)]\n",
            "\n",
            "Se o modelo , aparentemente já dotado de um ser superior , deseja algo , só pode se tratar de um objeto capaz de conferir uma plenitude de ser ainda mais total .\n",
            "mark\n",
            "\n",
            "loop: 5\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.26), ('obj', 0.26), ('mark', 0.2), ('iobj', 0.02), ('fixed', 0.01)]\n",
            "\n",
            "Por influência de a esposa , conseguiu emprego em a empresa de Bianor ( José Wilker ) , o homem com quem Joana , preterida , se casou .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('nsubj', 0.25), ('expl', 0.23), ('iobj', 0.11), ('obj', 0.09), ('fixed', 0.05)]\n",
            "\n",
            "Um de os requisitos necessários para transpormos esse 1º Portal é saber perdoar , mas perdoar com todos os sentidos , pois quem se ofende é a personalidade .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('expl', 0.24), ('nsubj', 0.22), ('iobj', 0.1), ('fixed', 0.09), ('obj', 0.09)]\n",
            "\n",
            "Isto tudo para dizer , que sou uma mãe com muita vontade que a minha filha goste de ler e que , em o que depender de mim ( já que o pai , apesar de não se opôr , não gosta de ler ) , nunca lhe faltem livros para ler .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.27), ('expl', 0.26), ('obj', 0.21), ('mark', 0.18), ('iobj', 0.05), ('fixed', 0.03)]\n",
            "\n",
            "Respeite sua privacidade e não as force a contar segredos se é algo realmente particular .\n",
            "mark\n",
            "\n",
            "loop: 5\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.26), ('mark', 0.18), ('obj', 0.11), ('iobj', 0.1), ('fixed', 0.09)]\n",
            "\n",
            "Em este lugar ermo , as serpentes existem , como em todo o lado , mas existe algo mais assustador , se bem que pouco perigoso - talvez a Vipera latastei , víbora cornuda .\n",
            "fixed\n",
            "\n",
            "loop: 5\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.22), ('nsubj', 0.2), ('obj', 0.14), ('iobj', 0.1), ('fixed', 0.07)]\n",
            "\n",
            "Qualquer romantismo que porventura aparecesse esvaecia se em o primeiro desentendimento , quando então Marcinha mandava tudo a as favas .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.28), ('mark', 0.16), ('obj', 0.12), ('fixed', 0.08), ('iobj', 0.08)]\n",
            "\n",
            "Bem é isso que a policia desconfia tanto que pediram a prisão temporária de o dono de a boate Kiss , e mais dois integrantes de a banda que se apresentava em o dia .\n",
            "expl\n",
            "\n",
            "loop: 5\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.24), ('mark', 0.21), ('fixed', 0.09), ('iobj', 0.09), ('obj', 0.08)]\n",
            "\n",
            "Inicialmente utiliza se um produto para o relaxamento capilar e a utilização de a chapa térmica , e ainda um equipamento que distribui e coloca a queratina uniformemente criando o cabelo liso .\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5891\u001b[0m      \u001b[32m0.4623\u001b[0m        \u001b[35m1.5633\u001b[0m  0.1543\n",
            "      2      \u001b[36m0.6100\u001b[0m      0.4622        \u001b[35m1.1575\u001b[0m  0.1544\n",
            "      3      \u001b[36m0.6118\u001b[0m      \u001b[32m0.4664\u001b[0m        \u001b[35m0.9701\u001b[0m  0.1512\n",
            "      4      \u001b[36m0.7036\u001b[0m      \u001b[32m0.6293\u001b[0m        \u001b[35m0.7243\u001b[0m  0.1469\n",
            "      5      \u001b[36m0.8645\u001b[0m      \u001b[32m0.8443\u001b[0m        \u001b[35m0.4597\u001b[0m  0.1441\n",
            "      6      \u001b[36m0.9391\u001b[0m      \u001b[32m0.9303\u001b[0m        \u001b[35m0.2839\u001b[0m  0.1579\n",
            "      7      \u001b[36m0.9618\u001b[0m      \u001b[32m0.9577\u001b[0m        \u001b[35m0.1876\u001b[0m  0.1514\n",
            "      8      \u001b[36m0.9736\u001b[0m      \u001b[32m0.9715\u001b[0m        \u001b[35m0.1331\u001b[0m  0.1504\n",
            "      9      \u001b[36m0.9809\u001b[0m      \u001b[32m0.9797\u001b[0m        \u001b[35m0.0993\u001b[0m  0.1495\n",
            "     10      \u001b[36m0.9891\u001b[0m      \u001b[32m0.9885\u001b[0m        \u001b[35m0.0768\u001b[0m  0.1588\n",
            "\n",
            "loop: 6\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('fixed', 0.27), ('mark', 0.24), ('expl', 0.22), ('nsubj', 0.13), ('iobj', 0.1), ('obj', 0.05)]\n",
            "\n",
            "A juíza Ana Carriço disse ainda que , também desde essa altura , passou a ter cuidados redobrados e que tentava sempre perceber se o advogado andava armado .\n",
            "mark\n",
            "\n",
            "loop: 6\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl', 0.24), ('nsubj', 0.23), ('obj', 0.19), ('mark', 0.13), ('fixed', 0.12), ('iobj', 0.09)]\n",
            "\n",
            "Hoje percebo que Deus se utilizava de aquela menina para falar em seu Nome para um menininho .\n",
            "obj\n",
            "\n",
            "loop: 6\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.2), ('obj', 0.2), ('mark', 0.15), ('fixed', 0.1), ('iobj', 0.09)]\n",
            "\n",
            "Isto refere se a as técnicas de MLM e similares .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('fixed', 0.2), ('nsubj', 0.16), ('mark', 0.14), ('iobj', 0.12), ('obj', 0.12)]\n",
            "\n",
            "« As naves sobrevoaram por um tempo Los Angeles , pessoas entraram em conflito interno e chamaram as autoridades militares que logo chegarem com seus helicópteros , que tentaram intimidar as naves que sabiamente se dispersaram . \"\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('fixed', 0.27), ('mark', 0.25), ('nsubj', 0.21), ('obj', 0.12), ('iobj', 0.1), ('expl', 0.06)]\n",
            "\n",
            "« PUBLICIDADE PUBLICIDADE FAMOSOS EM O INSTAGRAM PUBLICIDADE Conecte se com nós PUBLICIDADE Boatos & FOFOCAS Revistas de fofocas apresentam histórias escandalosas sobre a vida pessoal de celebridades .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('mark', 0.26), ('nsubj', 0.18), ('obj', 0.14), ('fixed', 0.08), ('iobj', 0.07)]\n",
            "\n",
            "Todos os comentário serão respondidos , portanto se você tiver alguma dúvida ou fizer alguma pergunta , volte a o post em questão para conferir a sua resposta !\n",
            "mark\n",
            "\n",
            "loop: 6\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('mark', 0.25), ('nsubj', 0.19), ('fixed', 0.17), ('iobj', 0.07), ('obj', 0.05)]\n",
            "\n",
            "Não se põe um país a pão e água por precaução . \"\n",
            "nsubj\n",
            "\n",
            "loop: 6\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('obj', 0.25), ('mark', 0.22), ('expl', 0.21), ('nsubj', 0.2), ('fixed', 0.08), ('iobj', 0.04)]\n",
            "\n",
            "Misteriosamente , Red se entrega , prometendo dizer onde está o terrorista Ranko Zamani , há muito tido como morto .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('fixed', 0.25), ('expl', 0.22), ('iobj', 0.1), ('nsubj', 0.09), ('obj', 0.08)]\n",
            "\n",
            "Seguiram se novos episódios de violência , não só para com a juíza mas também contra a própria filha e Ferreira da Silva .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('nsubj', 0.24), ('expl', 0.21), ('obj', 0.21), ('iobj', 0.04), ('fixed', 0.03)]\n",
            "\n",
            "13 Também levantou a capa de Elias , que lhe caíra ; e voltou se e parou a a borda de o Jordão .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('fixed', 0.27), ('mark', 0.25), ('nsubj', 0.21), ('obj', 0.12), ('iobj', 0.1), ('expl', 0.06)]\n",
            "\n",
            "PUBLICIDADE PUBLICIDADE FAMOSOS EM O INSTAGRAM PUBLICIDADE Conecte se com nós PUBLICIDADE Boatos & FOFOCAS Revistas de fofocas apresentam histórias escandalosas sobre a vida pessoal de celebridades .\n",
            "None\n",
            "\n",
            "loop: 6\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('expl', 0.26), ('obj', 0.17), ('nsubj', 0.13), ('iobj', 0.09), ('fixed', 0.07)]\n",
            "\n",
            "- As questões colocadas serão exclarecidas via e-mail se o mesmo for disponibilizado por o comentador .\n",
            "mark\n",
            "\n",
            "loop: 6\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('obj', 0.27), ('mark', 0.25), ('expl', 0.22), ('nsubj', 0.16), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "Não adianta suprimir os sintomas se a raiz de o mal continua ali presente , porque ele [ alcoolismo ] vai voltar » , explica .\n",
            "mark\n",
            "\n",
            "loop: 6\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.25), ('mark', 0.22), ('obj', 0.21), ('iobj', 0.03), ('fixed', 0.02)]\n",
            "\n",
            "Eles são os pais de Charlie ( Tracy Spiridakos ) e Danny ( Graham Rogers ) , que acabam se tornando protagonistas de a trama .\n",
            "iobj\n",
            "\n",
            "loop: 6\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.26), ('obj', 0.16), ('mark', 0.13), ('fixed', 0.1), ('iobj', 0.08)]\n",
            "\n",
            "Há algumas teorias em as quais a sabedoria popular se baseia .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.27), ('expl', 0.25), ('mark', 0.22), ('obj', 0.16), ('fixed', 0.06), ('iobj', 0.04)]\n",
            "\n",
            "O local e a hora eram completamente imprevisíveis , e ele mais vezes se desviou de batalhas do que as enfrentou .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.23), ('expl', 0.19), ('fixed', 0.16), ('iobj', 0.09), ('mark', 0.06)]\n",
            "\n",
            "A gente se acostuma a pagar por tudo o que deseja e o de que necessita .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('obj', 0.28), ('mark', 0.27), ('expl', 0.24), ('nsubj', 0.17), ('fixed', 0.02), ('iobj', 0.02)]\n",
            "\n",
            "Um oficial içara a bandeira pedindo socorro e mais de cinqüenta homens lançaram se a o mar .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('fixed', 0.21), ('mark', 0.19), ('nsubj', 0.16), ('obj', 0.1), ('iobj', 0.06)]\n",
            "\n",
            "Determinação se realiza em o acaso de a dialética .\n",
            "expl\n",
            "\n",
            "loop: 6\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.27), ('fixed', 0.14), ('iobj', 0.11), ('nsubj', 0.11), ('obj', 0.1)]\n",
            "\n",
            "A aceitação de a Graça , por outro lado , dá se por a Fé e exige renúncia , dedicação , obediência e Sacrifícios .\n",
            "expl\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.4996\u001b[0m      \u001b[32m0.4457\u001b[0m        \u001b[35m1.6296\u001b[0m  0.1474\n",
            "      2      \u001b[36m0.6104\u001b[0m      \u001b[32m0.4627\u001b[0m        \u001b[35m1.1780\u001b[0m  0.1483\n",
            "      3      \u001b[36m0.6113\u001b[0m      \u001b[32m0.4647\u001b[0m        \u001b[35m0.9803\u001b[0m  0.1479\n",
            "      4      \u001b[36m0.7140\u001b[0m      \u001b[32m0.6461\u001b[0m        \u001b[35m0.7404\u001b[0m  0.1465\n",
            "      5      \u001b[36m0.8704\u001b[0m      \u001b[32m0.8474\u001b[0m        \u001b[35m0.4855\u001b[0m  0.1505\n",
            "      6      \u001b[36m0.9348\u001b[0m      \u001b[32m0.9253\u001b[0m        \u001b[35m0.3094\u001b[0m  0.1582\n",
            "      7      \u001b[36m0.9562\u001b[0m      \u001b[32m0.9503\u001b[0m        \u001b[35m0.2081\u001b[0m  0.1506\n",
            "      8      \u001b[36m0.9687\u001b[0m      \u001b[32m0.9658\u001b[0m        \u001b[35m0.1488\u001b[0m  0.1489\n",
            "      9      \u001b[36m0.9759\u001b[0m      \u001b[32m0.9736\u001b[0m        \u001b[35m0.1116\u001b[0m  0.1461\n",
            "     10      \u001b[36m0.9821\u001b[0m      \u001b[32m0.9811\u001b[0m        \u001b[35m0.0866\u001b[0m  0.1499\n",
            "\n",
            "loop: 7\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('mark', 0.23), ('obj', 0.22), ('nsubj', 0.13), ('fixed', 0.08), ('iobj', 0.08)]\n",
            "\n",
            "Pesquisar em o Diário ... DECIF ' 13 - Campanha DB Os 19 bombeiros que perderam suas vidas em um incêndio Arizona aproveitou o último recurso disponível para eles - abrigos de emergência que se parecem com aluminizados sacos de dormir - mas mesmo aqueles que não foram suficientes para salvar los .\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.27), ('expl', 0.26), ('mark', 0.14), ('obj', 0.14), ('fixed', 0.09), ('iobj', 0.09)]\n",
            "\n",
            "Trata se de um erro grave , uma vez que o nosso país deixou de ser República Popular de Moçambique em 1990 com a entrada em vigor de a Constituição da República que introduz o multipartidarismo , há sensivelmente 20 anos ... Maputo ( Canalmoz ) - Em a edição número 206 , de o Canalmoz , de o dia 20 de Maio , publicámos uma notícia com o título Parlamento cria comissão para inquirir partidarização de o Estado , dando conta de a criação , por a Assembleia da República , de uma comissão de inquérito para inquirir a partidarização de o Estado .\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.26), ('expl', 0.25), ('mark', 0.23), ('obj', 0.21), ('fixed', 0.02), ('iobj', 0.02)]\n",
            "\n",
            "A.A. acredita que os alcoólicos são pessoas enfermas , passíveis de recuperação se seguirem um simples programa , bem sucedido para mais de 2 milhões de homens e mulheres .\n",
            "mark\n",
            "\n",
            "loop: 7\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('mark', 0.26), ('obj', 0.22), ('expl', 0.21), ('nsubj', 0.2), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "Epa , é que esses lavradores chegam mesmo a convencer as pessoas que em o linux só se instalam programas por a « linha de comandos » ( como eles lhe chamam ) !\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.26), ('expl', 0.25), ('mark', 0.25), ('fixed', 0.11), ('iobj', 0.07), ('obj', 0.07)]\n",
            "\n",
            "Há muito que se mudar - « Correio Popular » Os artigos assinados não traduzem a opinião de o Instituto Millenium .\n",
            "nsubj\n",
            "\n",
            "loop: 7\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('mark', 0.22), ('nsubj', 0.19), ('obj', 0.18), ('fixed', 0.07), ('iobj', 0.07)]\n",
            "\n",
            "Onde as pessoas não são presas sem razão , onde não se cometem abusos , onde há uma democracia a funcionar .\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('obj', 0.27), ('mark', 0.21), ('expl', 0.2), ('nsubj', 0.2), ('iobj', 0.07), ('fixed', 0.04)]\n",
            "\n",
            "É dizer o que ela quer ouvir só pra conquistar , escondendo quem se é de verdade ?\n",
            "nsubj\n",
            "\n",
            "loop: 7\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.27), ('nsubj', 0.19), ('obj', 0.16), ('iobj', 0.06), ('fixed', 0.04)]\n",
            "\n",
            "Mozilla admite que nada está finalizado ainda , uma vez que continua a concentrar se em testar a funcionalidade de a sua App Store .\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.26), ('mark', 0.25), ('obj', 0.13), ('fixed', 0.04), ('iobj', 0.04)]\n",
            "\n",
            "Esta crise era um facto inegável e de aí vão surgir duas correntes explicativas : Explicação liberal ( por esquerdistas ) : esta teoria defendia que se está a viver uma crise de governabilidade e a razão é o excesso de democracia , de controle público sobre as empresas e sobre a economia .\n",
            "nsubj\n",
            "\n",
            "loop: 7\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.24), ('nsubj', 0.24), ('obj', 0.1), ('fixed', 0.07), ('iobj', 0.07)]\n",
            "\n",
            "Esta minha opção foi se formando ao longo de o tempo e influenciada por vários fatores : qualidade de vida em o interior , melhor lugar para criar os filhos , possibilidade de relacionamento mais caloroso com as pessoas , participação em a vida de a comunidade ...\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('obj', 0.28), ('nsubj', 0.23), ('expl', 0.2), ('mark', 0.14), ('iobj', 0.09), ('fixed', 0.05)]\n",
            "\n",
            "Embora isto não seja desculpa para o que ele fez , pois se ele tivesse sido um « homenzinho » , não tinha marcado um casamento só para cumprir os desejos de a sua familia .\n",
            "mark\n",
            "\n",
            "loop: 7\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.25), ('expl', 0.24), ('mark', 0.21), ('obj', 0.16), ('iobj', 0.08), ('fixed', 0.07)]\n",
            "\n",
            "Não é necessário se fazer nada , pois elas sumirão mais cedo ou mais tarde .\n",
            "nsubj\n",
            "\n",
            "loop: 7\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.27), ('mark', 0.19), ('obj', 0.17), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "- A mulher ( se foi casada e teve filhos ) tem mantido um relacionamento de amor e respeito para com os filhos de o casamento anterior ?\n",
            "mark\n",
            "\n",
            "loop: 7\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.23), ('obj', 0.2), ('iobj', 0.1), ('mark', 0.1), ('fixed', 0.08)]\n",
            "\n",
            "De o Templo de Jerusalém foi recuperado um código de leis , « o livro de a Lei » ( sêfer hattôrâh ) , como se lê em 2 Rs 22,8 .\n",
            "nsubj\n",
            "\n",
            "loop: 7\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.29), ('expl', 0.28), ('mark', 0.23), ('obj', 0.09), ('iobj', 0.06), ('fixed', 0.05)]\n",
            "\n",
            "Sonho que se sonha junto é ralidade ! \"\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.24), ('expl', 0.2), ('mark', 0.15), ('iobj', 0.09), ('fixed', 0.04)]\n",
            "\n",
            "Mas o povão gosta de ser passado para trás em todas as situações ( sociais , políticas e financeiras ) às vezes fazem sacrifícios e se afundam em as compras .\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.2), ('nsubj', 0.2), ('obj', 0.13), ('fixed', 0.1), ('iobj', 0.09)]\n",
            "\n",
            "Acredito também que cada um tenta ser qualquer coisa ao longo de a vida , isto é , que se vai auto-moldando em função de as caracteristicas que considera desejáveis para si ( claro que o « qualquer coisa » que nós queremos ser também vai mudando de definição ao longo de o tempo ) .\n",
            "obj\n",
            "\n",
            "loop: 7\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('expl', 0.23), ('obj', 0.22), ('mark', 0.21), ('fixed', 0.03), ('iobj', 0.02)]\n",
            "\n",
            "Não é muito provável , contudo , que venhamos jamais a encontrar buracos de minhoca macroscópicos como os que se vêem em a série de televisão \" Deep Space Nine \\> \" .\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('obj', 0.26), ('nsubj', 0.22), ('mark', 0.12), ('iobj', 0.08), ('fixed', 0.04)]\n",
            "\n",
            "Quem tem por profissão pensar , podia dançar de vez em quando , conhecer o que se fala em esta outra linguagem .\n",
            "expl\n",
            "\n",
            "loop: 7\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('obj', 0.24), ('mark', 0.19), ('nsubj', 0.14), ('iobj', 0.09), ('fixed', 0.05)]\n",
            "\n",
            "( rs ) Eu sempre tive muito mais amigos héteros do que gays , antes de me assumir eu tinha medo de todos pararem de falar com mim ou agirem estranho ( e todo aquele drama de sempre ) , pois sempre tivemos brincadeira de moleques , nós dávamos chicotadas de toalha um em a bunda de o outro , roubava cueca de o banheiro para o outro ter que sair caçando onde a gente botou , se trocava em a frente um de o outro e nunca , NEM POR UM SEGUNDO , tive algum desejo sexual por eles , são meus amigos , meus irmãos , e o mais surpreendente é que quando contei pra eles NADA mudou , absolutamente nada , ficamos todos ainda mais próximos , sempre conversamos tomando cerveja e falando de sexo , mulher e homem .\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5382\u001b[0m      \u001b[32m0.4511\u001b[0m        \u001b[35m1.5916\u001b[0m  0.1526\n",
            "      2      \u001b[36m0.6093\u001b[0m      \u001b[32m0.4614\u001b[0m        \u001b[35m1.1587\u001b[0m  0.1494\n",
            "      3      \u001b[36m0.6128\u001b[0m      \u001b[32m0.4693\u001b[0m        \u001b[35m0.9688\u001b[0m  0.1516\n",
            "      4      \u001b[36m0.7243\u001b[0m      \u001b[32m0.6596\u001b[0m        \u001b[35m0.7293\u001b[0m  0.1519\n",
            "      5      \u001b[36m0.8551\u001b[0m      \u001b[32m0.8294\u001b[0m        \u001b[35m0.4785\u001b[0m  0.1638\n",
            "      6      \u001b[36m0.9298\u001b[0m      \u001b[32m0.9184\u001b[0m        \u001b[35m0.3067\u001b[0m  0.1521\n",
            "      7      \u001b[36m0.9535\u001b[0m      \u001b[32m0.9480\u001b[0m        \u001b[35m0.2087\u001b[0m  0.1531\n",
            "      8      \u001b[36m0.9684\u001b[0m      \u001b[32m0.9658\u001b[0m        \u001b[35m0.1510\u001b[0m  0.1549\n",
            "      9      \u001b[36m0.9745\u001b[0m      \u001b[32m0.9723\u001b[0m        \u001b[35m0.1143\u001b[0m  0.1511\n",
            "     10      \u001b[36m0.9816\u001b[0m      \u001b[32m0.9806\u001b[0m        \u001b[35m0.0893\u001b[0m  0.1547\n",
            "\n",
            "loop: 8\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('mark', 0.29), ('expl', 0.23), ('nsubj', 0.2), ('obj', 0.17), ('iobj', 0.07), ('fixed', 0.03)]\n",
            "\n",
            "Não sei exatamente como vc se sente agora , mas já tive uma prévia de histórias assim , porque minha mãe viveu um parto normal em uma maternidade que teve um término parecido e as sensações que ela me relata em o pós-parto são muito parecidas com as que vc descreveu ... Infelizmente , mesmo após muitos anos de luta por a humanização de o parto , mesmo a OMS comprando essa batalha , as instituições brasileiras não mudaram muito ...\n",
            "expl\n",
            "\n",
            "loop: 8\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.24), ('fixed', 0.17), ('obj', 0.12), ('mark', 0.11), ('iobj', 0.09)]\n",
            "\n",
            "Também é possível digitar buscas como « meu voo para Londres » e ver as informações sobre o seu próximo voo - a busca também se tornou mais pessoal .\n",
            "iobj\n",
            "\n",
            "loop: 8\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.26), ('nsubj', 0.22), ('obj', 0.15), ('iobj', 0.06), ('fixed', 0.03)]\n",
            "\n",
            "Ao passo que , em um fracasso , você pode realmente analisar os seus erros , desde o erro psicológico de se achar ótimo , a os erros específicos de aquela produção .\n",
            "expl\n",
            "\n",
            "loop: 8\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.26), ('mark', 0.25), ('obj', 0.18), ('iobj', 0.04), ('fixed', 0.02)]\n",
            "\n",
            "Você também poderia alterar o local de destino para pastas especiais como Documentos ou Imagens ( ou outras ) para pastas em o SkyDrive , tratando o seu SkyDrive como se fosse sua unidade principal ( clique com o botão direito de o mouse em a pasta Documento , clique em Propriedades e em Local ) .\n",
            "fixed\n",
            "\n",
            "loop: 8\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('mark', 0.18), ('nsubj', 0.18), ('fixed', 0.15), ('obj', 0.11), ('iobj', 0.09)]\n",
            "\n",
            "Tu sabe que eu me sinto assim às vezes ... sinto como se tivesse pagando meus pecados aqui em a terra.hehehe Bem assim como tu falou , já aprontei tanto ... já tratei mal quem não merecia e agora só tenho levado porrada .\n",
            "fixed\n",
            "\n",
            "loop: 8\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.24), ('mark', 0.21), ('obj', 0.17), ('fixed', 0.07), ('iobj', 0.06)]\n",
            "\n",
            "Estando as bebidas espirituosas muito associadas a os shots e a o padrão de binge drinking procura se de este modo restringir o acesso de menores a este tipo de bebida e a a instalação precoce de este tipo de padrão .\n",
            "nsubj\n",
            "\n",
            "loop: 8\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.26), ('expl', 0.18), ('iobj', 0.13), ('mark', 0.1), ('fixed', 0.05)]\n",
            "\n",
            "Mas não parece tão absurdo quando se tenta entender sem a condição de refém de o estilo alheio , sobretudo porque o pacote teleológico não é privilégio hegeliano .\n",
            "nsubj\n",
            "\n",
            "loop: 8\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('mark', 0.29), ('nsubj', 0.23), ('obj', 0.19), ('iobj', 0.01), ('fixed', 0.0)]\n",
            "\n",
            "Esta transferência deverá implicar em mudaça de residência para o município onde se situe a instituição recebedora ou para localidade próxima a esta , observadas as normas estabelecidas por o CFE .\n",
            "expl\n",
            "\n",
            "loop: 8\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.25), ('obj', 0.23), ('mark', 0.13), ('iobj', 0.06), ('fixed', 0.05)]\n",
            "\n",
            "Ignoro se teve algo a ver com os alisamentos .\n",
            "mark\n",
            "\n",
            "loop: 8\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.25), ('obj', 0.19), ('nsubj', 0.16), ('iobj', 0.09), ('fixed', 0.04)]\n",
            "\n",
            "Para o irascível Paul Krugman , Nobel da Economia , Ben Bernanke , o presidente de a Reserva Federal americana ( Fed ) , tornou se mais banqueiro do que economista .\n",
            "iobj\n",
            "\n",
            "loop: 8\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('mark', 0.28), ('nsubj', 0.27), ('expl', 0.25), ('obj', 0.08), ('iobj', 0.07), ('fixed', 0.04)]\n",
            "\n",
            "Lembre se de que os tempos mudaram e para a maioria de as meninas , aquela história de esperar o príncipe em um cavalo branco está ultrapassada .\n",
            "expl\n",
            "\n",
            "loop: 8\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.28), ('mark', 0.27), ('obj', 0.1), ('iobj', 0.04), ('fixed', 0.03)]\n",
            "\n",
            "Mas se vês que te sobra compota tens a minha morada não tens ?\n",
            "mark\n",
            "\n",
            "loop: 8\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('mark', 0.27), ('nsubj', 0.23), ('obj', 0.11), ('iobj', 0.07), ('fixed', 0.04)]\n",
            "\n",
            "A comparação é inevitável se tivermos em mente que este é o único disco lançado até aqui de um artista envolvido com movimentos musicais desde fins de a década de 1960 .\n",
            "mark\n",
            "\n",
            "loop: 8\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('obj', 0.28), ('expl', 0.27), ('fixed', 0.17), ('nsubj', 0.15), ('iobj', 0.08), ('mark', 0.05)]\n",
            "\n",
            "Passados três anos e várias mudanças em a política de a autarquia alfacinha , mantém se o interesse .\n",
            "expl\n",
            "\n",
            "loop: 8\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('mark', 0.29), ('expl', 0.28), ('obj', 0.16), ('nsubj', 0.14), ('fixed', 0.06), ('iobj', 0.06)]\n",
            "\n",
            "Outro ponto é que os confrontos óbvios não são surpresas : se você ver uma barricada é contra soldado , viu garrafas demais em o cenário , são clickers .\n",
            "mark\n",
            "\n",
            "loop: 8\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.29), ('mark', 0.23), ('obj', 0.18), ('fixed', 0.01), ('iobj', 0.01)]\n",
            "\n",
            "É em torno de esta ideia que se organiza grande parte de o discurso político e económico de os nossos dias .\n",
            "expl\n",
            "\n",
            "loop: 8\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('mark', 0.29), ('nsubj', 0.22), ('obj', 0.11), ('fixed', 0.05), ('iobj', 0.04)]\n",
            "\n",
            "Mas se você não quer ter pesadelos durante a noite para o resto de sua vida , aconselho a nem desbloquear essa criatura .\n",
            "mark\n",
            "\n",
            "loop: 8\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('mark', 0.28), ('obj', 0.21), ('nsubj', 0.11), ('fixed', 0.06), ('iobj', 0.05)]\n",
            "\n",
            "E tem que se concordar , acertada .\n",
            "expl\n",
            "\n",
            "loop: 8\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.28), ('obj', 0.25), ('mark', 0.12), ('iobj', 0.04), ('fixed', 0.03)]\n",
            "\n",
            "Dizer simplesmente que uma pessoa se torna fixa em a sua maneira de considerar o universo físico e os organismos que a rodeiam não é uma afirmação completa , pois existem formas definidas , para além de a consciência , que permitem que isto suceda .\n",
            "iobj\n",
            "\n",
            "loop: 8\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.29), ('expl', 0.28), ('mark', 0.25), ('obj', 0.11), ('iobj', 0.04), ('fixed', 0.02)]\n",
            "\n",
            "Todos os sete se casaram com ela ! \"\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5418\u001b[0m      \u001b[32m0.4416\u001b[0m        \u001b[35m1.5874\u001b[0m  0.1566\n",
            "      2      \u001b[36m0.6057\u001b[0m      \u001b[32m0.4570\u001b[0m        \u001b[35m1.1740\u001b[0m  0.1563\n",
            "      3      \u001b[36m0.6083\u001b[0m      \u001b[32m0.4628\u001b[0m        \u001b[35m0.9799\u001b[0m  0.1590\n",
            "      4      \u001b[36m0.7179\u001b[0m      \u001b[32m0.6518\u001b[0m        \u001b[35m0.7267\u001b[0m  0.1541\n",
            "      5      \u001b[36m0.8775\u001b[0m      \u001b[32m0.8585\u001b[0m        \u001b[35m0.4673\u001b[0m  0.1533\n",
            "      6      \u001b[36m0.9336\u001b[0m      \u001b[32m0.9234\u001b[0m        \u001b[35m0.2987\u001b[0m  0.1561\n",
            "      7      \u001b[36m0.9534\u001b[0m      \u001b[32m0.9487\u001b[0m        \u001b[35m0.2037\u001b[0m  0.1538\n",
            "      8      \u001b[36m0.9707\u001b[0m      \u001b[32m0.9686\u001b[0m        \u001b[35m0.1476\u001b[0m  0.1517\n",
            "      9      \u001b[36m0.9767\u001b[0m      \u001b[32m0.9752\u001b[0m        \u001b[35m0.1117\u001b[0m  0.1636\n",
            "     10      \u001b[36m0.9862\u001b[0m      \u001b[32m0.9858\u001b[0m        \u001b[35m0.0870\u001b[0m  0.1516\n",
            "\n",
            "loop: 9\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.25), ('mark', 0.24), ('expl', 0.18), ('iobj', 0.03), ('fixed', 0.02)]\n",
            "\n",
            "A cidade não é super plana , mas dá pra pedalar de boa , principalmente se você estiver passeando - tem uma rede de ciclovias que liga os principais parques de a cidade .\n",
            "mark\n",
            "\n",
            "loop: 9\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('mark', 0.27), ('expl', 0.24), ('iobj', 0.17), ('nsubj', 0.15), ('obj', 0.12), ('fixed', 0.05)]\n",
            "\n",
            "Compara a seguir com a imagem anterior : se o contraste aumentou , continua acionando o motor e efetuando comparações , até atingir o maior nível de contraste possível .\n",
            "mark\n",
            "\n",
            "loop: 9\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl', 0.22), ('iobj', 0.21), ('nsubj', 0.19), ('mark', 0.17), ('obj', 0.16), ('fixed', 0.05)]\n",
            "\n",
            "Duchamp se apresentava como um de os precursores de esse modo de pensar a arte , forçando os limites entre os objetos utilitários e os objetos artísticos .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.25), ('mark', 0.24), ('expl', 0.18), ('iobj', 0.03), ('fixed', 0.02)]\n",
            "\n",
            "Um enorme casarão branco ( tipo chalé ) com quase 30 metros de frente e 32 de fundos , com sete cômodos de cada lado , para vendas , onde se instalaram os comerciantes de aquela época .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('iobj', 0.2), ('obj', 0.2), ('mark', 0.14), ('nsubj', 0.1), ('fixed', 0.08)]\n",
            "\n",
            "Pessoalmente , acredito que o choque relaciona se com a confrontação de o leitor com estilos de vida alternativos que fogem a a definição de amor romântico .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl', 0.23), ('fixed', 0.23), ('iobj', 0.22), ('mark', 0.18), ('nsubj', 0.08), ('obj', 0.06)]\n",
            "\n",
            "Payton virou se para a parede , onde havia uma escada improvisada com tábuas e oculta entre a vegetação , e só então notou a presença de a jovem magra e pálida em meio a os arbustos .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('nsubj', 0.25), ('obj', 0.22), ('fixed', 0.12), ('iobj', 0.12), ('mark', 0.04)]\n",
            "\n",
            "Alguns dispositivos , como teclados e mouses , por exemplo , não irão se beneficiar em melhor desempenho .\n",
            "obj\n",
            "\n",
            "loop: 9\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('fixed', 0.28), ('expl', 0.23), ('nsubj', 0.18), ('iobj', 0.13), ('mark', 0.13), ('obj', 0.07)]\n",
            "\n",
            "Se os mesmos ficarem com ela você terá o direito de visitar los , se ficarem com você , ela terá o mesmo direito .\n",
            "mark\n",
            "\n",
            "loop: 9\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.25), ('mark', 0.24), ('expl', 0.18), ('iobj', 0.03), ('fixed', 0.02)]\n",
            "\n",
            "O bebé sente se confortável quando está em o aconchego de a mama .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('expl', 0.27), ('nsubj', 0.23), ('mark', 0.21), ('iobj', 0.15), ('obj', 0.1), ('fixed', 0.05)]\n",
            "\n",
            "saiba mais Acionadas por o ministro de o STF Marco Aurélio Mello , relator de o habeas corpus pedido por a defesa de Pinto , a AGU e a PGR se manifestaram contra possibilidade de governo brasileiro conceder carro diplomático a o senador com base em informações de o Itamaraty .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('obj', 0.22), ('expl', 0.21), ('iobj', 0.17), ('fixed', 0.16), ('mark', 0.12), ('nsubj', 0.12)]\n",
            "\n",
            "Política também se tornou mercado .\n",
            "iobj\n",
            "\n",
            "loop: 9\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('expl', 0.26), ('mark', 0.23), ('obj', 0.14), ('iobj', 0.13), ('nsubj', 0.13), ('fixed', 0.12)]\n",
            "\n",
            "Para tal , tem de haver uma boa dose de amor-próprio para se estabelecer uma relação saudável com um novo parceiro .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.25), ('mark', 0.24), ('expl', 0.18), ('iobj', 0.03), ('fixed', 0.02)]\n",
            "\n",
            "Apesar de não terem sido especificados , estima se que entre os modelos oferecidos esteja o Ilyushin IL-76 .\n",
            "nsubj\n",
            "\n",
            "loop: 9\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('obj', 0.24), ('expl', 0.23), ('mark', 0.12), ('fixed', 0.07), ('iobj', 0.07)]\n",
            "\n",
            "Acredito que esta situação possa contribuir também a longo prazo , para os casos de diabetes em resultado de o « cansaço » de o pâncreas , sempre a ser estimulado sobretudo se se trata de a ingestão de alimentos ricos e açucar ; 3 - Diminuir o consumo de alimentos ricos em açucar e gordura , de excelente « palatibilidade » , o correntemente « sabem bem » , muito ricos em calorias e que oferecem um prazer imediato mas que não promovem a saciedade de o organismo .\n",
            "None\n",
            "\n",
            "loop: 9\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('mark', 0.22), ('nsubj', 0.21), ('obj', 0.15), ('iobj', 0.1), ('fixed', 0.04)]\n",
            "\n",
            "O professor de a Universidade Federal de Minas Gerais ( UFMG ) Francisco Soares , estudioso de o tema , critica : - Não se pode abrir mão de a dimensão de a qualidade .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('mark', 0.29), ('expl', 0.28), ('nsubj', 0.19), ('iobj', 0.09), ('fixed', 0.08), ('obj', 0.08)]\n",
            "\n",
            "Para quem se apresenta publicamente em um Blogue , após abandono profissional , e procura assuntos para evolução cultural ( minha primeira etapa ) , terá que ter alguma coragem e poder de aventura .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('obj', 0.29), ('nsubj', 0.23), ('mark', 0.22), ('expl', 0.18), ('iobj', 0.07), ('fixed', 0.02)]\n",
            "\n",
            "Compreender a Palavra O texto está composto por uma introdução e uma parábola que se desenrola em três cenas .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.28), ('mark', 0.25), ('obj', 0.1), ('iobj', 0.06), ('fixed', 0.03)]\n",
            "\n",
            "Não vou nem entrar em o mérito de como a fase de os dois é péssima ( e não acho os dois tão bons jogadores assim ) , mas se eles não começarem a confiar mais em eles mesmos , a performance de os dois só vai piorar .\n",
            "mark\n",
            "\n",
            "loop: 9\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('obj', 0.25), ('mark', 0.18), ('iobj', 0.15), ('nsubj', 0.09), ('fixed', 0.05)]\n",
            "\n",
            "O músico residente em Lisboa , que confirmou a a nossa reportagem que está de malas feitas para regressar a Angola , questionado sobre a motivação de o grande show gospel de 500 vozes realçou que \" a consolidação de a paz deve se também a o ecumenismo que é forma em que os cristãos enaltecem a união entre os irmãos .\n",
            "expl\n",
            "\n",
            "loop: 9\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('mark', 0.29), ('nsubj', 0.28), ('expl', 0.25), ('obj', 0.09), ('iobj', 0.06), ('fixed', 0.04)]\n",
            "\n",
            "Foi se impondo e conseguiu o carinho de o torcedor de o Bahia .\n",
            "expl\n",
            "Note: you either discarded samples or did not annotate all samples\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5772\u001b[0m      \u001b[32m0.4490\u001b[0m        \u001b[35m1.5626\u001b[0m  0.1736\n",
            "      2      \u001b[36m0.6061\u001b[0m      \u001b[32m0.4575\u001b[0m        \u001b[35m1.1612\u001b[0m  0.1596\n",
            "      3      \u001b[36m0.6095\u001b[0m      \u001b[32m0.4651\u001b[0m        \u001b[35m0.9764\u001b[0m  0.1623\n",
            "      4      \u001b[36m0.7216\u001b[0m      \u001b[32m0.6580\u001b[0m        \u001b[35m0.7371\u001b[0m  0.1569\n",
            "      5      \u001b[36m0.8616\u001b[0m      \u001b[32m0.8366\u001b[0m        \u001b[35m0.4868\u001b[0m  0.1618\n",
            "      6      \u001b[36m0.9253\u001b[0m      \u001b[32m0.9137\u001b[0m        \u001b[35m0.3177\u001b[0m  0.1562\n",
            "      7      \u001b[36m0.9499\u001b[0m      \u001b[32m0.9451\u001b[0m        \u001b[35m0.2195\u001b[0m  0.1656\n",
            "      8      \u001b[36m0.9643\u001b[0m      \u001b[32m0.9620\u001b[0m        \u001b[35m0.1616\u001b[0m  0.1618\n",
            "      9      \u001b[36m0.9737\u001b[0m      \u001b[32m0.9721\u001b[0m        \u001b[35m0.1238\u001b[0m  0.1584\n",
            "     10      \u001b[36m0.9796\u001b[0m      \u001b[32m0.9788\u001b[0m        \u001b[35m0.0984\u001b[0m  0.1625\n",
            "\n",
            "loop: 10\n",
            "sentence: 1\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.27), ('obj', 0.27), ('expl', 0.23), ('fixed', 0.11), ('iobj', 0.09), ('mark', 0.02)]\n",
            "\n",
            "I. Quem se conserva unido a a vontade de Deus , goza , mesmo em este mundo , uma paz inalterável : Non contristabit iustum quidquid ei acciderit ( 1 ) - \" Não entristecerá a o justo coisa alguma que lhe acontecer \" .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 2\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.2), ('iobj', 0.19), ('obj', 0.19), ('fixed', 0.13), ('mark', 0.0)]\n",
            "\n",
            "Preciso de um curriculo para o primeiro emprego ou seja desde motorista alguma coisa em supermercado pois sou habilitado em a categoria b tenho segundo grau completo precisava de uma idea para um curriculo se vcs pudesse me enviar uma ideia ficaria muito grato preciso muito trabalhar .\n",
            "mark\n",
            "\n",
            "loop: 10\n",
            "sentence: 3\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.27), ('obj', 0.15), ('mark', 0.13), ('fixed', 0.08), ('iobj', 0.08)]\n",
            "\n",
            "Estes dois « hotspots » ocupam principalmente a zona costeira , contudo a região Maputoland-Pondoland-Albany estende se por várias centenas de km em o continente a partir de a costa , ate a região norte de Drakensberg / Strydpoortberg .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 4\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('expl', 0.27), ('obj', 0.19), ('mark', 0.1), ('iobj', 0.09), ('fixed', 0.07)]\n",
            "\n",
            "O edifício religioso veio ocupar uma zona relativamente periférica de o primitivo recinto muralhado , onde até a o século XV se localizou a judiaria , precisamente a área oposta a a Alcáçova e a a principal porta de a cidade .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 5\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.29), ('obj', 0.25), ('mark', 0.1), ('iobj', 0.04), ('fixed', 0.02)]\n",
            "\n",
            "Devem se fazer pulverizações preventivas com os fungicidas registrados ( consultar Agrofit ) .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 6\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('mark', 0.16), ('obj', 0.16), ('fixed', 0.14), ('nsubj', 0.13), ('iobj', 0.12)]\n",
            "\n",
            "O nosso técnico despreza completamente esta experiência secular , afirma o contrário e com lamentável orgulho técnico e étnico , não se dá a o incómodo de comprovar .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 7\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('fixed', 0.27), ('mark', 0.18), ('iobj', 0.12), ('obj', 0.09), ('nsubj', 0.05)]\n",
            "\n",
            "Em o final , o sonho realizou se .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 8\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.25), ('obj', 0.17), ('iobj', 0.12), ('mark', 0.09), ('fixed', 0.07)]\n",
            "\n",
            "Não se pode realizar lo através de imagens falsas e abstratas .\n",
            "nsubj\n",
            "\n",
            "loop: 10\n",
            "sentence: 9\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.28), ('expl', 0.27), ('mark', 0.23), ('obj', 0.09), ('fixed', 0.07), ('iobj', 0.06)]\n",
            "\n",
            "Como todos sabem , além de o desempenho como professor em a Escola Secundária Diogo Gouveia ( antigo Liceu ) , a minha participação cívica pautou se por o contributo que durante algumas décadas mantive com o movimento associativo desportivo de a nossa cidade , concelho e região .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 10\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.27), ('mark', 0.22), ('expl', 0.19), ('iobj', 0.17), ('fixed', 0.15), ('obj', 0.01)]\n",
            "\n",
            "Quando morre um africano idoso , é como que se queimasse uma biblioteca ?\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 11\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.27), ('obj', 0.18), ('mark', 0.16), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "Legalidade de a nomeação « Quero deixar claro , mais uma vez , que trata se de nomeação perfeita de o ponto de vista jurídico .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 12\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.3), ('expl', 0.28), ('mark', 0.26), ('obj', 0.06), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "Quem tinha razão era o Presidente Pinto da Costa quando se referiu a os milhões de a treta .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 13\n",
            "The learners predictions are:\n",
            "[('mark', 0.29), ('expl', 0.27), ('nsubj', 0.23), ('obj', 0.13), ('iobj', 0.05), ('fixed', 0.02)]\n",
            "\n",
            "A elevação de Cabo Verde a a condição de cultura original ou específica significa , simplesmente , desconsiderar e destituir os demais grupos de as suas especificidades , reduzindo os a uma representação simplista , colonial e monolítica , como se eles fossem desprovidos de essa aura legitimadora de a própria originalidade caboverdiana .\n",
            "fixed\n",
            "\n",
            "loop: 10\n",
            "sentence: 14\n",
            "The learners predictions are:\n",
            "[('mark', 0.28), ('expl', 0.24), ('nsubj', 0.24), ('fixed', 0.12), ('iobj', 0.07), ('obj', 0.05)]\n",
            "\n",
            "Ela nasce com uma potência , uma força de viver que se expressa em uma voracidade em a utilização de o objeto de satisfação .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 15\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.28), ('mark', 0.26), ('iobj', 0.08), ('fixed', 0.06), ('obj', 0.04)]\n",
            "\n",
            "Os felizes reclamam lhe o amparo , a fim de não se desmandarem em as facilidades que transitoriamente lhes enfeitam as horas .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 16\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.22), ('fixed', 0.19), ('mark', 0.19), ('expl', 0.18), ('obj', 0.13), ('iobj', 0.08)]\n",
            "\n",
            "Tem coisa que não dar pra enteder se o governo faz concurso é pra recadar dinheiro ou pra fazer mais ainda o povo de palhaço ?\n",
            "mark\n",
            "\n",
            "loop: 10\n",
            "sentence: 17\n",
            "The learners predictions are:\n",
            "[('expl', 0.28), ('nsubj', 0.27), ('iobj', 0.16), ('obj', 0.13), ('fixed', 0.08), ('mark', 0.07)]\n",
            "\n",
            "Conhece e se preocupa apenas com suas próprias necessidades .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 18\n",
            "The learners predictions are:\n",
            "[('expl', 0.29), ('nsubj', 0.29), ('mark', 0.18), ('obj', 0.12), ('iobj', 0.07), ('fixed', 0.06)]\n",
            "\n",
            "Esse aumento de juros acontece em uma situação em que o crescimento de a economia arrasta se próxima de o chão , ou seja , perto de zero .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 19\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.3), ('expl', 0.28), ('mark', 0.26), ('obj', 0.06), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "508 Esta discussão perdura até os dias atuais , quando se disponibiliza um bom número de métodos para a discretização de as séries estatísticas .\n",
            "expl\n",
            "\n",
            "loop: 10\n",
            "sentence: 20\n",
            "The learners predictions are:\n",
            "[('nsubj', 0.3), ('expl', 0.28), ('mark', 0.26), ('obj', 0.06), ('fixed', 0.05), ('iobj', 0.05)]\n",
            "\n",
            "era autorizada a se engajar em a comitiva sempre que Marisa , a esposa de Lula , não podia acompanhar o marido .\n",
            "expl\n",
            "Re-initializing module because the following parameters were re-set: hidden_dim.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    accuracy    f1-score    train_loss     dur\n",
            "-------  ----------  ----------  ------------  ------\n",
            "      1      \u001b[36m0.5042\u001b[0m      \u001b[32m0.4350\u001b[0m        \u001b[35m1.5932\u001b[0m  0.1678\n",
            "      2      \u001b[36m0.6093\u001b[0m      \u001b[32m0.4614\u001b[0m        \u001b[35m1.1691\u001b[0m  0.1612\n",
            "      3      \u001b[36m0.6102\u001b[0m      \u001b[32m0.4633\u001b[0m        \u001b[35m0.9911\u001b[0m  0.1715\n",
            "      4      \u001b[36m0.7012\u001b[0m      \u001b[32m0.6286\u001b[0m        \u001b[35m0.7593\u001b[0m  0.1677\n",
            "      5      \u001b[36m0.8548\u001b[0m      \u001b[32m0.8309\u001b[0m        \u001b[35m0.5042\u001b[0m  0.1658\n",
            "      6      \u001b[36m0.9215\u001b[0m      \u001b[32m0.9105\u001b[0m        \u001b[35m0.3279\u001b[0m  0.1590\n",
            "      7      \u001b[36m0.9457\u001b[0m      \u001b[32m0.9412\u001b[0m        \u001b[35m0.2251\u001b[0m  0.1621\n",
            "      8      \u001b[36m0.9574\u001b[0m      \u001b[32m0.9551\u001b[0m        \u001b[35m0.1646\u001b[0m  0.1625\n",
            "      9      \u001b[36m0.9716\u001b[0m      \u001b[32m0.9704\u001b[0m        \u001b[35m0.1258\u001b[0m  0.1618\n",
            "     10      \u001b[36m0.9783\u001b[0m      \u001b[32m0.9775\u001b[0m        \u001b[35m0.1000\u001b[0m  0.1574\n"
          ]
        }
      ],
      "source": [
        "for i in range(number_of_loops):\n",
        "\n",
        "    # query new instances\n",
        "    query_idx, query_inst = learner.query(X_pool, n_instances=n_instances)\n",
        "    predicted_proba = get_learners_preds(learner.predict_proba(X_pool[query_idx]))\n",
        "    sentences = pool.text.iloc[query_idx]\n",
        "\n",
        "    # annotate the queried instances\n",
        "    annotation = list()\n",
        "    counter = 0\n",
        "    for sent, proba in zip(sentences, predicted_proba):\n",
        "        counter += 1\n",
        "        sorted_proba = sorted(proba.items(), key=lambda kv: kv[1], reverse=True)\n",
        "        prompt = '\\n'+'loop: '+str(i+1)+'\\n'+'sentence: '+str(counter)+'\\n'+'The learners predictions are:'+'\\n'+str(sorted_proba)+'\\n\\n'+sent+'\\n'\n",
        "        label = str(input(prompt))\n",
        "        annotation.append(label)\n",
        "\n",
        "    # keep track of annotations\n",
        "    sent_list = sentences.to_list()\n",
        "    pool_sent_list.append(sent_list)\n",
        "    pool_label_list.append(annotation)\n",
        "\n",
        "    # filter out sentences that were assigned 'None'; the learner should not see them\n",
        "    if 'None' in annotation:\n",
        "        print('Note: you either discarded samples or did not annotate all samples')\n",
        "        discarded_idxs=[idx for idx, sample in enumerate(annotation) if sample == 'None'] # TODO\n",
        "        discarded_idxs = sorted(discarded_idxs, reverse=True)\n",
        "        for index in discarded_idxs:\n",
        "            query_inst = np.delete(query_inst, index, axis=0)\n",
        "        annotation = list(filter('None'.__ne__, annotation))\n",
        "\n",
        "\n",
        "    # teach the learner\n",
        "    y_pool = label_encoder.transform(annotation)\n",
        "    learner.teach(query_inst, y_pool)\n",
        "    accuracies.append(learner.score(X=test_features, y=test_labels))\n",
        "\n",
        "    # delete queried instances from pool\n",
        "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "fUUAjbblp2DL",
        "outputId": "2e07e6f0-2ebb-4d5e-dbfa-66aee52f2cbc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot learning curve\n",
        "with plt.style.context('bmh'):\n",
        "    csfont = {'fontname':'Times New Roman'}\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(range(number_of_loops+1), accuracies)\n",
        "    plt.scatter(range(number_of_loops+1), accuracies)\n",
        "    plt.yticks(np.arange(0, 1.1, 0.1), fontsize=20, **csfont)\n",
        "    plt.xticks(np.arange(0, 11, 1), fontsize=20, **csfont)\n",
        "    plt.xlabel('loop number',fontsize=24, **csfont)\n",
        "    plt.ylabel('accuracy',fontsize=24, **csfont)\n",
        "    plt.savefig('/plots/pt_pytorch.png')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8nKkOG8p2DM",
        "outputId": "5a5b9059-8891-4b22-809a-94b823063c75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6454183266932271"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "max(accuracies)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG4heVnXp2DM",
        "outputId": "8b31f2a1-ddb5-495f-ded8-85efe6b28355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 2)\n",
            "                                                text se_label\n",
            "0  tornaram se prisioneiros esperando para aconte...     iobj\n",
            "1  Ou pior , vender como se fosse uma guitarra de...    fixed\n",
            "2  EU penso que a essas temperaturas se chama est...     expl\n",
            "3  Informe o seu médico ou farmacêutico se estive...     mark\n",
            "4  Eh um motivador pessoal para se estudar guitar...    nsubj\n"
          ]
        }
      ],
      "source": [
        "# create df from annotations\n",
        "sent_flattened = get_flattened_list(pool_sent_list)\n",
        "label_flattened = get_flattened_list(pool_label_list)\n",
        "\n",
        "labeled_pool = pd.DataFrame(list(zip(sent_flattened, label_flattened)),\n",
        "               columns =['text', 'se_label'])\n",
        "print(labeled_pool.shape)\n",
        "print(labeled_pool.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RN_SSf6_p2DM"
      },
      "outputs": [],
      "source": [
        "# save labeled pool\n",
        "labeled_pool.to_csv('/labeled_data/pt_pytorch_annotations.txt', header=None, index=False,  sep='\\t')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Tw9lI2GS7a9v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "pt_pytorch_active_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hNzOCU1A9n8G",
        "TcT5QKYzp2DA",
        "5qoyt9cOp2DD",
        "QbudqpM-p2DG"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}