{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "sources :\n",
    "- https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
    "- deeplearningwizard for model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Maxine/Desktop/se_corpus/rubrix'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# installations for colab\n",
    "!pip install skorch\n",
    "!pip install modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/jose/backends/cryptography_backend.py:18: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes, int_to_bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EpochScoring\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "import rubrix as rb\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load data: specify path\n",
    "\"\"\"\n",
    "\n",
    "# 1) (index), text, label\n",
    "initial_train = pd.read_csv('/Users/Maxine/Desktop/se_corpus/ud/es_data/es_ancora-ud-train.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # macbook\n",
    "# initial_train = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/ud/es_data/es_ancora-ud-train.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) #imac\n",
    "# initial_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/es_ancora-ud-train.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "initial_train.drop(columns=['text'], inplace = True)\n",
    "\n",
    "dev = pd.read_csv('/Users/Maxine/Desktop/se_corpus/ud/es_data/es_ancora-ud-dev.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # macbook\n",
    "# dev = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/ud/es_data/es_ancora-ud-dev.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # imac\n",
    "# dev = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/es_ancora-ud-dev.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "dev.drop(columns=['text'], inplace = True)\n",
    "\n",
    "test = pd.read_csv('/Users/Maxine/Desktop/se_corpus/ud/es_data/es_ancora-ud-test.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # macbook\n",
    "# test = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/ud/es_data/es_ancora-ud-test.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # imac\n",
    "# test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/es_ancora-ud-test.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "test.drop(columns=['text'], inplace = True)\n",
    "\n",
    "# by fileting out 'se'-sentences the data split of the initial ud corpus isn't accurate anymore\n",
    "se_corpus = pd.concat([initial_train, dev, test])\n",
    "\n",
    "pool = pd.read_csv('/Users/Maxine/Desktop/se_corpus/corpusdata_org/sp_text_se_corpus.txt', names=['text'], sep='\\t') # 1 col data containing comma values # macbook\n",
    "# pool = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/corpusdata_org/sp_text_se_corpus.txt', names=['text'], sep='\\t') # 1 col data containing comma values # imac\n",
    "# pool = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/sp_text_se_corpus.txt', names=['text'], sep='\\t')\n",
    "\n",
    "# Note: for some reason jupyter cannot find the relative path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4248, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "drop labels that appear only once\n",
    "\"\"\"\n",
    "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'flat')].index)\n",
    "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'fixed')].index)\n",
    "se_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data split\n",
    "\"\"\"\n",
    "X = se_corpus.tokenized_text\n",
    "y = se_corpus.se_label\n",
    "\n",
    "# Split into train+val and test\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=69)\n",
    "\n",
    "# Split train into train and val\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.1, stratify=y, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "check label distribution in splits\n",
    "\"\"\"\n",
    "def get_class_dist(df_col):\n",
    "    data = df_col.value_counts(normalize=True).rename('percentage').mul(100).reset_index().rename(columns = {\"index\":\"label\"})\n",
    "    plot = sns.barplot(x=\"label\", y=\"percentage\", data=data)\n",
    "    plot.set_xticklabels(plot.get_xticklabels(),\n",
    "                          rotation=90,\n",
    "                          horizontalalignment='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_class_dist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "store value counts for making weighted data sets\n",
    "\"\"\"\n",
    "y_train_counter = dict(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\neventually implement fasttext word embeddings instead of CountVectorizer()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "eventually implement fasttext word embeddings instead of CountVectorizer()\n",
    "\"\"\"\n",
    "# import fasttext.util\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # todo change to es\n",
    "# ft = fasttext.load_model('cc.en.300.bin') # rename model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_dev = vectorizer.transform(X_dev).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "pool_vectorized = vectorizer.transform(pool.text).toarray()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_dev = label_encoder.transform(y_dev)\n",
    "y_test = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PoolDataset(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "convert data splits into Datasets\n",
    "\"\"\"\n",
    "train_set = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "dev_set = ClassifierDataset(torch.from_numpy(X_dev).float(), torch.from_numpy(y_dev).long())\n",
    "test_set = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
    "\n",
    "pool_set = PoolDataset(torch.from_numpy(pool_vectorized).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution:  dict_items([('expl:pv', 1502), ('expl:pass', 1032), ('obj', 232), ('expl:impers', 157), ('iobj', 135)]) \n",
      "assigned weights:  tensor([0.0007, 0.0010, 0.0043, 0.0064, 0.0074])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "assign bigger weight to less frequent labels\n",
    "\"\"\"\n",
    "target_list = torch.tensor([target for _, target in train_set])\n",
    "class_count = [label for label in y_train_counter.values()]\n",
    "class_weight = 1./torch.tensor(class_count, dtype=torch.float)\n",
    "print('label distribution: ', y_train_counter.items(), '\\nassigned weights: ', class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assign weight to each sample in the train set\n",
    "\"\"\"\n",
    "class_weight_all = class_weight[target_list]\n",
    "weighted_sampler = WeightedRandomSampler(weights=class_weight_all, num_samples=len(class_weight_all), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "convert Datasets into weighted DataLoader objects\n",
    "\"\"\"\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=64, sampler=weighted_sampler)\n",
    "dev_loader = DataLoader(dataset=dev_set, batch_size=32)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = 64\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = 1\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(16325, 64, 1, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:  cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "skorch library creates sklearn classifier from torch neural net\n",
    "\"\"\"\n",
    "batch_size = 64\n",
    "n_iters = 1000 ### todo gpu\n",
    "epochs = int(n_iters/(len(train_set)/ batch_size))\n",
    "\n",
    "# create the classifier\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('using: ', device)\n",
    "\n",
    "# Callbacks: print accuracy when model is fitted\n",
    "train_acc = EpochScoring(scoring='accuracy', on_train=True,\n",
    "                         name='train_acc', lower_is_better=False)\n",
    "callbacks = [train_acc]\n",
    "\n",
    "classifier = NeuralNetClassifier(module=LSTMModel,\n",
    "                                 batch_size=64,\n",
    "                                 max_epochs= epochs,\n",
    "                                 criterion=nn.CrossEntropyLoss,\n",
    "                                 optimizer=torch.optim.SGD,\n",
    "                                 lr=0.1,\n",
    "                                 train_split=None,\n",
    "                                 callbacks=callbacks,\n",
    "                                 verbose=1,\n",
    "                                 device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 16325])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LSTM need 3-D input: determine shape and reshape\n",
    "- train\n",
    "- pool\n",
    "\"\"\"\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 16325])\n"
     ]
    }
   ],
   "source": [
    "#reshaping to rows, timestamps, features\n",
    "train_features = torch.reshape(train_features,   (train_features.shape[0], 1,train_features.shape[1]))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do the same for the test data which is going to be used in the active learning loop\n",
    "test_features, test_labels = next(iter(test_loader))\n",
    "test_features = torch.reshape(test_features,   (test_features.shape[0], 1,test_features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# do the same for the data pool which is going to be used in the active learning loop\n",
    "X_pool = pool_set.X_data\n",
    "X_pool = torch.reshape(X_pool,   (X_pool.shape[0], 1, X_pool.shape[1]))\n",
    "X_pool = X_pool.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss     dur\n",
      "-------  -----------  ------------  ------\n",
      "      1       \u001B[36m0.0312\u001B[0m        \u001B[32m1.6198\u001B[0m  0.0331\n",
      "      2       \u001B[36m0.3125\u001B[0m        \u001B[32m1.5885\u001B[0m  0.0278\n",
      "      3       \u001B[36m0.5625\u001B[0m        \u001B[32m1.5591\u001B[0m  0.0221\n",
      "      4       \u001B[36m0.6094\u001B[0m        \u001B[32m1.5314\u001B[0m  0.0210\n",
      "      5       0.6094        \u001B[32m1.5054\u001B[0m  0.0230\n",
      "      6       0.6094        \u001B[32m1.4810\u001B[0m  0.0216\n",
      "      7       0.6094        \u001B[32m1.4581\u001B[0m  0.0237\n",
      "      8       0.6094        \u001B[32m1.4366\u001B[0m  0.0213\n",
      "      9       0.6094        \u001B[32m1.4164\u001B[0m  0.0226\n",
      "     10       0.6094        \u001B[32m1.3976\u001B[0m  0.0215\n",
      "     11       0.6094        \u001B[32m1.3800\u001B[0m  0.0214\n",
      "     12       0.6094        \u001B[32m1.3635\u001B[0m  0.0218\n",
      "     13       0.6094        \u001B[32m1.3481\u001B[0m  0.0235\n",
      "     14       0.6094        \u001B[32m1.3338\u001B[0m  0.0208\n",
      "     15       0.6094        \u001B[32m1.3204\u001B[0m  0.0235\n",
      "     16       0.6094        \u001B[32m1.3079\u001B[0m  0.0216\n",
      "     17       0.6094        \u001B[32m1.2963\u001B[0m  0.0224\n",
      "     18       0.6094        \u001B[32m1.2855\u001B[0m  0.0223\n",
      "     19       0.6094        \u001B[32m1.2755\u001B[0m  0.0226\n",
      "     20       0.6094        \u001B[32m1.2661\u001B[0m  0.0233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=LSTMModel(\n",
       "    (lstm): LSTM(16325, 64, batch_first=True)\n",
       "    (fc): Linear(in_features=64, out_features=5, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fit the skorch classifier with the training data instead of leaving fitting to the ActiveLearner() (which would expect different shapes for the input data, would be incompatible with LSTM)\n",
    "\"\"\"\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Active Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mtype\u001B[39m(\u001B[43mclassifier\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "type(classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize the ActiveLearner with the fitted classifier\n",
    "\"\"\"\n",
    "learner = ActiveLearner(estimator=classifier,\n",
    "                        query_strategy=uncertainty_sampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_instances = 10\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop\n",
    "- stops after 20 iterations\n",
    "- opens the rubrix web interface\n",
    "- waits for user response\n",
    "\n",
    "Problem: if annotation is None (e.g in the case a sentence is discarded) the loop breaks. We have to discard certain sentences because when creating the underlying corpus\n",
    "phrases that do not contain 'se' like 'aunque a tu mac no le pase nada' were not discarded because there is no suited programmatical way to differentiate btw. 'pase' and 'si√©ntese'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c884fe45a048408c97dbaf6b3326301a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 records logged to http://localhost:6900/ws/rubrix/pytorch_active_learning_se_corpus\n",
      "confirm that annotations on rubrix are done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 17:13:40.686 | WARNING  | rubrix.client.rubrix_client:load:310 - The argument 'as_pandas' in `rb.load` will be deprecated in the future, and we will always return a `Dataset`. To emulate the future behavior set `as_pandas=False`. To get a pandas DataFrame, call `Dataset.to_pandas()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you either discarded samples or did not annotate all samples\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_acc    train_loss     dur\n",
      "-------  -----------  ------------  ------\n",
      "      1       \u001B[36m0.1111\u001B[0m        \u001B[32m1.6212\u001B[0m  0.0151\n",
      "      2       \u001B[36m0.2222\u001B[0m        \u001B[32m1.5928\u001B[0m  0.0186\n",
      "      3       \u001B[36m0.5556\u001B[0m        \u001B[32m1.5656\u001B[0m  0.0125\n",
      "      4       \u001B[36m0.6667\u001B[0m        \u001B[32m1.5395\u001B[0m  0.0120\n",
      "      5       0.6667        \u001B[32m1.5146\u001B[0m  0.0146\n",
      "      6       0.5556        \u001B[32m1.4907\u001B[0m  0.0124\n",
      "      7       0.5556        \u001B[32m1.4678\u001B[0m  0.0153\n",
      "      8       0.5556        \u001B[32m1.4459\u001B[0m  0.0145\n",
      "      9       0.5556        \u001B[32m1.4249\u001B[0m  0.0137\n",
      "     10       0.5556        \u001B[32m1.4047\u001B[0m  0.0132\n",
      "     11       0.5556        \u001B[32m1.3854\u001B[0m  0.0133\n",
      "     12       0.5556        \u001B[32m1.3668\u001B[0m  0.0139\n",
      "     13       0.5556        \u001B[32m1.3489\u001B[0m  0.0160\n",
      "     14       0.5556        \u001B[32m1.3317\u001B[0m  0.0138\n",
      "     15       0.5556        \u001B[32m1.3151\u001B[0m  0.0140\n",
      "     16       0.5556        \u001B[32m1.2991\u001B[0m  0.0128\n",
      "     17       0.5556        \u001B[32m1.2837\u001B[0m  0.0136\n",
      "     18       0.5556        \u001B[32m1.2688\u001B[0m  0.0136\n",
      "     19       0.5556        \u001B[32m1.2543\u001B[0m  0.0143\n",
      "     20       0.5556        \u001B[32m1.2403\u001B[0m  0.0143\n"
     ]
    }
   ],
   "source": [
    "while len(accuracies) < 1:\n",
    "    query_idx, query_inst = learner.query(X_pool, n_instances=n_instances)\n",
    "    probabilities = learner.predict_proba(X_pool[query_idx])\n",
    "    records = [\n",
    "        rb.TextClassificationRecord(\n",
    "            id=idx,\n",
    "            inputs=pool.text.iloc[idx],\n",
    "            prediction=list(zip(['expl:pass', 'obj', 'expl:impers', 'iobj', 'expl:pv'], probs)),\n",
    "            prediction_agent=\"skorch_classifier\",\n",
    "        )\n",
    "        for idx, probs in zip(query_idx, probabilities)\n",
    "    ]\n",
    "\n",
    "    # log the records\n",
    "    rb.log(records, name=\"pytorch_active_learning_se_corpus\")\n",
    "    webbrowser.get('firefox').open_new_tab('http://0.0.0.0:6900')\n",
    "\n",
    "    input('confirm that annotations on rubrix are done')\n",
    "    records_df = rb.load(\"pytorch_active_learning_se_corpus\", ids=query_idx.tolist(), as_pandas=False)\n",
    "    annotation = [record.annotation for record in records_df]\n",
    "    if None in annotation:\n",
    "        print('Note: you either discarded samples or did not annotate all samples')\n",
    "        discarded_idxs=[idx for idx, sample in enumerate(annotation) if sample is None]\n",
    "        discarded_idxs = sorted(discarded_idxs, reverse=True)\n",
    "        for index in discarded_idxs:\n",
    "            query_inst = np.delete(query_inst, index, axis=0)\n",
    "        annotation = list(filter(None.__ne__, annotation))\n",
    "\n",
    "    # train the classifier with the newly annotated examples\n",
    "    y_pool = label_encoder.transform(annotation)\n",
    "    learner.teach(query_inst, y_pool, only_new=True)\n",
    "    accuracies.append(learner.score(X=test_features, y=test_labels))\n",
    "\n",
    "    X_pool = np.delete(X_pool, query_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy versus the iteration number\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save the samples and the annotations\n",
    "\"\"\"\n",
    "dataset_rb = rb.load(\"sklearn_active_learning_se_corpus\", as_pandas=True)\n",
    "dataset_rb.to_csv('sklearn_annotations.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}