{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "notes:\n",
    "- important todos noted with ###todo\n",
    "\n",
    "\n",
    "sources :\n",
    "- https://towardsdatascience.com/pytorch-tabular-multiclass-classification-9f8211a123ab\n",
    "- deeplearningwizard for model architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/Maxine/Desktop/se_corpus/rubrix'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skorch in /Users/Maxine/Desktop/se_corpus/venv/lib/python3.8/site-packages (0.11.0)\r\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from skorch) (4.63.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from skorch) (1.8.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from skorch) (1.0.2)\r\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/Maxine/Desktop/se_corpus/venv/lib/python3.8/site-packages (from skorch) (0.8.9)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from skorch) (1.19.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn>=0.19.1->skorch) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn>=0.19.1->skorch) (0.16.0)\r\n",
      "Requirement already satisfied: modal in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.4.1)\r\n",
      "Requirement already satisfied: pandas>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from modal) (1.2.4)\r\n",
      "Requirement already satisfied: scipy>=0.18 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from modal) (1.8.0)\r\n",
      "Requirement already satisfied: numpy>=1.13 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from modal) (1.19.3)\r\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from modal) (1.0.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas>=1.1.0->modal) (2020.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas>=1.1.0->modal) (2.8.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn>=0.18->modal) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn>=0.18->modal) (0.16.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->modal) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "# installations for colab\n",
    "!pip install skorch\n",
    "!pip install modal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EpochScoring\n",
    "\n",
    "import webbrowser\n",
    "import rubrix as rb\n",
    "from modAL.models import ActiveLearner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load data: specify path\n",
    "\"\"\"\n",
    "\n",
    "# 1) (index), text, label\n",
    "initial_train = pd.read_csv('/Users/Maxine/Desktop/se_corpus/ud/es_data/es_ancora-ud-train.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # macbook\n",
    "# initial_train = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/ud/es_data/es_ancora-ud-train.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) #imac\n",
    "# initial_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/es_ancora-ud-train.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "initial_train.drop(columns=['text'], inplace = True)\n",
    "\n",
    "dev = pd.read_csv('/Users/Maxine/Desktop/se_corpus/ud/es_data/es_ancora-ud-dev.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # macbook\n",
    "# dev = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/ud/es_data/es_ancora-ud-dev.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # imac\n",
    "# dev = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/es_ancora-ud-dev.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "dev.drop(columns=['text'], inplace = True)\n",
    "\n",
    "test = pd.read_csv('/Users/Maxine/Desktop/se_corpus/ud/es_data/es_ancora-ud-test.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # macbook\n",
    "# test = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/ud/es_data/es_ancora-ud-test.txt', sep='\\t',names=['text', 'tokenized_text', 'se_label']) # imac\n",
    "# test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/es_ancora-ud-test.txt', sep='\\t', names=['text', 'tokenized_text', 'se_label']) # colab\n",
    "test.drop(columns=['text'], inplace = True)\n",
    "\n",
    "# by fileting out 'se'-sentences the data split of the initial ud corpus isn't accurate anymore\n",
    "se_corpus = pd.concat([initial_train, dev, test])\n",
    "\n",
    "pool = pd.read_csv('/Users/Maxine/Desktop/se_corpus/corpusdata_org/sp_text_se_corpus.txt', names=['text'], sep='\\t') # 1 col data containing comma values # macbook\n",
    "# pool = pd.read_csv('/Users/maxine/Documents/GitHub/se_corpus/corpusdata_org/sp_text_se_corpus.txt', names=['text'], sep='\\t') # 1 col data containing comma values # imac\n",
    "# pool = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/master/sp_text_se_corpus.txt', names=['text'], sep='\\t')\n",
    "\n",
    "# Note: for some reason jupyter cannot find the relative path"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "(4248, 2)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'flat')].index)\n",
    "se_corpus = se_corpus.drop(se_corpus[(se_corpus['se_label'] == 'fixed')].index)\n",
    "se_corpus.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data split\n",
    "\"\"\"\n",
    "X = se_corpus.tokenized_text\n",
    "y = se_corpus.se_label\n",
    "\n",
    "# Split into train+val and test\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=69)\n",
    "\n",
    "# Split train into train and val\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.1, stratify=y, random_state=21)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "check label distribution in splits\n",
    "\"\"\"\n",
    "def get_class_dist(y_set):\n",
    "    data = y_set.value_counts(normalize=True).rename('percentage').mul(100).reset_index().rename(columns = {\"index\":\"label\"})\n",
    "    plot = sns.barplot(x=\"label\", y=\"percentage\", data=data)\n",
    "    plot.set_xticklabels(plot.get_xticklabels(),\n",
    "                          rotation=90,\n",
    "                          horizontalalignment='right')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "store value counts for making weighted data sets\n",
    "\"\"\"\n",
    "y_train_counter = dict(y_train.value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_class_dist(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\neventually implement fasttext word embeddings instead of CountVectorizer()\\n'"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "eventually implement fasttext word embeddings instead of CountVectorizer()\n",
    "\"\"\"\n",
    "# import fasttext.util\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # todo change to es\n",
    "# ft = fasttext.load_model('cc.en.300.bin') # rename model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_dev = vectorizer.transform(X_dev).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "pool_vectorized = vectorizer.transform(pool.text).toarray()\n",
    "\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_dev = label_encoder.transform(y_dev)\n",
    "y_test = label_encoder.transform(y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class PoolDataset(Dataset):\n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "train_set = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "dev_set = ClassifierDataset(torch.from_numpy(X_dev).float(), torch.from_numpy(y_dev).long())\n",
    "test_set = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
    "\n",
    "pool_set = PoolDataset(torch.from_numpy(pool_vectorized).float())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution:  dict_items([('expl:pv', 1502), ('expl:pass', 1032), ('obj', 232), ('expl:impers', 157), ('iobj', 135)]) \n",
      "assigned weights:  tensor([0.0007, 0.0010, 0.0043, 0.0064, 0.0074])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "assign bigger weight to less frequent labels\n",
    "\"\"\"\n",
    "target_list = torch.tensor([target for _, target in train_set])\n",
    "class_count = [label for label in y_train_counter.values()]\n",
    "class_weight = 1./torch.tensor(class_count, dtype=torch.float)\n",
    "print('label distribution: ', y_train_counter.items(), '\\nassigned weights: ', class_weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "assign weight to each sample in the train set\n",
    "\"\"\"\n",
    "class_weight_all = class_weight[target_list]\n",
    "weighted_sampler = WeightedRandomSampler(weights=class_weight_all, num_samples=len(class_weight_all), replacement=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=64, sampler=weighted_sampler)\n",
    "dev_loader = DataLoader(dataset=dev_set, batch_size=32)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Data wrangling\n",
    "# 1. Reading data from torchvision\n",
    "# 2. Assembling initial training data for ActiveLearner\n",
    "# 3. Generating the pool\n",
    "# \"\"\"\n",
    "#\n",
    "# dataloader = DataLoader(se_corpus, shuffle=True, batch_size=60000)\n",
    "# X, y = next(iter(dataloader))\n",
    "# X = X.detach().cpu().numpy() # TF not recognized by learner\n",
    "# y = y.detach().cpu().numpy()\n",
    "#\n",
    "# # read training data\n",
    "# X_train, X_test, y_train, y_test = X[:50000], X[50000:], y[:50000], y[50000:]\n",
    "# X_train = X_train.reshape(50000, 1, 28, 28)\n",
    "# X_test = X_test.reshape(10000, 1, 28, 28)\n",
    "#\n",
    "# # assemble initial data\n",
    "# n_initial = 1000\n",
    "# initial_idx = np.random.choice(range(len(X_train)), size=n_initial, replace=False)\n",
    "# X_initial = X_train[initial_idx]\n",
    "# y_initial = y_train[initial_idx]\n",
    "#\n",
    "# # generate the pool\n",
    "# # remove the initial data from the training dataset\n",
    "# X_pool = np.delete(X_train, initial_idx, axis=0)\n",
    "# y_pool = np.delete(y_train, initial_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = 64\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = 1\n",
    "\n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(16325, 64, 1, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "\n",
    "        # One time step\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "# build class for the skorch API\n",
    "# class Torch_Model(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super(Torch_Model, self).__init__()\n",
    "#         self.convs = nn.Sequential(\n",
    "#                                 nn.Conv2d(1,32,3),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Conv2d(32,64,3),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.MaxPool2d(2),\n",
    "#                                 nn.Dropout(0.25)\n",
    "#         )\n",
    "#         self.fcs = nn.Sequential(\n",
    "#                                 nn.Linear(12*12*64,128),\n",
    "#                                 nn.ReLU(),\n",
    "#                                 nn.Dropout(0.5),\n",
    "#                                 nn.Linear(128,10),\n",
    "#         )\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         out = x\n",
    "#         out = self.convs(out)\n",
    "#         out = out.view(-1,12*12*64)\n",
    "#         out = self.fcs(out)\n",
    "#         return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### todo: https://github.com/skorch-dev/skorch/issues/499\n",
    "### add accuracy callback"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:  cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "skorch library creates sklearn classifier from torch neural net\n",
    "\"\"\"\n",
    "batch_size = 64\n",
    "n_iters = 1000 ### todo gpu\n",
    "epochs = int(n_iters/(len(train_set)/ batch_size))\n",
    "\n",
    "# create the classifier\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('using: ', device)\n",
    "\n",
    "# Callbacks: print accuracy when model is fitted\n",
    "train_acc = EpochScoring(scoring='accuracy', on_train=True,\n",
    "                         name='train_acc', lower_is_better=False)\n",
    "callbacks = [train_acc]\n",
    "\n",
    "classifier = NeuralNetClassifier(module=LSTMModel,\n",
    "                                 batch_size=64,\n",
    "                                 max_epochs= epochs,\n",
    "                                 criterion=nn.CrossEntropyLoss,\n",
    "                                 optimizer=torch.optim.SGD,\n",
    "                                 lr=0.1,\n",
    "                                 train_split=None,\n",
    "                                 callbacks=callbacks,\n",
    "                                 verbose=1,\n",
    "                                 device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 16325])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "LSTM need 3-D input: determine shape and reshape\n",
    "- train\n",
    "- pool\n",
    "\"\"\"\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 16325])\n"
     ]
    }
   ],
   "source": [
    "#reshaping to rows, timestamps, features\n",
    "train_features = torch.reshape(train_features,   (train_features.shape[0], 1,train_features.shape[1]))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 1, 16325])\n"
     ]
    }
   ],
   "source": [
    "# do the same for the test data which is going to be used in the active learning loop\n",
    "test_features, test_labels = next(iter(test_loader))\n",
    "test_features = torch.reshape(test_features,   (test_features.shape[0], 1,test_features.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([12579, 1, 16325])\n"
     ]
    }
   ],
   "source": [
    "# do the same for the data pool which is going to be used in the active learning loop\n",
    "X_pool = pool_set.X_data\n",
    "X_pool = torch.reshape(X_pool,   (X_pool.shape[0], 1, X_pool.shape[1]))\n",
    "X_pool = X_pool.detach().cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001B[36m1.6747\u001B[0m  0.0414\n",
      "      2        \u001B[36m1.6695\u001B[0m  0.0377\n",
      "      3        \u001B[36m1.6644\u001B[0m  0.0292\n",
      "      4        \u001B[36m1.6592\u001B[0m  0.0283\n",
      "      5        \u001B[36m1.6542\u001B[0m  0.0275\n",
      "      6        \u001B[36m1.6491\u001B[0m  0.0307\n",
      "      7        \u001B[36m1.6441\u001B[0m  0.0311\n",
      "      8        \u001B[36m1.6392\u001B[0m  0.0288\n",
      "      9        \u001B[36m1.6342\u001B[0m  0.0301\n",
      "     10        \u001B[36m1.6294\u001B[0m  0.0278\n",
      "     11        \u001B[36m1.6245\u001B[0m  0.0314\n",
      "     12        \u001B[36m1.6197\u001B[0m  0.0285\n",
      "     13        \u001B[36m1.6149\u001B[0m  0.0368\n",
      "     14        \u001B[36m1.6101\u001B[0m  0.0316\n",
      "     15        \u001B[36m1.6054\u001B[0m  0.0535\n",
      "     16        \u001B[36m1.6007\u001B[0m  0.0335\n",
      "     17        \u001B[36m1.5960\u001B[0m  0.0385\n",
      "     18        \u001B[36m1.5914\u001B[0m  0.0276\n",
      "     19        \u001B[36m1.5868\u001B[0m  0.0295\n",
      "     20        \u001B[36m1.5822\u001B[0m  0.0320\n"
     ]
    },
    {
     "data": {
      "text/plain": "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n  module_=LSTMModel(\n    (lstm): LSTM(16325, 64, batch_first=True)\n    (fc): Linear(in_features=64, out_features=5, bias=True)\n  ),\n)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fit the skorch classifier with the training data instead of leaving fitting to the ActiveLearner() (which would expect different shapes for the input data, would be incompatible with LSTM)\n",
    "\"\"\"\n",
    "classifier.fit(train_features, train_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Active Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize the ActiveLearner with the fitted classifier\n",
    "\"\"\"\n",
    "learner = ActiveLearner(\n",
    "    estimator=classifier\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "n_instances = 10\n",
    "accuracies = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "# query instances and predicted probs\n",
    "query_idx, query_inst = learner.query(X_pool, n_instances=n_instances)\n",
    "probabilities = learner.predict_proba(X_pool[query_idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37ce3c26562d4ef79ec7053c82ed9801"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 records logged to http://localhost:6900/ws/rubrix/pytorch_active_learning_se_corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": "BulkResponse(dataset='pytorch_active_learning_se_corpus', processed=10, failed=0)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record probs and retrieve text string for annotation\n",
    "records = [rb.TextClassificationRecord(\n",
    "    id=idx,\n",
    "    inputs=pool.text.iloc[idx],\n",
    "    prediction=list(zip(['expl:pass', 'obj', 'expl:impers', 'iobj', 'expl:pv'], probs)),\n",
    "    prediction_agent=\"skorch_classifier\", # purpose: keep track of 'who' did predictions\n",
    "    )\n",
    "    for idx, probs in zip(query_idx, probabilities)\n",
    "]\n",
    "\n",
    "rb.log(records, name=\"pytorch_active_learning_se_corpus\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you either discarded samples or did not annotate all of them\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001B[36m1.6012\u001B[0m  0.0257\n",
      "      2        \u001B[36m1.5992\u001B[0m  0.0267\n",
      "      3        \u001B[36m1.5972\u001B[0m  0.0159\n",
      "      4        \u001B[36m1.5952\u001B[0m  0.0155\n",
      "      5        \u001B[36m1.5932\u001B[0m  0.0148\n",
      "      6        \u001B[36m1.5912\u001B[0m  0.0149\n",
      "      7        \u001B[36m1.5893\u001B[0m  0.0145\n",
      "      8        \u001B[36m1.5873\u001B[0m  0.0205\n",
      "      9        \u001B[36m1.5854\u001B[0m  0.0153\n",
      "     10        \u001B[36m1.5834\u001B[0m  0.0185\n",
      "     11        \u001B[36m1.5815\u001B[0m  0.0215\n",
      "     12        \u001B[36m1.5796\u001B[0m  0.0191\n",
      "     13        \u001B[36m1.5777\u001B[0m  0.0187\n",
      "     14        \u001B[36m1.5758\u001B[0m  0.0165\n",
      "     15        \u001B[36m1.5740\u001B[0m  0.0210\n",
      "     16        \u001B[36m1.5721\u001B[0m  0.0175\n",
      "     17        \u001B[36m1.5703\u001B[0m  0.0187\n",
      "     18        \u001B[36m1.5684\u001B[0m  0.0165\n",
      "     19        \u001B[36m1.5666\u001B[0m  0.0158\n",
      "     20        \u001B[36m1.5648\u001B[0m  0.0185\n"
     ]
    }
   ],
   "source": [
    "# compare annotated label with the predicted label\n",
    "records_df = rb.load(\"pytorch_active_learning_se_corpus\", ids=query_idx.tolist(), as_pandas=False)\n",
    "annotation = [record.annotation for record in records_df]\n",
    "\n",
    "if None in annotation:\n",
    "    # discard sentences that should not be in the corpus and delete index of sentences\n",
    "    print('Note: you either discarded samples or did not annotate all of them')\n",
    "    discarded_idxs=[idx for idx, sample in enumerate(annotation) if sample is None]\n",
    "    discarded_idxs = sorted(discarded_idxs, reverse=True)\n",
    "    for index in discarded_idxs:\n",
    "        query_inst = np.delete(query_inst, index, axis=0)\n",
    "    annotation = list(filter(None.__ne__, annotation))\n",
    "\n",
    "y_pool = label_encoder.transform(annotation)\n",
    "\n",
    "# train the classifier with the newly annotated examples\n",
    "learner.teach(query_inst, y_pool)  # query_inst == X_pool[query_idx]\n",
    "accuracies.append(learner.score(X=test_features, y=test_labels))  # Keep track of our improvement\n",
    "\n",
    "X_pool = np.delete(X_pool, query_idx, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### todo: update while loop\n",
    "\"\"\"\n",
    "# while len(accuracies) < 20:\n",
    "# while len(accuracies) < 2:\n",
    "#     query_idx, query_inst = learner.query(X_pool, n_instances=n_instances)\n",
    "#     probabilities = learner.predict_proba(X_pool[query_idx])\n",
    "#     records = [\n",
    "#     rb.TextClassificationRecord(\n",
    "#         id=idx,\n",
    "#         inputs=pool.text.iloc[idx],\n",
    "#         prediction=list(zip(['expl:pass', 'obj', 'expl:impers', 'iobj', 'expl:pv'], probs)),\n",
    "#         prediction_agent=\"skorch_classifier\", # purpose: keep track of 'who' did predictions\n",
    "#     )\n",
    "#     for idx, probs in zip(query_idx, probabilities)\n",
    "# ]\n",
    "#\n",
    "#     # Log the records\n",
    "#     rb.log(records, name=\"pytorch_active_learning_se_corpus\")\n",
    "#     webbrowser.get('firefox').open_new_tab('http://0.0.0.0:6900')\n",
    "#\n",
    "#     input('confirm that annotations on rubrix are finished')\n",
    "#     records_df = rb.load(\"pytorch_active_learning_se_corpus\", ids=query_idx.tolist(), as_pandas=False)\n",
    "#     annotation = [record.annotation for record in records_df]\n",
    "#     if 'None' in annotation: # make it possible to discard sentences that should not be in the corpus\n",
    "#         print('you either discarded samples or did not annotate all of them')\n",
    "#         annotation = list(filter('None'.__ne__, annotation))\n",
    "#\n",
    "#     y_pool = label_encoder.transform(annotation)  # train the classifier with the newly annotated examples\n",
    "#     learner.teach(query_inst, y_pool)  # query_inst == X_pool[query_idx]\n",
    "#     accuracies.append(learner.score(X=X_test, y=y_test))  # Keep track of our improvement\n",
    "#     X_pool = np.delete(X_pool, query_idx, axis=0)  # remove queried instances from pool"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy versus the iteration number\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Accuracy\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}